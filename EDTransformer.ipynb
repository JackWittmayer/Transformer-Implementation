{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM95VqDd6z/5yReH7aeitkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackWittmayer/Transformer-Implementation/blob/main/EDTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37L0J9nog5yz",
        "outputId": "72d72c6e-d78d-4b83-a819-549fa27aa2f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VNf0Rr3ogy-4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "import pickle\n",
        "from unicodedata import normalize\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(25)\n",
        "random.seed(25)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2Hs0kEZYlwc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1c9989-081d-4314-9285-f74aca946524"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_X = torch.tensor([[3, 2, 0, 1], [1, 2, 3, 0]], dtype=torch.int32).to(device)\n",
        "SAMPLE_Z = torch.tensor([4, 1, 7, 6], dtype=torch.int32).to(device)"
      ],
      "metadata": {
        "id": "bMXiZFPpEtZa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printIfVerbose(verbose, tag, value):\n",
        "    if verbose:\n",
        "        print(tag, value)"
      ],
      "metadata": {
        "id": "6gsV7Wgv2DKh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(vocab_size, embedding_size).to(device)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        embeddings = self.table(sequence)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "Pk7xtwam89Hh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_embedding():\n",
        "    torch.manual_seed(25)\n",
        "    vocab_size = 4\n",
        "    embedding = Embedding(vocab_size, 4)\n",
        "    print(\"weight:\", embedding.table.weight)\n",
        "    print(\"SAMPLE_X: \", SAMPLE_X)\n",
        "    output = embedding(SAMPLE_X)\n",
        "    print(\"output:\", output)\n",
        "    for j in range(len(output)):\n",
        "        #print(\"sample:\", sample)\n",
        "        for i in range(vocab_size):\n",
        "            assert output[j, i, :].eq(embedding.table.weight[SAMPLE_X[j, i]]).all()\n",
        "test_embedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StJF4qlIBYVj",
        "outputId": "21122925-14da-4f39-9fae-d3058ce3116f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[ 0.0877, -0.6113,  0.3441, -1.2916],\n",
            "        [-0.5874,  0.8060,  1.3200,  0.4826],\n",
            "        [ 1.6671, -0.2342,  0.1074,  1.7852],\n",
            "        [ 0.7874, -0.2466,  0.2384, -0.6746]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "SAMPLE_X:  tensor([[3, 2, 0, 1],\n",
            "        [1, 2, 3, 0]], device='cuda:0', dtype=torch.int32)\n",
            "output: tensor([[[ 0.7874, -0.2466,  0.2384, -0.6746],\n",
            "         [ 1.6671, -0.2342,  0.1074,  1.7852],\n",
            "         [ 0.0877, -0.6113,  0.3441, -1.2916],\n",
            "         [-0.5874,  0.8060,  1.3200,  0.4826]],\n",
            "\n",
            "        [[-0.5874,  0.8060,  1.3200,  0.4826],\n",
            "         [ 1.6671, -0.2342,  0.1074,  1.7852],\n",
            "         [ 0.7874, -0.2466,  0.2384, -0.6746],\n",
            "         [ 0.0877, -0.6113,  0.3441, -1.2916]]], device='cuda:0',\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Unembedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(embedding_size, vocab_size)).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.matmul(x, self.weight)"
      ],
      "metadata": {
        "id": "EpoJIpc_CaX6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unembedding():\n",
        "    torch.manual_seed(25)\n",
        "    vocab_size = 10\n",
        "    embedding_size = 4\n",
        "    sequence_length = 4\n",
        "    batch_size = 2\n",
        "    input = torch.rand(batch_size, sequence_length, embedding_size).to(device)\n",
        "    unembedding = Unembedding(vocab_size, embedding_size)\n",
        "\n",
        "    print(\"weight:\", unembedding.weight)\n",
        "    print(\"input: \", input)\n",
        "    output = unembedding(input)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, sequence_length, vocab_size)\n",
        "test_unembedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLZ0-F4xNOMf",
        "outputId": "38ca8433-76ba-458a-a6f0-781959ac7f56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: tensor([[0.4691, 0.6875, 0.9917, 0.2772, 0.7970, 0.2249, 0.1119, 0.6863, 0.2238,\n",
            "         0.2678],\n",
            "        [0.2246, 0.4711, 0.0603, 0.2517, 0.3705, 0.7340, 0.6466, 0.5172, 0.1176,\n",
            "         0.7000],\n",
            "        [0.8191, 0.0488, 0.3021, 0.2490, 0.7769, 0.7847, 0.8554, 0.8310, 0.1154,\n",
            "         0.2578],\n",
            "        [0.4702, 0.0530, 0.4207, 0.7639, 0.7536, 0.6063, 0.1899, 0.2837, 0.6097,\n",
            "         0.5808]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
            "input:  tensor([[[0.7518, 0.1929, 0.0629, 0.9118],\n",
            "         [0.3828, 0.2990, 0.5933, 0.2911],\n",
            "         [0.2416, 0.5582, 0.0481, 0.3497],\n",
            "         [0.3520, 0.9528, 0.0284, 0.8488]],\n",
            "\n",
            "        [[0.3947, 0.5181, 0.9726, 0.8813],\n",
            "         [0.0056, 0.3056, 0.9384, 0.7949],\n",
            "         [0.4399, 0.1766, 0.8739, 0.1425],\n",
            "         [0.4682, 0.6254, 0.3040, 0.7923]]], device='cuda:0')\n",
            "output: tensor([[[0.8762, 0.6591, 1.1598, 0.9691, 1.4066, 0.9128, 0.4358, 0.9266,\n",
            "          0.7540, 0.8821],\n",
            "         [0.8696, 0.4484, 0.6993, 0.5514, 1.0961, 0.9476, 0.7989, 0.9929,\n",
            "          0.3668, 0.6338],\n",
            "         [0.4426, 0.4500, 0.4350, 0.4866, 0.7003, 0.7139, 0.4956, 0.5937,\n",
            "          0.3385, 0.6710],\n",
            "         [0.8015, 0.7373, 0.7723, 0.9928, 1.2953, 1.3154, 0.8409, 0.9988,\n",
            "          0.7116, 1.2615]],\n",
            "\n",
            "        [[1.5126, 0.6096, 1.0873, 1.1551, 1.9262, 1.7665, 1.3784, 1.5970,\n",
            "          0.7988, 1.2309],\n",
            "         [1.2137, 0.2358, 0.6419, 0.9193, 1.4458, 1.4439, 1.1519, 1.1672,\n",
            "          0.6301, 0.9190],\n",
            "         [1.0289, 0.4358, 0.7708, 0.4928, 1.2023, 1.0007, 0.9380, 1.1599,\n",
            "          0.3069, 0.5494],\n",
            "         [0.9816, 0.6733, 0.9272, 0.9681, 1.4381, 1.2832, 0.8673, 1.1221,\n",
            "          0.6964, 1.1016]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_size, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(max_sequence_length, embedding_size).to(device)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        positions = torch.zeros(sequence.shape, dtype=torch.int32)\n",
        "        positions[:, ::] = torch.arange(0, sequence.shape[-1])\n",
        "        #print(\"positions\", positions)\n",
        "        positional_embeddings = self.table(positions.to(device))\n",
        "        return positional_embeddings"
      ],
      "metadata": {
        "id": "5xpYM9Zf_KLw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_positional_embedding():\n",
        "    embedding_size = 8\n",
        "    max_sequence_length = 10\n",
        "    batch_size = 2\n",
        "    positional_embedding = PositionalEmbedding(embedding_size, max_sequence_length)\n",
        "    output = positional_embedding(SAMPLE_X)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, SAMPLE_X.shape[-1], embedding_size)\n",
        "test_positional_embedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l1Z_ZH8Pb_P",
        "outputId": "b03fb17d-86da-4386-fc76-9d99299179ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tensor([[[-0.0079, -0.6091,  1.5286,  1.9735,  0.1646,  0.5387,  0.5112,\n",
            "           0.8526],\n",
            "         [-0.6024, -1.1570,  0.9000,  0.5598,  0.2992, -2.0385,  1.9378,\n",
            "          -0.1953],\n",
            "         [-0.2086,  0.0196, -0.0843, -1.2005,  1.1399,  1.2420,  0.1124,\n",
            "          -0.0296],\n",
            "         [-0.7684,  0.3472,  0.4499, -0.3574, -0.8319,  0.6517,  0.5965,\n",
            "          -1.3327]],\n",
            "\n",
            "        [[-0.0079, -0.6091,  1.5286,  1.9735,  0.1646,  0.5387,  0.5112,\n",
            "           0.8526],\n",
            "         [-0.6024, -1.1570,  0.9000,  0.5598,  0.2992, -2.0385,  1.9378,\n",
            "          -0.1953],\n",
            "         [-0.2086,  0.0196, -0.0843, -1.2005,  1.1399,  1.2420,  0.1124,\n",
            "          -0.0296],\n",
            "         [-0.7684,  0.3472,  0.4499, -0.3574, -0.8319,  0.6517,  0.5965,\n",
            "          -1.3327]]], device='cuda:0', grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(queries, keys, values, mask, verbose):\n",
        "    printIfVerbose(verbose, \"queries:\", queries)\n",
        "    printIfVerbose(verbose, \"keys:\", keys)\n",
        "    printIfVerbose(verbose, \"values:\", values)\n",
        "    keys_transposed = torch.transpose(keys, -2, -1)\n",
        "    printIfVerbose(verbose, \"keys_transposed:\", keys_transposed)\n",
        "    scores = torch.matmul(queries, keys_transposed)\n",
        "    #assert scores.shape == (keys.shape[0], keys.shape[-1], queries.shape[-1])\n",
        "    printIfVerbose(verbose, \"scores:\", scores)\n",
        "    printIfVerbose(verbose, \"scores:\", scores.shape)\n",
        "    printIfVerbose(verbose, \"masks:\", mask.shape)\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    printIfVerbose(verbose, \"masked scores:\", scores)\n",
        "    d_attn = keys.shape[-1]\n",
        "    scaled_scores = scores / math.sqrt(d_attn)\n",
        "    printIfVerbose(verbose, \"scaled_scores:\", scaled_scores)\n",
        "    softmax_scores = torch.softmax(scaled_scores, -1)\n",
        "    printIfVerbose(verbose, \"softmax_scores:\", softmax_scores)\n",
        "    printIfVerbose(verbose, \"softmax_socres shape:\", softmax_scores.shape)\n",
        "    printIfVerbose(verbose, \"values:\", values)\n",
        "    v_out = torch.matmul(softmax_scores, values)\n",
        "    return v_out"
      ],
      "metadata": {
        "id": "DL3t3E_ThGF2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_attention():\n",
        "    d_attn = 4\n",
        "    length_x = 4\n",
        "    length_z = 3\n",
        "    batch_size = 2\n",
        "    d_out = 2\n",
        "\n",
        "    queries = torch.rand(batch_size, length_x, d_attn)\n",
        "    keys = torch.rand(batch_size, length_z, d_attn)\n",
        "    values = torch.rand(batch_size, length_z, d_out)\n",
        "    mask = torch.tril(torch.ones(length_x, length_z) == 1)\n",
        "    padding_mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]], dtype=torch.int32)\n",
        "\n",
        "    v_out = attention(queries, keys, values, mask, True)\n",
        "    #print(\"output:\", v_out)\n",
        "    assert v_out.shape == (batch_size, length_x, d_out)\n",
        "test_attention()"
      ],
      "metadata": {
        "id": "KhGXLYp6i61z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711a0c96-315a-4a27-bedb-963cb0a17629"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries: tensor([[[0.2746, 0.1760, 0.3505, 0.9246],\n",
            "         [0.8537, 0.5464, 0.9339, 0.0768],\n",
            "         [0.0565, 0.3594, 0.4961, 0.6278],\n",
            "         [0.3572, 0.5220, 0.1997, 0.5286]],\n",
            "\n",
            "        [[0.4723, 0.0238, 0.1838, 0.2010],\n",
            "         [0.1765, 0.8587, 0.7776, 0.1199],\n",
            "         [0.8638, 0.1066, 0.1084, 0.8448],\n",
            "         [0.7043, 0.9275, 0.3953, 0.2704]]])\n",
            "keys: tensor([[[0.6228, 0.6078, 0.7686, 0.3296],\n",
            "         [0.4959, 0.0065, 0.9125, 0.8358],\n",
            "         [0.6698, 0.4129, 0.0129, 0.5052]],\n",
            "\n",
            "        [[0.5967, 0.3134, 0.1648, 0.4834],\n",
            "         [0.2368, 0.7654, 0.9255, 0.3393],\n",
            "         [0.5612, 0.0953, 0.5582, 0.5739]]])\n",
            "values: tensor([[[0.5244, 0.6292],\n",
            "         [0.7426, 0.3134],\n",
            "         [0.7793, 0.9385]],\n",
            "\n",
            "        [[0.1588, 0.3427],\n",
            "         [0.3863, 0.2306],\n",
            "         [0.1533, 0.0876]]])\n",
            "keys_transposed: tensor([[[0.6228, 0.4959, 0.6698],\n",
            "         [0.6078, 0.0065, 0.4129],\n",
            "         [0.7686, 0.9125, 0.0129],\n",
            "         [0.3296, 0.8358, 0.5052]],\n",
            "\n",
            "        [[0.5967, 0.2368, 0.5612],\n",
            "         [0.3134, 0.7654, 0.0953],\n",
            "         [0.1648, 0.9255, 0.5582],\n",
            "         [0.4834, 0.3393, 0.5739]]])\n",
            "scores: tensor([[[0.8523, 1.2301, 0.7283],\n",
            "         [1.6069, 1.3433, 0.8482],\n",
            "         [0.8419, 1.0077, 0.5098],\n",
            "         [0.8675, 0.8046, 0.7244]],\n",
            "\n",
            "        [[0.4168, 0.3684, 0.4853],\n",
            "         [0.5606, 1.4594, 0.6838],\n",
            "         [0.9751, 0.6731, 1.0402],\n",
            "         [0.9068, 1.3343, 0.8595]]])\n",
            "scores: torch.Size([2, 4, 3])\n",
            "masks: torch.Size([4, 3])\n",
            "masked scores: tensor([[[ 8.5227e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.6069e+00,  1.3433e+00, -1.0000e+09],\n",
            "         [ 8.4185e-01,  1.0077e+00,  5.0977e-01],\n",
            "         [ 8.6750e-01,  8.0463e-01,  7.2441e-01]],\n",
            "\n",
            "        [[ 4.1675e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.6055e-01,  1.4594e+00, -1.0000e+09],\n",
            "         [ 9.7509e-01,  6.7312e-01,  1.0402e+00],\n",
            "         [ 9.0683e-01,  1.3343e+00,  8.5948e-01]]])\n",
            "scaled_scores: tensor([[[ 4.2613e-01, -5.0000e+08, -5.0000e+08],\n",
            "         [ 8.0343e-01,  6.7164e-01, -5.0000e+08],\n",
            "         [ 4.2093e-01,  5.0386e-01,  2.5489e-01],\n",
            "         [ 4.3375e-01,  4.0231e-01,  3.6221e-01]],\n",
            "\n",
            "        [[ 2.0838e-01, -5.0000e+08, -5.0000e+08],\n",
            "         [ 2.8028e-01,  7.2970e-01, -5.0000e+08],\n",
            "         [ 4.8754e-01,  3.3656e-01,  5.2012e-01],\n",
            "         [ 4.5341e-01,  6.6716e-01,  4.2974e-01]]])\n",
            "softmax_scores: tensor([[[1.0000, 0.0000, 0.0000],\n",
            "         [0.5329, 0.4671, 0.0000],\n",
            "         [0.3409, 0.3704, 0.2887],\n",
            "         [0.3448, 0.3342, 0.3210]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000],\n",
            "         [0.3895, 0.6105, 0.0000],\n",
            "         [0.3457, 0.2972, 0.3571],\n",
            "         [0.3110, 0.3852, 0.3038]]])\n",
            "softmax_socres shape: torch.Size([2, 4, 3])\n",
            "values: tensor([[[0.5244, 0.6292],\n",
            "         [0.7426, 0.3134],\n",
            "         [0.7793, 0.9385]],\n",
            "\n",
            "        [[0.1588, 0.3427],\n",
            "         [0.3863, 0.2306],\n",
            "         [0.1533, 0.0876]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "class MaskStrategy(Enum):\n",
        "    UNMASKED = 1\n",
        "    MASKED = 2"
      ],
      "metadata": {
        "id": "wUJ-CbaCB9g-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, maskStrategy, verbose):\n",
        "        super().__init__()\n",
        "        self.verbose = verbose\n",
        "        self.num_heads = num_heads\n",
        "        self.d_attn = d_attn\n",
        "        self.d_x = d_x\n",
        "        self.d_z = d_z\n",
        "        self.d_out = d_out\n",
        "        self.d_mid = d_mid\n",
        "        self.maskStrategy = maskStrategy\n",
        "        self.weight_query = nn.Parameter(torch.rand(num_heads, d_x, d_attn))\n",
        "        self.weight_key = nn.Parameter(torch.rand(num_heads, d_z, d_attn))\n",
        "        self.weight_value = nn.Parameter(torch.rand(num_heads, d_z, d_mid))\n",
        "        self.weight_out = nn.Parameter(torch.rand(d_mid * num_heads, d_out))\n",
        "        self.bias_query = nn.Parameter(torch.zeros(num_heads, d_attn))\n",
        "        self.bias_key = nn.Parameter(torch.zeros(num_heads, d_attn))\n",
        "        self.bias_value = nn.Parameter(torch.zeros(num_heads, d_mid))\n",
        "        self.bias_out = nn.Parameter(torch.zeros(d_out))\n",
        "\n",
        "    def forward(self, z, x, padding_mask):\n",
        "        length_z = z.shape[-2]\n",
        "        length_x = x.shape[-2]\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        queries = torch.matmul(x.unsqueeze(1), self.weight_query) + self.bias_query[None, :, None, :]\n",
        "        keys = torch.matmul(z.unsqueeze(1), self.weight_key) + self.bias_key[None, :, None, :]\n",
        "        values = torch.matmul(z.unsqueeze(1), self.weight_value) + self.bias_value[None, :, None, :]\n",
        "\n",
        "        assert queries.shape == (batch_size, self.num_heads, length_x, self.d_attn)\n",
        "        assert keys.shape == (batch_size, self.num_heads, length_z, self.d_attn)\n",
        "        assert values.shape == (batch_size, self.num_heads, length_z, self.d_mid)\n",
        "\n",
        "        if self.maskStrategy == MaskStrategy['UNMASKED']:\n",
        "            mask = padding_mask.unsqueeze(-2)\n",
        "        elif self.maskStrategy == MaskStrategy['MASKED']:\n",
        "            padding_mask = padding_mask.unsqueeze(-2)\n",
        "            mask = torch.tril(torch.ones(length_x, length_z) == 1).to(device)\n",
        "            printIfVerbose(self.verbose, \"padding mask:\", padding_mask.shape)\n",
        "            printIfVerbose(self.verbose, \"mask tril\", mask)\n",
        "            mask = mask & padding_mask\n",
        "            printIfVerbose(self.verbose, \"merged mask:\", mask)\n",
        "        mask = mask.unsqueeze(1)\n",
        "        printIfVerbose(self.verbose, \"mask\", mask)\n",
        "        printIfVerbose(self.verbose, \"mask\", mask.shape)\n",
        "        v_out = attention(queries, keys, values, mask, self.verbose)\n",
        "        printIfVerbose(self.verbose, \"v_out shape\", v_out.shape)\n",
        "        assert v_out.shape == (batch_size, self.num_heads, length_x, self.d_mid)\n",
        "        printIfVerbose(self.verbose, \"v_out:\", v_out)\n",
        "        printIfVerbose(self.verbose, \"v_out shape before:\", v_out.shape)\n",
        "        v_out = v_out.reshape(batch_size, v_out.shape[-2], -1)\n",
        "        printIfVerbose(self.verbose, \"v_out shape:\", v_out.shape)\n",
        "        printIfVerbose(self.verbose, \"weight_out shape:\", self.weight_out.shape)\n",
        "        printIfVerbose(self.verbose, \"v_out reshaped:\", v_out)\n",
        "        output = torch.matmul(v_out, self.weight_out) + self.bias_out\n",
        "        printIfVerbose(self.verbose, \"output shape\", output.shape)\n",
        "        assert output.shape == (batch_size, length_x, self.d_out)\n",
        "        return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CX2A1i9Z4lVO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multi_headed_attention_encoder_fixed():\n",
        "    num_heads = 1\n",
        "    d_attn = 3\n",
        "    d_x = 4\n",
        "    d_z = 4\n",
        "    d_out = 1\n",
        "    d_mid = 3\n",
        "    length_z = 3\n",
        "    batch_size = 1\n",
        "    padding_mask = torch.tensor([[1, 1, 0]], dtype=torch.int32).to(device)\n",
        "\n",
        "    multi_headed_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'], True).to(device)\n",
        "    multi_headed_attention.weight_query = nn.Parameter(torch.tensor([[[1, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 1]]], dtype = torch.float32).to(device))\n",
        "    multi_headed_attention.weight_key = nn.Parameter(torch.tensor([[[0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0]]], dtype = torch.float32).to(device))\n",
        "    multi_headed_attention.weight_value = nn.Parameter(torch.tensor([[[0, 2, 0], [0, 3, 0], [1, 0, 3], [1, 1, 0]]], dtype = torch.float32).to(device))\n",
        "    multi_headed_attention.weight_out = nn.Parameter(torch.tensor([[1], [0], [1]], dtype = torch.float32).to(device))\n",
        "    z = torch.tensor([[[1, 0, 1, 0], [0, 2, 0, 2], [1, 1, 1, 1]]], dtype=torch.float32).to(device)\n",
        "    #print(\"z:\", z\n",
        "    output = multi_headed_attention(z, z, padding_mask)\n",
        "    #print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, length_z, d_out)\n",
        "test_multi_headed_attention_encoder_fixed()"
      ],
      "metadata": {
        "id": "kJuRy-3dTMY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce673f1-9335-4f9c-c408-6799c14d2fbe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask tensor([[[[1, 1, 0]]]], device='cuda:0', dtype=torch.int32)\n",
            "mask torch.Size([1, 1, 1, 3])\n",
            "queries: tensor([[[[1.0334, 0.4025, 2.4895],\n",
            "          [2.0334, 2.4025, 2.4895],\n",
            "          [2.0334, 1.4025, 3.4895]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys: tensor([[[[0.7353, 1.7822, 1.5923],\n",
            "          [4.7353, 4.7822, 0.5923],\n",
            "          [2.7353, 3.7822, 1.5923]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "values: tensor([[[[1.8523, 2.2521, 3.5369],\n",
            "          [2.8523, 8.2521, 0.5369],\n",
            "          [2.8523, 6.2521, 3.5369]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys_transposed: tensor([[[[0.7353, 4.7353, 2.7353],\n",
            "          [1.7822, 4.7822, 3.7822],\n",
            "          [1.5923, 0.5923, 1.5923]]]], device='cuda:0',\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "scores: tensor([[[[ 5.4412,  8.2928,  8.3130],\n",
            "          [ 9.7409, 22.5925, 18.6127],\n",
            "          [ 9.5510, 18.4026, 16.4228]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "scores: torch.Size([1, 1, 3, 3])\n",
            "masks: torch.Size([1, 1, 1, 3])\n",
            "masked scores: tensor([[[[ 5.4412e+00,  8.2928e+00, -1.0000e+09],\n",
            "          [ 9.7409e+00,  2.2593e+01, -1.0000e+09],\n",
            "          [ 9.5510e+00,  1.8403e+01, -1.0000e+09]]]], device='cuda:0',\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "scaled_scores: tensor([[[[ 3.1415e+00,  4.7878e+00, -5.7735e+08],\n",
            "          [ 5.6239e+00,  1.3044e+01, -5.7735e+08],\n",
            "          [ 5.5143e+00,  1.0625e+01, -5.7735e+08]]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "softmax_scores: tensor([[[[1.6160e-01, 8.3840e-01, 0.0000e+00],\n",
            "          [5.9885e-04, 9.9940e-01, 0.0000e+00],\n",
            "          [5.9969e-03, 9.9400e-01, 0.0000e+00]]]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "softmax_socres shape: torch.Size([1, 1, 3, 3])\n",
            "values: tensor([[[[1.8523, 2.2521, 3.5369],\n",
            "          [2.8523, 8.2521, 0.5369],\n",
            "          [2.8523, 6.2521, 3.5369]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "v_out shape torch.Size([1, 1, 3, 3])\n",
            "v_out: tensor([[[[2.6907, 7.2825, 1.0217],\n",
            "          [2.8517, 8.2485, 0.5387],\n",
            "          [2.8463, 8.2161, 0.5549]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "v_out shape before: torch.Size([1, 1, 3, 3])\n",
            "v_out shape: torch.Size([1, 3, 3])\n",
            "weight_out shape: torch.Size([3, 1])\n",
            "v_out reshaped: tensor([[[2.6907, 7.2825, 1.0217],\n",
            "         [2.8517, 8.2485, 0.5387],\n",
            "         [2.8463, 8.2161, 0.5549]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "output shape torch.Size([1, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multi_headed_attention_encoder():\n",
        "    num_heads = 3\n",
        "    d_attn = 3\n",
        "    d_x = 4\n",
        "    d_z = 4\n",
        "    d_out = 1\n",
        "    d_mid = 3\n",
        "    length_z = 3\n",
        "    batch_size = 3\n",
        "    padding_mask = torch.tensor([[1, 1, 0], [1, 1, 0], [1, 1, 1]], dtype=torch.int32).to(device)\n",
        "\n",
        "    multi_headed_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'], True).to(device)\n",
        "    z = torch.tensor([[[1, 0, 1, 0], [0, 2, 0, 2], [1, 1, 1, 1]],\n",
        "                      [[1, 0, 1, 0], [0, 2, 0, 2], [1, 1, 1, 1]],\n",
        "                      [[1, 0, 1, 0], [0, 2, 0, 2], [1, 1, 1, 1]]], dtype=torch.float32).to(device)\n",
        "    #print(\"z:\", z\n",
        "    output = multi_headed_attention(z, z, padding_mask)\n",
        "    #print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, length_z, d_out)\n",
        "test_multi_headed_attention_encoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9CYHYJbMObt",
        "outputId": "17ea22d0-dc5e-4597-8b9c-e25a6a412479"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask tensor([[[[1, 1, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 1, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 1, 1]]]], device='cuda:0', dtype=torch.int32)\n",
            "mask torch.Size([3, 1, 1, 3])\n",
            "queries: tensor([[[[1.6190, 0.6863, 2.1165],\n",
            "          [3.4282, 1.5750, 3.2955],\n",
            "          [3.1582, 1.4306, 3.3010]],\n",
            "\n",
            "         [[2.1277, 1.7037, 1.2801],\n",
            "          [2.8481, 2.1833, 2.1802],\n",
            "          [3.1013, 2.4035, 2.2014]],\n",
            "\n",
            "         [[0.4334, 1.3646, 1.3209],\n",
            "          [2.4264, 1.4926, 3.5806],\n",
            "          [1.5392, 1.9644, 3.0962]]],\n",
            "\n",
            "\n",
            "        [[[1.6190, 0.6863, 2.1165],\n",
            "          [3.4282, 1.5750, 3.2955],\n",
            "          [3.1582, 1.4306, 3.3010]],\n",
            "\n",
            "         [[2.1277, 1.7037, 1.2801],\n",
            "          [2.8481, 2.1833, 2.1802],\n",
            "          [3.1013, 2.4035, 2.2014]],\n",
            "\n",
            "         [[0.4334, 1.3646, 1.3209],\n",
            "          [2.4264, 1.4926, 3.5806],\n",
            "          [1.5392, 1.9644, 3.0962]]],\n",
            "\n",
            "\n",
            "        [[[1.6190, 0.6863, 2.1165],\n",
            "          [3.4282, 1.5750, 3.2955],\n",
            "          [3.1582, 1.4306, 3.3010]],\n",
            "\n",
            "         [[2.1277, 1.7037, 1.2801],\n",
            "          [2.8481, 2.1833, 2.1802],\n",
            "          [3.1013, 2.4035, 2.2014]],\n",
            "\n",
            "         [[0.4334, 1.3646, 1.3209],\n",
            "          [2.4264, 1.4926, 3.5806],\n",
            "          [1.5392, 1.9644, 3.0962]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys: tensor([[[[2.5229, 1.3445, 1.9752],\n",
            "          [2.0873, 3.2342, 4.1285],\n",
            "          [3.1471, 2.6863, 3.6520]],\n",
            "\n",
            "         [[1.1572, 0.8625, 1.7915],\n",
            "          [2.2861, 2.5625, 1.6820],\n",
            "          [2.2603, 2.1015, 2.4997]],\n",
            "\n",
            "         [[0.8895, 0.6030, 1.5121],\n",
            "          [1.9893, 2.5933, 0.7180],\n",
            "          [1.6948, 1.8888, 1.8344]]],\n",
            "\n",
            "\n",
            "        [[[2.5229, 1.3445, 1.9752],\n",
            "          [2.0873, 3.2342, 4.1285],\n",
            "          [3.1471, 2.6863, 3.6520]],\n",
            "\n",
            "         [[1.1572, 0.8625, 1.7915],\n",
            "          [2.2861, 2.5625, 1.6820],\n",
            "          [2.2603, 2.1015, 2.4997]],\n",
            "\n",
            "         [[0.8895, 0.6030, 1.5121],\n",
            "          [1.9893, 2.5933, 0.7180],\n",
            "          [1.6948, 1.8888, 1.8344]]],\n",
            "\n",
            "\n",
            "        [[[2.5229, 1.3445, 1.9752],\n",
            "          [2.0873, 3.2342, 4.1285],\n",
            "          [3.1471, 2.6863, 3.6520]],\n",
            "\n",
            "         [[1.1572, 0.8625, 1.7915],\n",
            "          [2.2861, 2.5625, 1.6820],\n",
            "          [2.2603, 2.1015, 2.4997]],\n",
            "\n",
            "         [[0.8895, 0.6030, 1.5121],\n",
            "          [1.9893, 2.5933, 0.7180],\n",
            "          [1.6948, 1.8888, 1.8344]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "values: tensor([[[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]],\n",
            "\n",
            "\n",
            "        [[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]],\n",
            "\n",
            "\n",
            "        [[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys_transposed: tensor([[[[2.5229, 2.0873, 3.1471],\n",
            "          [1.3445, 3.2342, 2.6863],\n",
            "          [1.9752, 4.1285, 3.6520]],\n",
            "\n",
            "         [[1.1572, 2.2861, 2.2603],\n",
            "          [0.8625, 2.5625, 2.1015],\n",
            "          [1.7915, 1.6820, 2.4997]],\n",
            "\n",
            "         [[0.8895, 1.9893, 1.6948],\n",
            "          [0.6030, 2.5933, 1.8888],\n",
            "          [1.5121, 0.7180, 1.8344]]],\n",
            "\n",
            "\n",
            "        [[[2.5229, 2.0873, 3.1471],\n",
            "          [1.3445, 3.2342, 2.6863],\n",
            "          [1.9752, 4.1285, 3.6520]],\n",
            "\n",
            "         [[1.1572, 2.2861, 2.2603],\n",
            "          [0.8625, 2.5625, 2.1015],\n",
            "          [1.7915, 1.6820, 2.4997]],\n",
            "\n",
            "         [[0.8895, 1.9893, 1.6948],\n",
            "          [0.6030, 2.5933, 1.8888],\n",
            "          [1.5121, 0.7180, 1.8344]]],\n",
            "\n",
            "\n",
            "        [[[2.5229, 2.0873, 3.1471],\n",
            "          [1.3445, 3.2342, 2.6863],\n",
            "          [1.9752, 4.1285, 3.6520]],\n",
            "\n",
            "         [[1.1572, 2.2861, 2.2603],\n",
            "          [0.8625, 2.5625, 2.1015],\n",
            "          [1.7915, 1.6820, 2.4997]],\n",
            "\n",
            "         [[0.8895, 1.9893, 1.6948],\n",
            "          [0.6030, 2.5933, 1.8888],\n",
            "          [1.5121, 0.7180, 1.8344]]]], device='cuda:0',\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "scores: tensor([[[[ 9.1877, 14.3367, 14.6683],\n",
            "          [17.2757, 25.8548, 27.0552],\n",
            "          [16.4110, 24.8466, 25.8373]],\n",
            "\n",
            "         [[ 6.2249, 11.3832, 11.5897],\n",
            "          [ 9.0846, 15.7729, 16.4757],\n",
            "          [ 9.6053, 16.9514, 17.5635]],\n",
            "\n",
            "         [[ 3.2057,  5.3494,  5.7351],\n",
            "          [ 8.4727, 11.2685, 13.4996],\n",
            "          [ 7.2355, 10.3794, 11.9987]]],\n",
            "\n",
            "\n",
            "        [[[ 9.1877, 14.3367, 14.6683],\n",
            "          [17.2757, 25.8548, 27.0552],\n",
            "          [16.4110, 24.8466, 25.8373]],\n",
            "\n",
            "         [[ 6.2249, 11.3832, 11.5897],\n",
            "          [ 9.0846, 15.7729, 16.4757],\n",
            "          [ 9.6053, 16.9514, 17.5635]],\n",
            "\n",
            "         [[ 3.2057,  5.3494,  5.7351],\n",
            "          [ 8.4727, 11.2685, 13.4996],\n",
            "          [ 7.2355, 10.3794, 11.9987]]],\n",
            "\n",
            "\n",
            "        [[[ 9.1877, 14.3367, 14.6683],\n",
            "          [17.2757, 25.8548, 27.0552],\n",
            "          [16.4110, 24.8466, 25.8373]],\n",
            "\n",
            "         [[ 6.2249, 11.3832, 11.5897],\n",
            "          [ 9.0846, 15.7729, 16.4757],\n",
            "          [ 9.6053, 16.9514, 17.5635]],\n",
            "\n",
            "         [[ 3.2057,  5.3494,  5.7351],\n",
            "          [ 8.4727, 11.2685, 13.4996],\n",
            "          [ 7.2355, 10.3794, 11.9987]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "scores: torch.Size([3, 3, 3, 3])\n",
            "masks: torch.Size([3, 1, 1, 3])\n",
            "masked scores: tensor([[[[ 9.1877e+00,  1.4337e+01, -1.0000e+09],\n",
            "          [ 1.7276e+01,  2.5855e+01, -1.0000e+09],\n",
            "          [ 1.6411e+01,  2.4847e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 6.2249e+00,  1.1383e+01, -1.0000e+09],\n",
            "          [ 9.0846e+00,  1.5773e+01, -1.0000e+09],\n",
            "          [ 9.6053e+00,  1.6951e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 3.2057e+00,  5.3494e+00, -1.0000e+09],\n",
            "          [ 8.4727e+00,  1.1268e+01, -1.0000e+09],\n",
            "          [ 7.2355e+00,  1.0379e+01, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[ 9.1877e+00,  1.4337e+01, -1.0000e+09],\n",
            "          [ 1.7276e+01,  2.5855e+01, -1.0000e+09],\n",
            "          [ 1.6411e+01,  2.4847e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 6.2249e+00,  1.1383e+01, -1.0000e+09],\n",
            "          [ 9.0846e+00,  1.5773e+01, -1.0000e+09],\n",
            "          [ 9.6053e+00,  1.6951e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 3.2057e+00,  5.3494e+00, -1.0000e+09],\n",
            "          [ 8.4727e+00,  1.1268e+01, -1.0000e+09],\n",
            "          [ 7.2355e+00,  1.0379e+01, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[ 9.1877e+00,  1.4337e+01,  1.4668e+01],\n",
            "          [ 1.7276e+01,  2.5855e+01,  2.7055e+01],\n",
            "          [ 1.6411e+01,  2.4847e+01,  2.5837e+01]],\n",
            "\n",
            "         [[ 6.2249e+00,  1.1383e+01,  1.1590e+01],\n",
            "          [ 9.0846e+00,  1.5773e+01,  1.6476e+01],\n",
            "          [ 9.6053e+00,  1.6951e+01,  1.7564e+01]],\n",
            "\n",
            "         [[ 3.2057e+00,  5.3494e+00,  5.7351e+00],\n",
            "          [ 8.4727e+00,  1.1268e+01,  1.3500e+01],\n",
            "          [ 7.2355e+00,  1.0379e+01,  1.1999e+01]]]], device='cuda:0',\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "scaled_scores: tensor([[[[ 5.3045e+00,  8.2773e+00, -5.7735e+08],\n",
            "          [ 9.9741e+00,  1.4927e+01, -5.7735e+08],\n",
            "          [ 9.4749e+00,  1.4345e+01, -5.7735e+08]],\n",
            "\n",
            "         [[ 3.5940e+00,  6.5721e+00, -5.7735e+08],\n",
            "          [ 5.2450e+00,  9.1065e+00, -5.7735e+08],\n",
            "          [ 5.5456e+00,  9.7869e+00, -5.7735e+08]],\n",
            "\n",
            "         [[ 1.8508e+00,  3.0885e+00, -5.7735e+08],\n",
            "          [ 4.8917e+00,  6.5058e+00, -5.7735e+08],\n",
            "          [ 4.1774e+00,  5.9926e+00, -5.7735e+08]]],\n",
            "\n",
            "\n",
            "        [[[ 5.3045e+00,  8.2773e+00, -5.7735e+08],\n",
            "          [ 9.9741e+00,  1.4927e+01, -5.7735e+08],\n",
            "          [ 9.4749e+00,  1.4345e+01, -5.7735e+08]],\n",
            "\n",
            "         [[ 3.5940e+00,  6.5721e+00, -5.7735e+08],\n",
            "          [ 5.2450e+00,  9.1065e+00, -5.7735e+08],\n",
            "          [ 5.5456e+00,  9.7869e+00, -5.7735e+08]],\n",
            "\n",
            "         [[ 1.8508e+00,  3.0885e+00, -5.7735e+08],\n",
            "          [ 4.8917e+00,  6.5058e+00, -5.7735e+08],\n",
            "          [ 4.1774e+00,  5.9926e+00, -5.7735e+08]]],\n",
            "\n",
            "\n",
            "        [[[ 5.3045e+00,  8.2773e+00,  8.4687e+00],\n",
            "          [ 9.9741e+00,  1.4927e+01,  1.5620e+01],\n",
            "          [ 9.4749e+00,  1.4345e+01,  1.4917e+01]],\n",
            "\n",
            "         [[ 3.5940e+00,  6.5721e+00,  6.6913e+00],\n",
            "          [ 5.2450e+00,  9.1065e+00,  9.5123e+00],\n",
            "          [ 5.5456e+00,  9.7869e+00,  1.0140e+01]],\n",
            "\n",
            "         [[ 1.8508e+00,  3.0885e+00,  3.3111e+00],\n",
            "          [ 4.8917e+00,  6.5058e+00,  7.7940e+00],\n",
            "          [ 4.1774e+00,  5.9926e+00,  6.9275e+00]]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "softmax_scores: tensor([[[[0.0487, 0.9513, 0.0000],\n",
            "          [0.0070, 0.9930, 0.0000],\n",
            "          [0.0076, 0.9924, 0.0000]],\n",
            "\n",
            "         [[0.0484, 0.9516, 0.0000],\n",
            "          [0.0206, 0.9794, 0.0000],\n",
            "          [0.0142, 0.9858, 0.0000]],\n",
            "\n",
            "         [[0.2248, 0.7752, 0.0000],\n",
            "          [0.1660, 0.8340, 0.0000],\n",
            "          [0.1400, 0.8600, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0487, 0.9513, 0.0000],\n",
            "          [0.0070, 0.9930, 0.0000],\n",
            "          [0.0076, 0.9924, 0.0000]],\n",
            "\n",
            "         [[0.0484, 0.9516, 0.0000],\n",
            "          [0.0206, 0.9794, 0.0000],\n",
            "          [0.0142, 0.9858, 0.0000]],\n",
            "\n",
            "         [[0.2248, 0.7752, 0.0000],\n",
            "          [0.1660, 0.8340, 0.0000],\n",
            "          [0.1400, 0.8600, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0226, 0.4421, 0.5353],\n",
            "          [0.0023, 0.3326, 0.6651],\n",
            "          [0.0028, 0.3598, 0.6375]],\n",
            "\n",
            "         [[0.0234, 0.4592, 0.5174],\n",
            "          [0.0083, 0.3966, 0.5951],\n",
            "          [0.0059, 0.4101, 0.5840]],\n",
            "\n",
            "         [[0.1142, 0.3938, 0.4920],\n",
            "          [0.0413, 0.2072, 0.7515],\n",
            "          [0.0439, 0.2696, 0.6866]]]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "softmax_socres shape: torch.Size([3, 3, 3, 3])\n",
            "values: tensor([[[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]],\n",
            "\n",
            "\n",
            "        [[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]],\n",
            "\n",
            "\n",
            "        [[[1.7189, 1.5675, 1.0440],\n",
            "          [2.7755, 2.6917, 3.3955],\n",
            "          [2.8750, 2.7536, 2.6762]],\n",
            "\n",
            "         [[1.4104, 2.0525, 1.5880],\n",
            "          [1.7873, 4.4439, 2.2690],\n",
            "          [1.9701, 3.9165, 2.5938]],\n",
            "\n",
            "         [[2.4330, 1.0993, 1.7113],\n",
            "          [3.6095, 1.5047, 2.5606],\n",
            "          [3.7646, 1.7647, 2.5100]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "v_out shape torch.Size([3, 3, 3, 3])\n",
            "v_out: tensor([[[[2.7240, 2.6370, 3.2811],\n",
            "          [2.7681, 2.6838, 3.3790],\n",
            "          [2.7674, 2.6831, 3.3776]],\n",
            "\n",
            "         [[1.7690, 4.3281, 2.2360],\n",
            "          [1.7795, 4.3946, 2.2549],\n",
            "          [1.7819, 4.4100, 2.2593]],\n",
            "\n",
            "         [[3.3450, 1.4136, 2.3696],\n",
            "          [3.4142, 1.4374, 2.4196],\n",
            "          [3.4448, 1.4479, 2.4417]]],\n",
            "\n",
            "\n",
            "        [[[2.7240, 2.6370, 3.2811],\n",
            "          [2.7681, 2.6838, 3.3790],\n",
            "          [2.7674, 2.6831, 3.3776]],\n",
            "\n",
            "         [[1.7690, 4.3281, 2.2360],\n",
            "          [1.7795, 4.3946, 2.2549],\n",
            "          [1.7819, 4.4100, 2.2593]],\n",
            "\n",
            "         [[3.3450, 1.4136, 2.3696],\n",
            "          [3.4142, 1.4374, 2.4196],\n",
            "          [3.4448, 1.4479, 2.4417]]],\n",
            "\n",
            "\n",
            "        [[[2.8048, 2.6994, 2.9573],\n",
            "          [2.8392, 2.7302, 2.9116],\n",
            "          [2.8360, 2.7281, 2.9305]],\n",
            "\n",
            "         [[1.8731, 4.1152, 2.4211],\n",
            "          [1.8929, 4.1101, 2.4566],\n",
            "          [1.8918, 4.1218, 2.4547]],\n",
            "\n",
            "         [[3.5514, 1.5863, 2.4387],\n",
            "          [3.6775, 1.6833, 2.4876],\n",
            "          [3.6644, 1.6654, 2.4886]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "v_out shape before: torch.Size([3, 3, 3, 3])\n",
            "v_out shape: torch.Size([3, 3, 9])\n",
            "weight_out shape: torch.Size([9, 1])\n",
            "v_out reshaped: tensor([[[2.7240, 2.6370, 3.2811, 2.7681, 2.6838, 3.3790, 2.7674, 2.6831,\n",
            "          3.3776],\n",
            "         [1.7690, 4.3281, 2.2360, 1.7795, 4.3946, 2.2549, 1.7819, 4.4100,\n",
            "          2.2593],\n",
            "         [3.3450, 1.4136, 2.3696, 3.4142, 1.4374, 2.4196, 3.4448, 1.4479,\n",
            "          2.4417]],\n",
            "\n",
            "        [[2.7240, 2.6370, 3.2811, 2.7681, 2.6838, 3.3790, 2.7674, 2.6831,\n",
            "          3.3776],\n",
            "         [1.7690, 4.3281, 2.2360, 1.7795, 4.3946, 2.2549, 1.7819, 4.4100,\n",
            "          2.2593],\n",
            "         [3.3450, 1.4136, 2.3696, 3.4142, 1.4374, 2.4196, 3.4448, 1.4479,\n",
            "          2.4417]],\n",
            "\n",
            "        [[2.8048, 2.6994, 2.9573, 2.8392, 2.7302, 2.9116, 2.8360, 2.7281,\n",
            "          2.9305],\n",
            "         [1.8731, 4.1152, 2.4211, 1.8929, 4.1101, 2.4566, 1.8918, 4.1218,\n",
            "          2.4547],\n",
            "         [3.5514, 1.5863, 2.4387, 3.6775, 1.6833, 2.4876, 3.6644, 1.6654,\n",
            "          2.4886]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "output shape torch.Size([3, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multi_headed_attention_encoder_decoder():\n",
        "    num_heads = 1\n",
        "    d_attn = 4\n",
        "    d_x = 1\n",
        "    d_z = 1\n",
        "    d_out = 1\n",
        "    d_mid = 1\n",
        "    length_x = 3\n",
        "    length_z = 3\n",
        "    batch_size = 1\n",
        "    padding_mask = torch.tensor([[1, 1, 0]], dtype=torch.int32).to(device)\n",
        "\n",
        "    multi_headed_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'], True).to(device)\n",
        "    x = torch.rand(batch_size, length_x, d_x).to(device)\n",
        "    z = torch.rand(batch_size, length_z, d_z).to(device)\n",
        "    output = multi_headed_attention(z, x, padding_mask)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, length_x, d_out)\n",
        "test_multi_headed_attention_encoder_decoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbYma85ffEHr",
        "outputId": "db4bd993-405f-43aa-e270-a91ee18ac9f8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask tensor([[[[1, 1, 0]]]], device='cuda:0', dtype=torch.int32)\n",
            "mask torch.Size([1, 1, 1, 3])\n",
            "queries: tensor([[[[0.2580, 0.3788, 0.9121, 0.6015],\n",
            "          [0.4090, 0.4261, 1.1700, 1.0154],\n",
            "          [0.3933, 0.4212, 1.1432, 0.9725]]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n",
            "keys: tensor([[[[0.4685, 0.4606, 1.0917, 0.8183],\n",
            "          [0.5242, 0.6823, 1.2893, 0.8993],\n",
            "          [0.5205, 0.6675, 1.2761, 0.8939]]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n",
            "values: tensor([[[[0.5083],\n",
            "          [0.7635],\n",
            "          [0.7465]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys_transposed: tensor([[[[0.4685, 0.5242, 0.5205],\n",
            "          [0.4606, 0.6823, 0.6675],\n",
            "          [1.0917, 1.2893, 1.2761],\n",
            "          [0.8183, 0.8993, 0.8939]]]], device='cuda:0',\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "scores: tensor([[[[1.7833, 2.1106, 2.0888],\n",
            "          [2.4961, 2.9268, 2.8981],\n",
            "          [2.4221, 2.8421, 2.8140]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "scores: torch.Size([1, 1, 3, 3])\n",
            "masks: torch.Size([1, 1, 1, 3])\n",
            "masked scores: tensor([[[[ 1.7833e+00,  2.1106e+00, -1.0000e+09],\n",
            "          [ 2.4961e+00,  2.9268e+00, -1.0000e+09],\n",
            "          [ 2.4221e+00,  2.8421e+00, -1.0000e+09]]]], device='cuda:0',\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "scaled_scores: tensor([[[[ 8.9165e-01,  1.0553e+00, -5.0000e+08],\n",
            "          [ 1.2481e+00,  1.4634e+00, -5.0000e+08],\n",
            "          [ 1.2111e+00,  1.4210e+00, -5.0000e+08]]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "softmax_scores: tensor([[[[0.4592, 0.5408, 0.0000],\n",
            "          [0.4464, 0.5536, 0.0000],\n",
            "          [0.4477, 0.5523, 0.0000]]]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "softmax_socres shape: torch.Size([1, 1, 3, 3])\n",
            "values: tensor([[[[0.5083],\n",
            "          [0.7635],\n",
            "          [0.7465]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "v_out shape torch.Size([1, 1, 3, 1])\n",
            "v_out: tensor([[[[0.6463],\n",
            "          [0.6496],\n",
            "          [0.6493]]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
            "v_out shape before: torch.Size([1, 1, 3, 1])\n",
            "v_out shape: torch.Size([1, 3, 1])\n",
            "weight_out shape: torch.Size([1, 1])\n",
            "v_out reshaped: tensor([[[0.6463],\n",
            "         [0.6496],\n",
            "         [0.6493]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "output shape torch.Size([1, 3, 1])\n",
            "output: tensor([[[0.4839],\n",
            "         [0.4863],\n",
            "         [0.4860]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multi_headed_attention_decoder_self():\n",
        "    num_heads = 8\n",
        "    d_attn = 4\n",
        "    d_x = 4\n",
        "    d_z = 4\n",
        "    d_out = 4\n",
        "    d_mid = 2\n",
        "    length_x = 3\n",
        "    batch_size = 4\n",
        "    padding_mask = torch.tensor([[1, 1, 0], [1, 1, 0], [1, 0, 0], [1, 1, 1]], dtype=torch.int32).to(device)\n",
        "\n",
        "    multi_headed_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['MASKED'], True).to(device)\n",
        "    x = torch.rand(batch_size, length_x, d_x).to(device)\n",
        "    output = multi_headed_attention(x, x, padding_mask)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (batch_size, length_x, d_out)\n",
        "test_multi_headed_attention_decoder_self()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn9s5ak_Yr1B",
        "outputId": "8ceeb920-b53a-4a6e-9633-350a4fcd4bf2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padding mask: torch.Size([4, 1, 3])\n",
            "mask tril tensor([[ True, False, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True,  True]], device='cuda:0')\n",
            "merged mask: tensor([[[1, 0, 0],\n",
            "         [1, 1, 0],\n",
            "         [1, 1, 0]],\n",
            "\n",
            "        [[1, 0, 0],\n",
            "         [1, 1, 0],\n",
            "         [1, 1, 0]],\n",
            "\n",
            "        [[1, 0, 0],\n",
            "         [1, 0, 0],\n",
            "         [1, 0, 0]],\n",
            "\n",
            "        [[1, 0, 0],\n",
            "         [1, 1, 0],\n",
            "         [1, 1, 1]]], device='cuda:0', dtype=torch.int32)\n",
            "mask tensor([[[[1, 0, 0],\n",
            "          [1, 1, 0],\n",
            "          [1, 1, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0],\n",
            "          [1, 1, 0],\n",
            "          [1, 1, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0],\n",
            "          [1, 0, 0],\n",
            "          [1, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0],\n",
            "          [1, 1, 0],\n",
            "          [1, 1, 1]]]], device='cuda:0', dtype=torch.int32)\n",
            "mask torch.Size([4, 1, 3, 3])\n",
            "queries: tensor([[[[1.1067, 1.6913, 2.1271, 1.9234],\n",
            "          [1.2436, 1.4748, 1.8042, 1.9838],\n",
            "          [0.9214, 1.8090, 2.0074, 1.7083]],\n",
            "\n",
            "         [[1.2254, 1.6446, 1.4996, 1.7931],\n",
            "          [1.2596, 1.8325, 1.2539, 1.8559],\n",
            "          [1.4517, 1.6102, 1.3883, 1.7682]],\n",
            "\n",
            "         [[1.2117, 1.2388, 1.1923, 1.0951],\n",
            "          [1.1432, 1.1618, 1.2883, 0.9993],\n",
            "          [1.1506, 1.0997, 1.0540, 1.4119]],\n",
            "\n",
            "         [[0.7924, 1.8029, 0.8203, 1.9887],\n",
            "          [0.5917, 1.6530, 0.7729, 1.7603],\n",
            "          [0.4545, 1.9001, 0.6707, 1.6339]],\n",
            "\n",
            "         [[2.4322, 2.4485, 1.6167, 1.7409],\n",
            "          [2.0945, 2.2110, 1.2761, 1.7208],\n",
            "          [2.1328, 2.4371, 1.4629, 1.7924]],\n",
            "\n",
            "         [[2.1360, 1.9285, 2.1118, 1.4293],\n",
            "          [2.1404, 1.8171, 1.6440, 1.5666],\n",
            "          [2.3523, 1.5365, 1.9197, 1.2238]],\n",
            "\n",
            "         [[1.1698, 1.3698, 1.0904, 1.8496],\n",
            "          [1.0106, 1.4506, 0.8910, 1.7102],\n",
            "          [1.3229, 1.6265, 0.9467, 2.0883]],\n",
            "\n",
            "         [[1.9907, 1.8761, 2.1324, 2.2928],\n",
            "          [2.0541, 1.9274, 1.9185, 1.6262],\n",
            "          [2.3017, 1.7480, 2.1001, 2.2033]]],\n",
            "\n",
            "\n",
            "        [[[1.4972, 1.7565, 2.2128, 2.2532],\n",
            "          [1.1498, 1.7069, 1.9693, 1.8839],\n",
            "          [1.6100, 2.2199, 2.6329, 2.3931]],\n",
            "\n",
            "         [[1.3862, 2.0721, 1.4579, 1.9912],\n",
            "          [1.4352, 1.9664, 1.5344, 1.9646],\n",
            "          [1.7081, 2.1236, 1.4281, 2.0013]],\n",
            "\n",
            "         [[1.3660, 1.3544, 1.5369, 1.2537],\n",
            "          [1.3153, 1.2731, 1.2252, 1.2986],\n",
            "          [1.4552, 1.3506, 1.7037, 1.8397]],\n",
            "\n",
            "         [[0.7592, 1.9034, 0.9225, 1.9879],\n",
            "          [0.5204, 1.8603, 0.7563, 1.7551],\n",
            "          [0.6803, 2.2796, 0.9587, 1.9169]],\n",
            "\n",
            "         [[2.5043, 2.5916, 1.5746, 1.9846],\n",
            "          [2.1474, 2.4011, 1.2886, 1.7651],\n",
            "          [2.7819, 3.0605, 1.9538, 2.4110]],\n",
            "\n",
            "         [[2.4038, 2.0394, 1.9445, 1.7580],\n",
            "          [2.4787, 1.7813, 1.8646, 1.5731],\n",
            "          [2.7546, 1.8719, 2.1201, 1.6438]],\n",
            "\n",
            "         [[1.1357, 1.7156, 1.0679, 2.0401],\n",
            "          [1.3599, 1.7783, 0.9009, 2.0826],\n",
            "          [1.2691, 2.0981, 1.2093, 2.5655]],\n",
            "\n",
            "         [[2.2544, 2.1435, 2.2170, 2.0074],\n",
            "          [2.4203, 1.9630, 2.1949, 1.9674],\n",
            "          [2.5938, 2.1992, 2.4307, 2.4385]]],\n",
            "\n",
            "\n",
            "        [[[0.8554, 1.9588, 2.2239, 1.7257],\n",
            "          [1.3530, 1.8710, 2.2432, 2.1649],\n",
            "          [1.8580, 1.5155, 2.0235, 2.5805]],\n",
            "\n",
            "         [[1.4157, 1.2390, 1.2043, 1.5498],\n",
            "          [1.4418, 1.6491, 1.0650, 1.7227],\n",
            "          [1.3073, 2.1282, 0.9549, 1.9395]],\n",
            "\n",
            "         [[0.9965, 0.9617, 1.0333, 1.4911],\n",
            "          [1.0971, 1.0704, 1.4537, 1.4227],\n",
            "          [1.1860, 1.2146, 1.8387, 1.0321]],\n",
            "\n",
            "         [[0.5620, 1.9705, 0.6821, 1.6769],\n",
            "          [0.6375, 1.9423, 0.8311, 1.7624],\n",
            "          [0.7531, 1.7085, 0.9787, 1.8944]],\n",
            "\n",
            "         [[2.3716, 2.6032, 1.8688, 1.9413],\n",
            "          [2.4746, 2.6466, 1.8257, 2.1455],\n",
            "          [2.4204, 2.4334, 1.5323, 2.1323]],\n",
            "\n",
            "         [[2.1365, 1.4437, 2.0847, 0.9280],\n",
            "          [2.2087, 1.6785, 1.8387, 1.3355],\n",
            "          [2.1359, 2.0441, 1.4593, 1.8891]],\n",
            "\n",
            "         [[1.1492, 1.3773, 1.1239, 2.0541],\n",
            "          [0.9181, 1.5273, 1.1175, 2.0104],\n",
            "          [0.6167, 1.5281, 1.0169, 1.6954]],\n",
            "\n",
            "         [[2.0298, 1.6053, 2.0197, 2.5618],\n",
            "          [2.0651, 1.9048, 1.9846, 2.0951],\n",
            "          [1.9632, 2.2298, 1.8497, 1.3133]]],\n",
            "\n",
            "\n",
            "        [[[1.7980, 2.2895, 2.8828, 2.5920],\n",
            "          [0.9325, 1.2127, 1.4950, 1.7382],\n",
            "          [1.2609, 1.9196, 2.2179, 2.1030]],\n",
            "\n",
            "         [[1.6543, 2.3439, 1.7307, 2.1463],\n",
            "          [1.0103, 1.1581, 0.7515, 1.4551],\n",
            "          [1.4809, 1.3676, 0.7572, 1.5381]],\n",
            "\n",
            "         [[1.6711, 1.5883, 1.8597, 1.7889],\n",
            "          [0.6841, 0.7770, 1.0137, 0.6686],\n",
            "          [0.8954, 0.8580, 1.3998, 1.5234]],\n",
            "\n",
            "         [[0.9416, 2.3583, 1.1094, 2.2494],\n",
            "          [0.5434, 1.3595, 0.6258, 1.5593],\n",
            "          [0.5259, 1.9462, 0.7580, 1.5734]],\n",
            "\n",
            "         [[3.1177, 3.2378, 2.0973, 2.4433],\n",
            "          [1.8519, 1.8722, 1.3288, 1.5465],\n",
            "          [2.4057, 2.6486, 1.9560, 2.2490]],\n",
            "\n",
            "         [[2.8520, 2.2412, 2.4276, 1.9130],\n",
            "          [1.5065, 1.5037, 1.3914, 1.0709],\n",
            "          [2.0653, 1.4079, 1.7046, 1.0502]],\n",
            "\n",
            "         [[1.3724, 2.1658, 1.3471, 2.6493],\n",
            "          [0.5728, 0.7848, 0.8627, 1.1623],\n",
            "          [0.7445, 1.3972, 1.1254, 1.9652]],\n",
            "\n",
            "         [[2.6211, 2.4025, 2.6806, 2.7109],\n",
            "          [1.4244, 1.5375, 1.4064, 1.4217],\n",
            "          [1.9340, 1.7379, 1.7902, 2.0722]]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n",
            "keys: tensor([[[[2.0725, 2.6693, 1.5328, 1.1760],\n",
            "          [2.2480, 2.0761, 1.2159, 0.7723],\n",
            "          [2.1862, 2.1194, 1.3513, 1.2371]],\n",
            "\n",
            "         [[1.1901, 1.6703, 1.0154, 1.5346],\n",
            "          [1.0776, 1.3035, 0.7239, 0.9797],\n",
            "          [1.3647, 1.3615, 0.7281, 1.2096]],\n",
            "\n",
            "         [[1.7443, 2.0166, 1.6476, 2.3332],\n",
            "          [1.4095, 2.0479, 1.6338, 2.1370],\n",
            "          [1.7671, 1.8529, 1.6592, 2.0643]],\n",
            "\n",
            "         [[1.1724, 2.0698, 0.7825, 1.3843],\n",
            "          [1.4568, 2.1535, 0.8681, 1.4930],\n",
            "          [1.3700, 2.4348, 0.8699, 1.4864]],\n",
            "\n",
            "         [[1.5884, 1.7679, 2.1080, 1.6204],\n",
            "          [1.1243, 1.3599, 1.7852, 1.3703],\n",
            "          [1.3717, 1.7894, 1.6954, 1.7341]],\n",
            "\n",
            "         [[2.0082, 2.0340, 1.3686, 2.1381],\n",
            "          [2.0391, 1.8077, 0.8023, 1.8485],\n",
            "          [1.8567, 1.7918, 0.8239, 1.8964]],\n",
            "\n",
            "         [[0.9281, 0.9671, 1.4425, 1.5969],\n",
            "          [1.0258, 0.8680, 1.0929, 1.5035],\n",
            "          [1.1059, 0.4483, 1.4385, 1.4125]],\n",
            "\n",
            "         [[1.0980, 1.1845, 1.0997, 0.7961],\n",
            "          [1.0084, 1.1736, 1.2759, 0.9716],\n",
            "          [1.3733, 1.3748, 1.0612, 1.0409]]],\n",
            "\n",
            "\n",
            "        [[[2.4929, 2.5020, 1.4337, 1.0279],\n",
            "          [2.4950, 2.1240, 1.2611, 1.0472],\n",
            "          [2.6632, 2.5724, 1.6060, 1.4271]],\n",
            "\n",
            "         [[1.3960, 1.6123, 0.9690, 1.3567],\n",
            "          [1.2807, 1.3387, 0.7568, 1.0932],\n",
            "          [1.9716, 1.7633, 1.0201, 1.6047]],\n",
            "\n",
            "         [[1.7155, 2.2944, 1.7568, 2.4132],\n",
            "          [1.5988, 2.1976, 1.7698, 2.3425],\n",
            "          [2.1822, 2.2314, 1.8177, 2.3025]],\n",
            "\n",
            "         [[1.6203, 2.3926, 0.9239, 1.6201],\n",
            "          [1.5998, 2.5192, 0.9165, 1.6492],\n",
            "          [1.8476, 2.8593, 1.0383, 1.7343]],\n",
            "\n",
            "         [[1.4549, 1.6203, 2.1078, 1.5840],\n",
            "          [1.2893, 1.5649, 1.8541, 1.6069],\n",
            "          [1.6940, 2.0430, 2.0624, 1.9566]],\n",
            "\n",
            "         [[2.2813, 2.0104, 1.1422, 2.1892],\n",
            "          [2.0360, 1.9208, 0.7248, 2.0904],\n",
            "          [2.3919, 1.9468, 1.2126, 2.2269]],\n",
            "\n",
            "         [[1.2202, 1.0220, 1.3529, 1.7197],\n",
            "          [1.2036, 0.7137, 1.1994, 1.5246],\n",
            "          [1.5296, 0.6817, 1.8076, 1.7862]],\n",
            "\n",
            "         [[1.2379, 1.4091, 1.4005, 1.0820],\n",
            "          [1.3444, 1.2454, 1.2339, 1.1330],\n",
            "          [1.6831, 1.9695, 1.4701, 1.3441]]],\n",
            "\n",
            "\n",
            "        [[[1.7951, 2.4289, 1.5969, 1.4725],\n",
            "          [2.1075, 2.3445, 1.4984, 1.1520],\n",
            "          [2.4182, 2.1842, 1.2719, 0.5616]],\n",
            "\n",
            "         [[1.5155, 1.6015, 0.8656, 1.5698],\n",
            "          [1.5724, 1.5818, 0.8615, 1.3832],\n",
            "          [1.3182, 1.4566, 0.8181, 1.0082]],\n",
            "\n",
            "         [[2.0515, 1.5165, 1.5213, 1.8205],\n",
            "          [1.9011, 1.7941, 1.5742, 1.8863],\n",
            "          [1.4581, 2.1832, 1.6208, 2.0553]],\n",
            "\n",
            "         [[1.0670, 2.2174, 0.8027, 1.2588],\n",
            "          [1.4314, 2.2962, 0.9078, 1.4166],\n",
            "          [1.7564, 2.1688, 0.9733, 1.5625]],\n",
            "\n",
            "         [[1.6189, 2.1118, 1.7193, 1.8765],\n",
            "          [1.4346, 1.8292, 1.7845, 1.6838],\n",
            "          [1.0802, 1.2575, 1.8852, 1.2599]],\n",
            "\n",
            "         [[1.7961, 1.7333, 1.2750, 1.7709],\n",
            "          [2.1199, 1.7173, 1.1793, 1.7732],\n",
            "          [2.4327, 1.7454, 0.9867, 1.7796]],\n",
            "\n",
            "         [[0.9722, 0.3725, 1.8309, 1.4160],\n",
            "          [1.1514, 0.6379, 1.6570, 1.5766],\n",
            "          [1.2068, 1.1252, 1.1794, 1.7236]],\n",
            "\n",
            "         [[1.3233, 1.5967, 0.9414, 0.8632],\n",
            "          [1.2379, 1.7280, 1.2895, 1.0309],\n",
            "          [0.9189, 1.5533, 1.6558, 1.1026]]],\n",
            "\n",
            "\n",
            "        [[[2.8240, 3.0928, 1.7891, 1.5372],\n",
            "          [1.5026, 1.8951, 1.1958, 0.6092],\n",
            "          [1.8506, 2.1574, 1.5028, 1.1870]],\n",
            "\n",
            "         [[1.9949, 2.0685, 1.3062, 1.9568],\n",
            "          [0.7824, 1.1835, 0.5777, 0.8710],\n",
            "          [1.6749, 1.5118, 0.7476, 1.3303]],\n",
            "\n",
            "         [[2.2905, 2.5551, 1.9291, 2.7255],\n",
            "          [1.2678, 1.3986, 1.3133, 1.5277],\n",
            "          [1.9857, 1.4410, 1.4415, 1.4884]],\n",
            "\n",
            "         [[1.8582, 2.8467, 1.0200, 1.8010],\n",
            "          [0.9217, 1.5300, 0.7198, 1.0708],\n",
            "          [1.3264, 2.2313, 0.9046, 1.2827]],\n",
            "\n",
            "         [[1.9906, 2.1392, 2.5039, 2.0124],\n",
            "          [0.9370, 1.3011, 1.4342, 1.1767],\n",
            "          [1.3602, 1.9232, 1.5141, 1.7201]],\n",
            "\n",
            "         [[2.5898, 2.2546, 1.6236, 2.6438],\n",
            "          [1.7128, 1.4915, 0.8987, 1.2658],\n",
            "          [2.0041, 1.4817, 1.1338, 1.4409]],\n",
            "\n",
            "         [[1.5511, 1.0736, 1.8679, 2.0017],\n",
            "          [0.6071, 0.6953, 1.1372, 1.2614],\n",
            "          [1.1088, 0.3544, 1.8241, 1.4606]],\n",
            "\n",
            "         [[1.6955, 1.8856, 1.5386, 1.2892],\n",
            "          [0.5704, 1.0864, 1.0356, 0.6089],\n",
            "          [1.2215, 1.9439, 1.2283, 1.0116]]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n",
            "values: tensor([[[[1.5747, 1.7492],\n",
            "          [1.3344, 1.8350],\n",
            "          [1.4778, 1.7851]],\n",
            "\n",
            "         [[1.0093, 1.3817],\n",
            "          [1.2377, 1.2117],\n",
            "          [1.2499, 1.0589]],\n",
            "\n",
            "         [[1.6020, 1.0224],\n",
            "          [1.5602, 0.8358],\n",
            "          [1.5025, 0.7863]],\n",
            "\n",
            "         [[2.4326, 2.1812],\n",
            "          [1.9088, 1.9548],\n",
            "          [2.1832, 1.9427]],\n",
            "\n",
            "         [[2.1698, 2.3601],\n",
            "          [2.0842, 1.9954],\n",
            "          [2.1401, 2.2258]],\n",
            "\n",
            "         [[2.4991, 1.4703],\n",
            "          [2.0578, 1.2332],\n",
            "          [2.0615, 1.1764]],\n",
            "\n",
            "         [[2.6198, 1.0720],\n",
            "          [2.1335, 1.1735],\n",
            "          [2.1899, 0.8560]],\n",
            "\n",
            "         [[1.1448, 1.2390],\n",
            "          [1.1031, 0.9995],\n",
            "          [1.4096, 0.9710]]],\n",
            "\n",
            "\n",
            "        [[[1.6333, 2.0743],\n",
            "          [1.5914, 1.9850],\n",
            "          [1.7852, 2.2712]],\n",
            "\n",
            "         [[1.3902, 1.4824],\n",
            "          [1.3333, 1.2764],\n",
            "          [1.7475, 1.4162]],\n",
            "\n",
            "         [[1.8033, 1.1089],\n",
            "          [1.6332, 0.8113],\n",
            "          [1.9536, 1.2804]],\n",
            "\n",
            "         [[2.2536, 2.2194],\n",
            "          [2.1555, 2.1599],\n",
            "          [2.4108, 2.1548]],\n",
            "\n",
            "         [[2.4051, 2.2898],\n",
            "          [2.3002, 2.2594],\n",
            "          [2.6475, 2.4405]],\n",
            "\n",
            "         [[2.4014, 1.4652],\n",
            "          [2.1777, 1.2872],\n",
            "          [2.3610, 1.4348]],\n",
            "\n",
            "         [[2.5075, 1.3683],\n",
            "          [2.2989, 1.1178],\n",
            "          [2.5001, 1.3284]],\n",
            "\n",
            "         [[1.2931, 1.2840],\n",
            "          [1.3202, 0.9923],\n",
            "          [1.7636, 1.4349]]],\n",
            "\n",
            "\n",
            "        [[[1.3954, 1.5883],\n",
            "          [1.3592, 1.8547],\n",
            "          [1.2560, 2.0755]],\n",
            "\n",
            "         [[1.1389, 0.9657],\n",
            "          [1.4325, 1.1236],\n",
            "          [1.5854, 1.3515]],\n",
            "\n",
            "         [[1.4568, 0.9618],\n",
            "          [1.6554, 1.1071],\n",
            "          [1.8069, 1.1608]],\n",
            "\n",
            "         [[2.3366, 1.7633],\n",
            "          [2.0807, 1.7739],\n",
            "          [1.7026, 1.8489]],\n",
            "\n",
            "         [[2.0188, 2.2448],\n",
            "          [2.1706, 2.0740],\n",
            "          [2.2329, 1.8096]],\n",
            "\n",
            "         [[2.1304, 1.1950],\n",
            "          [2.0730, 1.2338],\n",
            "          [2.0303, 1.2959]],\n",
            "\n",
            "         [[2.2612, 0.7031],\n",
            "          [2.1645, 1.0995],\n",
            "          [2.0610, 1.5831]],\n",
            "\n",
            "         [[1.4726, 1.1552],\n",
            "          [1.4482, 1.2563],\n",
            "          [1.1681, 1.2713]]],\n",
            "\n",
            "\n",
            "        [[[2.0769, 2.4145],\n",
            "          [0.8295, 1.3199],\n",
            "          [1.1327, 1.7041]],\n",
            "\n",
            "         [[1.6676, 1.7909],\n",
            "          [0.9145, 0.8050],\n",
            "          [1.4834, 0.8466]],\n",
            "\n",
            "         [[2.1427, 1.5032],\n",
            "          [1.2186, 0.7123],\n",
            "          [1.5410, 1.0781]],\n",
            "\n",
            "         [[2.7894, 2.5395],\n",
            "          [1.5882, 1.4196],\n",
            "          [1.8923, 1.4300]],\n",
            "\n",
            "         [[2.8820, 2.7457],\n",
            "          [1.5286, 1.5919],\n",
            "          [1.9885, 1.8747]],\n",
            "\n",
            "         [[2.8431, 1.7519],\n",
            "          [1.7093, 0.9805],\n",
            "          [1.7853, 1.0396]],\n",
            "\n",
            "         [[3.0050, 1.5547],\n",
            "          [1.7365, 0.8337],\n",
            "          [1.8606, 0.9177]],\n",
            "\n",
            "         [[1.7002, 1.6920],\n",
            "          [0.8610, 0.8666],\n",
            "          [1.5469, 1.2031]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "keys_transposed: tensor([[[[2.0725, 2.2480, 2.1862],\n",
            "          [2.6693, 2.0761, 2.1194],\n",
            "          [1.5328, 1.2159, 1.3513],\n",
            "          [1.1760, 0.7723, 1.2371]],\n",
            "\n",
            "         [[1.1901, 1.0776, 1.3647],\n",
            "          [1.6703, 1.3035, 1.3615],\n",
            "          [1.0154, 0.7239, 0.7281],\n",
            "          [1.5346, 0.9797, 1.2096]],\n",
            "\n",
            "         [[1.7443, 1.4095, 1.7671],\n",
            "          [2.0166, 2.0479, 1.8529],\n",
            "          [1.6476, 1.6338, 1.6592],\n",
            "          [2.3332, 2.1370, 2.0643]],\n",
            "\n",
            "         [[1.1724, 1.4568, 1.3700],\n",
            "          [2.0698, 2.1535, 2.4348],\n",
            "          [0.7825, 0.8681, 0.8699],\n",
            "          [1.3843, 1.4930, 1.4864]],\n",
            "\n",
            "         [[1.5884, 1.1243, 1.3717],\n",
            "          [1.7679, 1.3599, 1.7894],\n",
            "          [2.1080, 1.7852, 1.6954],\n",
            "          [1.6204, 1.3703, 1.7341]],\n",
            "\n",
            "         [[2.0082, 2.0391, 1.8567],\n",
            "          [2.0340, 1.8077, 1.7918],\n",
            "          [1.3686, 0.8023, 0.8239],\n",
            "          [2.1381, 1.8485, 1.8964]],\n",
            "\n",
            "         [[0.9281, 1.0258, 1.1059],\n",
            "          [0.9671, 0.8680, 0.4483],\n",
            "          [1.4425, 1.0929, 1.4385],\n",
            "          [1.5969, 1.5035, 1.4125]],\n",
            "\n",
            "         [[1.0980, 1.0084, 1.3733],\n",
            "          [1.1845, 1.1736, 1.3748],\n",
            "          [1.0997, 1.2759, 1.0612],\n",
            "          [0.7961, 0.9716, 1.0409]]],\n",
            "\n",
            "\n",
            "        [[[2.4929, 2.4950, 2.6632],\n",
            "          [2.5020, 2.1240, 2.5724],\n",
            "          [1.4337, 1.2611, 1.6060],\n",
            "          [1.0279, 1.0472, 1.4271]],\n",
            "\n",
            "         [[1.3960, 1.2807, 1.9716],\n",
            "          [1.6123, 1.3387, 1.7633],\n",
            "          [0.9690, 0.7568, 1.0201],\n",
            "          [1.3567, 1.0932, 1.6047]],\n",
            "\n",
            "         [[1.7155, 1.5988, 2.1822],\n",
            "          [2.2944, 2.1976, 2.2314],\n",
            "          [1.7568, 1.7698, 1.8177],\n",
            "          [2.4132, 2.3425, 2.3025]],\n",
            "\n",
            "         [[1.6203, 1.5998, 1.8476],\n",
            "          [2.3926, 2.5192, 2.8593],\n",
            "          [0.9239, 0.9165, 1.0383],\n",
            "          [1.6201, 1.6492, 1.7343]],\n",
            "\n",
            "         [[1.4549, 1.2893, 1.6940],\n",
            "          [1.6203, 1.5649, 2.0430],\n",
            "          [2.1078, 1.8541, 2.0624],\n",
            "          [1.5840, 1.6069, 1.9566]],\n",
            "\n",
            "         [[2.2813, 2.0360, 2.3919],\n",
            "          [2.0104, 1.9208, 1.9468],\n",
            "          [1.1422, 0.7248, 1.2126],\n",
            "          [2.1892, 2.0904, 2.2269]],\n",
            "\n",
            "         [[1.2202, 1.2036, 1.5296],\n",
            "          [1.0220, 0.7137, 0.6817],\n",
            "          [1.3529, 1.1994, 1.8076],\n",
            "          [1.7197, 1.5246, 1.7862]],\n",
            "\n",
            "         [[1.2379, 1.3444, 1.6831],\n",
            "          [1.4091, 1.2454, 1.9695],\n",
            "          [1.4005, 1.2339, 1.4701],\n",
            "          [1.0820, 1.1330, 1.3441]]],\n",
            "\n",
            "\n",
            "        [[[1.7951, 2.1075, 2.4182],\n",
            "          [2.4289, 2.3445, 2.1842],\n",
            "          [1.5969, 1.4984, 1.2719],\n",
            "          [1.4725, 1.1520, 0.5616]],\n",
            "\n",
            "         [[1.5155, 1.5724, 1.3182],\n",
            "          [1.6015, 1.5818, 1.4566],\n",
            "          [0.8656, 0.8615, 0.8181],\n",
            "          [1.5698, 1.3832, 1.0082]],\n",
            "\n",
            "         [[2.0515, 1.9011, 1.4581],\n",
            "          [1.5165, 1.7941, 2.1832],\n",
            "          [1.5213, 1.5742, 1.6208],\n",
            "          [1.8205, 1.8863, 2.0553]],\n",
            "\n",
            "         [[1.0670, 1.4314, 1.7564],\n",
            "          [2.2174, 2.2962, 2.1688],\n",
            "          [0.8027, 0.9078, 0.9733],\n",
            "          [1.2588, 1.4166, 1.5625]],\n",
            "\n",
            "         [[1.6189, 1.4346, 1.0802],\n",
            "          [2.1118, 1.8292, 1.2575],\n",
            "          [1.7193, 1.7845, 1.8852],\n",
            "          [1.8765, 1.6838, 1.2599]],\n",
            "\n",
            "         [[1.7961, 2.1199, 2.4327],\n",
            "          [1.7333, 1.7173, 1.7454],\n",
            "          [1.2750, 1.1793, 0.9867],\n",
            "          [1.7709, 1.7732, 1.7796]],\n",
            "\n",
            "         [[0.9722, 1.1514, 1.2068],\n",
            "          [0.3725, 0.6379, 1.1252],\n",
            "          [1.8309, 1.6570, 1.1794],\n",
            "          [1.4160, 1.5766, 1.7236]],\n",
            "\n",
            "         [[1.3233, 1.2379, 0.9189],\n",
            "          [1.5967, 1.7280, 1.5533],\n",
            "          [0.9414, 1.2895, 1.6558],\n",
            "          [0.8632, 1.0309, 1.1026]]],\n",
            "\n",
            "\n",
            "        [[[2.8240, 1.5026, 1.8506],\n",
            "          [3.0928, 1.8951, 2.1574],\n",
            "          [1.7891, 1.1958, 1.5028],\n",
            "          [1.5372, 0.6092, 1.1870]],\n",
            "\n",
            "         [[1.9949, 0.7824, 1.6749],\n",
            "          [2.0685, 1.1835, 1.5118],\n",
            "          [1.3062, 0.5777, 0.7476],\n",
            "          [1.9568, 0.8710, 1.3303]],\n",
            "\n",
            "         [[2.2905, 1.2678, 1.9857],\n",
            "          [2.5551, 1.3986, 1.4410],\n",
            "          [1.9291, 1.3133, 1.4415],\n",
            "          [2.7255, 1.5277, 1.4884]],\n",
            "\n",
            "         [[1.8582, 0.9217, 1.3264],\n",
            "          [2.8467, 1.5300, 2.2313],\n",
            "          [1.0200, 0.7198, 0.9046],\n",
            "          [1.8010, 1.0708, 1.2827]],\n",
            "\n",
            "         [[1.9906, 0.9370, 1.3602],\n",
            "          [2.1392, 1.3011, 1.9232],\n",
            "          [2.5039, 1.4342, 1.5141],\n",
            "          [2.0124, 1.1767, 1.7201]],\n",
            "\n",
            "         [[2.5898, 1.7128, 2.0041],\n",
            "          [2.2546, 1.4915, 1.4817],\n",
            "          [1.6236, 0.8987, 1.1338],\n",
            "          [2.6438, 1.2658, 1.4409]],\n",
            "\n",
            "         [[1.5511, 0.6071, 1.1088],\n",
            "          [1.0736, 0.6953, 0.3544],\n",
            "          [1.8679, 1.1372, 1.8241],\n",
            "          [2.0017, 1.2614, 1.4606]],\n",
            "\n",
            "         [[1.6955, 0.5704, 1.2215],\n",
            "          [1.8856, 1.0864, 1.9439],\n",
            "          [1.5386, 1.0356, 1.2283],\n",
            "          [1.2892, 0.6089, 1.0116]]]], device='cuda:0',\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "scores: tensor([[[[12.3304, 10.0708, 11.2578],\n",
            "          [11.6124,  9.5832, 10.7367],\n",
            "          [11.8240,  9.5869, 10.6742]],\n",
            "\n",
            "         [[ 8.4796,  6.3064,  7.1720],\n",
            "          [ 8.6811,  6.4719,  7.3716],\n",
            "          [ 8.5404,  6.4007,  7.3231]],\n",
            "\n",
            "         [[ 9.1315,  8.5330,  8.6755],\n",
            "          [ 8.7913,  8.2309,  8.3733],\n",
            "          [ 9.2554,  8.6128,  8.7340]],\n",
            "\n",
            "         [[ 8.0553,  8.7181,  9.1449],\n",
            "          [ 7.1566,  7.7209,  8.1243],\n",
            "          [ 7.2522,  7.7756,  8.2612]],\n",
            "\n",
            "         [[14.4207, 11.3360, 13.4777],\n",
            "          [12.7139,  9.9978, 11.9772],\n",
            "          [13.6842, 10.7798, 12.8751]],\n",
            "\n",
            "         [[14.1584, 12.1778, 11.8718],\n",
            "          [13.5940, 11.8639, 11.5553],\n",
            "          [13.0933, 11.3764, 11.0232]],\n",
            "\n",
            "         [[ 6.9371,  6.3616,  6.0890],\n",
            "          [ 6.3570,  5.8407,  5.4652],\n",
            "          [ 7.5011,  6.9431,  6.5036]],\n",
            "\n",
            "         [[ 8.5785,  9.1576,  9.9626],\n",
            "          [ 7.9430,  8.3612,  9.1995],\n",
            "          [ 8.6614,  9.1926, 10.0862]]],\n",
            "\n",
            "\n",
            "        [[[13.6156, 12.6164, 15.2750],\n",
            "          [11.8969, 10.9505, 13.3042],\n",
            "          [15.8025, 14.5584, 17.6418]],\n",
            "\n",
            "         [[ 9.3902,  7.8293, 11.0693],\n",
            "          [ 9.3261,  7.7793, 11.0147],\n",
            "          [ 9.9074,  8.2989, 11.7805]],\n",
            "\n",
            "         [[11.1764, 10.8173, 11.6834],\n",
            "          [10.4636, 10.1110, 10.9281],\n",
            "          [13.0277, 12.6192, 13.5218]],\n",
            "\n",
            "         [[ 9.8571, 10.1336, 11.2506],\n",
            "          [ 8.8365,  9.1068, 10.1100],\n",
            "          [10.5477, 10.8710, 12.0948]],\n",
            "\n",
            "         [[14.3055, 13.3929, 16.6673],\n",
            "          [12.5269, 11.7515, 14.6540],\n",
            "          [16.9437, 15.8727, 19.7116]],\n",
            "\n",
            "         [[15.6535, 13.8959, 15.9927],\n",
            "          [14.8094, 13.1081, 15.1607],\n",
            "          [16.0675, 14.1768, 16.4642]],\n",
            "\n",
            "         [[ 8.0920,  6.9826,  8.4810],\n",
            "          [ 8.2769,  7.1618,  8.6409],\n",
            "          [ 9.7406,  8.3868, 10.1399]],\n",
            "\n",
            "         [[11.0880, 10.7105, 13.9737],\n",
            "          [10.9647, 10.6361, 13.8111],\n",
            "          [12.3524, 11.9884, 15.5484]]],\n",
            "\n",
            "\n",
            "        [[[12.3856, 11.7153, 10.1446],\n",
            "          [13.7432, 13.0930, 11.4274],\n",
            "          [14.0475, 13.4736, 11.8261]],\n",
            "\n",
            "         [[ 7.6052,  7.3672,  6.2185],\n",
            "          [ 8.4522,  8.1760,  6.9105],\n",
            "          [ 9.2609,  8.9275,  7.5597]],\n",
            "\n",
            "         [[ 7.7889,  8.0589,  8.2918],\n",
            "          [ 8.6753,  8.9781,  9.2167],\n",
            "          [ 8.9508,  9.2750,  9.4823]],\n",
            "\n",
            "         [[ 7.6274,  8.3237,  8.5448],\n",
            "          [ 7.8727,  8.6234,  8.8949],\n",
            "          [ 7.7621,  8.5730,  8.9407]],\n",
            "\n",
            "         [[16.1928, 14.7680, 11.8043],\n",
            "          [16.7601, 15.2620, 12.1461],\n",
            "          [15.6929, 14.2484, 11.2497]],\n",
            "\n",
            "         [[10.6412, 11.1124, 11.4257],\n",
            "          [11.5858, 12.1010, 12.4935],\n",
            "          [12.5854, 13.1088, 13.5654]],\n",
            "\n",
            "         [[ 6.5969,  7.3026,  7.8026],\n",
            "          [ 6.3544,  7.0527,  7.6096],\n",
            "          [ 5.4314,  6.0428,  6.5852]],\n",
            "\n",
            "         [[ 9.3618, 10.5321, 10.5274],\n",
            "          [ 9.4509, 10.5670, 10.4525],\n",
            "          [ 9.0332, 10.0226,  9.7783]]],\n",
            "\n",
            "\n",
            "        [[[21.3005, 12.0669, 15.6758],\n",
            "          [11.7305,  6.5459,  8.6518],\n",
            "          [16.6984,  9.4658, 12.3041]],\n",
            "\n",
            "         [[14.6086,  6.9373, 10.4633],\n",
            "          [ 8.2399,  3.8626,  5.9406],\n",
            "          [ 9.7818,  4.5542,  7.1602]],\n",
            "\n",
            "         [[16.3494,  9.5153, 10.9504],\n",
            "          [ 7.3303,  4.3068,  4.9346],\n",
            "          [11.0954,  6.5007,  7.2994]],\n",
            "\n",
            "         [[13.6458,  7.6835, 10.4001],\n",
            "          [ 8.3263,  4.7011,  6.3204],\n",
            "          [10.1241,  5.6929,  7.7440]],\n",
            "\n",
            "         [[23.3007, 13.0171, 17.8458],\n",
            "          [14.1307,  7.8967, 10.7915],\n",
            "          [19.8779, 11.1519, 15.1959]],\n",
            "\n",
            "         [[21.4385, 12.8309, 14.5454],\n",
            "          [12.3822,  7.4291,  8.3678],\n",
            "          [14.0673,  8.4987,  9.6711]],\n",
            "\n",
            "         [[12.2732,  7.2128,  8.6160],\n",
            "          [ 5.6690,  3.3406,  4.1845],\n",
            "          [ 8.6908,  5.1822,  6.2440]],\n",
            "\n",
            "         [[16.5934,  8.5320, 13.9067],\n",
            "          [ 9.3108,  4.8050,  7.8942],\n",
            "          [11.9819,  6.1070, 10.0358]]]], device='cuda:0',\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "scores: torch.Size([4, 8, 3, 3])\n",
            "masks: torch.Size([4, 1, 3, 3])\n",
            "masked scores: tensor([[[[ 1.2330e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.1612e+01,  9.5832e+00, -1.0000e+09],\n",
            "          [ 1.1824e+01,  9.5869e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 8.4796e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.6811e+00,  6.4719e+00, -1.0000e+09],\n",
            "          [ 8.5404e+00,  6.4007e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 9.1315e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.7913e+00,  8.2309e+00, -1.0000e+09],\n",
            "          [ 9.2554e+00,  8.6128e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 8.0553e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 7.1566e+00,  7.7209e+00, -1.0000e+09],\n",
            "          [ 7.2522e+00,  7.7756e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.4421e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.2714e+01,  9.9978e+00, -1.0000e+09],\n",
            "          [ 1.3684e+01,  1.0780e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.4158e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.3594e+01,  1.1864e+01, -1.0000e+09],\n",
            "          [ 1.3093e+01,  1.1376e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 6.9371e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 6.3570e+00,  5.8407e+00, -1.0000e+09],\n",
            "          [ 7.5011e+00,  6.9431e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 8.5785e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 7.9430e+00,  8.3612e+00, -1.0000e+09],\n",
            "          [ 8.6614e+00,  9.1926e+00, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3616e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.1897e+01,  1.0951e+01, -1.0000e+09],\n",
            "          [ 1.5802e+01,  1.4558e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 9.3902e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 9.3261e+00,  7.7793e+00, -1.0000e+09],\n",
            "          [ 9.9074e+00,  8.2989e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.1176e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.0464e+01,  1.0111e+01, -1.0000e+09],\n",
            "          [ 1.3028e+01,  1.2619e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 9.8571e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.8365e+00,  9.1068e+00, -1.0000e+09],\n",
            "          [ 1.0548e+01,  1.0871e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.4305e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.2527e+01,  1.1752e+01, -1.0000e+09],\n",
            "          [ 1.6944e+01,  1.5873e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.5653e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.4809e+01,  1.3108e+01, -1.0000e+09],\n",
            "          [ 1.6068e+01,  1.4177e+01, -1.0000e+09]],\n",
            "\n",
            "         [[ 8.0920e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.2769e+00,  7.1618e+00, -1.0000e+09],\n",
            "          [ 9.7406e+00,  8.3868e+00, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.1088e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.0965e+01,  1.0636e+01, -1.0000e+09],\n",
            "          [ 1.2352e+01,  1.1988e+01, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2386e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.3743e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.4048e+01, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 7.6052e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.4522e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 9.2609e+00, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 7.7889e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.6753e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.9508e+00, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 7.6274e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 7.8727e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 7.7621e+00, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.6193e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.6760e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.5693e+01, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 1.0641e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.1586e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.2585e+01, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 6.5969e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 6.3544e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 5.4314e+00, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "         [[ 9.3618e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 9.4509e+00, -1.0000e+09, -1.0000e+09],\n",
            "          [ 9.0332e+00, -1.0000e+09, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1301e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.1730e+01,  6.5459e+00, -1.0000e+09],\n",
            "          [ 1.6698e+01,  9.4658e+00,  1.2304e+01]],\n",
            "\n",
            "         [[ 1.4609e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.2399e+00,  3.8626e+00, -1.0000e+09],\n",
            "          [ 9.7818e+00,  4.5542e+00,  7.1602e+00]],\n",
            "\n",
            "         [[ 1.6349e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 7.3303e+00,  4.3068e+00, -1.0000e+09],\n",
            "          [ 1.1095e+01,  6.5007e+00,  7.2994e+00]],\n",
            "\n",
            "         [[ 1.3646e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 8.3263e+00,  4.7011e+00, -1.0000e+09],\n",
            "          [ 1.0124e+01,  5.6929e+00,  7.7440e+00]],\n",
            "\n",
            "         [[ 2.3301e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.4131e+01,  7.8967e+00, -1.0000e+09],\n",
            "          [ 1.9878e+01,  1.1152e+01,  1.5196e+01]],\n",
            "\n",
            "         [[ 2.1438e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 1.2382e+01,  7.4291e+00, -1.0000e+09],\n",
            "          [ 1.4067e+01,  8.4987e+00,  9.6711e+00]],\n",
            "\n",
            "         [[ 1.2273e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 5.6690e+00,  3.3406e+00, -1.0000e+09],\n",
            "          [ 8.6908e+00,  5.1822e+00,  6.2440e+00]],\n",
            "\n",
            "         [[ 1.6593e+01, -1.0000e+09, -1.0000e+09],\n",
            "          [ 9.3108e+00,  4.8050e+00, -1.0000e+09],\n",
            "          [ 1.1982e+01,  6.1070e+00,  1.0036e+01]]]], device='cuda:0',\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "scaled_scores: tensor([[[[ 6.1652e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.8062e+00,  4.7916e+00, -5.0000e+08],\n",
            "          [ 5.9120e+00,  4.7934e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.2398e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.3405e+00,  3.2360e+00, -5.0000e+08],\n",
            "          [ 4.2702e+00,  3.2003e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.5658e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.3957e+00,  4.1154e+00, -5.0000e+08],\n",
            "          [ 4.6277e+00,  4.3064e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.0276e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.5783e+00,  3.8604e+00, -5.0000e+08],\n",
            "          [ 3.6261e+00,  3.8878e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 7.2104e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.3570e+00,  4.9989e+00, -5.0000e+08],\n",
            "          [ 6.8421e+00,  5.3899e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 7.0792e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.7970e+00,  5.9320e+00, -5.0000e+08],\n",
            "          [ 6.5466e+00,  5.6882e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 3.4685e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.1785e+00,  2.9204e+00, -5.0000e+08],\n",
            "          [ 3.7505e+00,  3.4715e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.2892e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.9715e+00,  4.1806e+00, -5.0000e+08],\n",
            "          [ 4.3307e+00,  4.5963e+00, -5.0000e+08]]],\n",
            "\n",
            "\n",
            "        [[[ 6.8078e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.9484e+00,  5.4753e+00, -5.0000e+08],\n",
            "          [ 7.9012e+00,  7.2792e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.6951e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.6631e+00,  3.8897e+00, -5.0000e+08],\n",
            "          [ 4.9537e+00,  4.1495e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 5.5882e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.2318e+00,  5.0555e+00, -5.0000e+08],\n",
            "          [ 6.5138e+00,  6.3096e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.9286e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.4183e+00,  4.5534e+00, -5.0000e+08],\n",
            "          [ 5.2738e+00,  5.4355e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 7.1527e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.2634e+00,  5.8758e+00, -5.0000e+08],\n",
            "          [ 8.4718e+00,  7.9363e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 7.8267e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 7.4047e+00,  6.5540e+00, -5.0000e+08],\n",
            "          [ 8.0338e+00,  7.0884e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.0460e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.1385e+00,  3.5809e+00, -5.0000e+08],\n",
            "          [ 4.8703e+00,  4.1934e+00, -5.0000e+08]],\n",
            "\n",
            "         [[ 5.5440e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.4824e+00,  5.3181e+00, -5.0000e+08],\n",
            "          [ 6.1762e+00,  5.9942e+00, -5.0000e+08]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1928e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.8716e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 7.0238e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 3.8026e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.2261e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.6304e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 3.8945e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.3376e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.4754e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 3.8137e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.9363e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.8811e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 8.0964e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 8.3800e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 7.8465e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 5.3206e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.7929e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.2927e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 3.2984e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.1772e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 2.7157e+00, -5.0000e+08, -5.0000e+08]],\n",
            "\n",
            "         [[ 4.6809e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.7254e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.5166e+00, -5.0000e+08, -5.0000e+08]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0650e+01, -5.0000e+08, -5.0000e+08],\n",
            "          [ 5.8652e+00,  3.2730e+00, -5.0000e+08],\n",
            "          [ 8.3492e+00,  4.7329e+00,  6.1521e+00]],\n",
            "\n",
            "         [[ 7.3043e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.1200e+00,  1.9313e+00, -5.0000e+08],\n",
            "          [ 4.8909e+00,  2.2771e+00,  3.5801e+00]],\n",
            "\n",
            "         [[ 8.1747e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 3.6652e+00,  2.1534e+00, -5.0000e+08],\n",
            "          [ 5.5477e+00,  3.2503e+00,  3.6497e+00]],\n",
            "\n",
            "         [[ 6.8229e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.1632e+00,  2.3505e+00, -5.0000e+08],\n",
            "          [ 5.0621e+00,  2.8464e+00,  3.8720e+00]],\n",
            "\n",
            "         [[ 1.1650e+01, -5.0000e+08, -5.0000e+08],\n",
            "          [ 7.0653e+00,  3.9484e+00, -5.0000e+08],\n",
            "          [ 9.9389e+00,  5.5760e+00,  7.5979e+00]],\n",
            "\n",
            "         [[ 1.0719e+01, -5.0000e+08, -5.0000e+08],\n",
            "          [ 6.1911e+00,  3.7145e+00, -5.0000e+08],\n",
            "          [ 7.0336e+00,  4.2493e+00,  4.8356e+00]],\n",
            "\n",
            "         [[ 6.1366e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 2.8345e+00,  1.6703e+00, -5.0000e+08],\n",
            "          [ 4.3454e+00,  2.5911e+00,  3.1220e+00]],\n",
            "\n",
            "         [[ 8.2967e+00, -5.0000e+08, -5.0000e+08],\n",
            "          [ 4.6554e+00,  2.4025e+00, -5.0000e+08],\n",
            "          [ 5.9909e+00,  3.0535e+00,  5.0179e+00]]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "softmax_scores: tensor([[[[1.0000, 0.0000, 0.0000],\n",
            "          [0.7339, 0.2661, 0.0000],\n",
            "          [0.7537, 0.2463, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.7511, 0.2489, 0.0000],\n",
            "          [0.7446, 0.2554, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.5696, 0.4304, 0.0000],\n",
            "          [0.5796, 0.4204, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.4299, 0.5701, 0.0000],\n",
            "          [0.4349, 0.5651, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.7954, 0.2046, 0.0000],\n",
            "          [0.8103, 0.1897, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.7037, 0.2963, 0.0000],\n",
            "          [0.7023, 0.2977, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.5642, 0.4358, 0.0000],\n",
            "          [0.5693, 0.4307, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.4479, 0.5521, 0.0000],\n",
            "          [0.4340, 0.5660, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000],\n",
            "          [0.6161, 0.3839, 0.0000],\n",
            "          [0.6507, 0.3493, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.6843, 0.3157, 0.0000],\n",
            "          [0.6909, 0.3091, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.5440, 0.4560, 0.0000],\n",
            "          [0.5509, 0.4491, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.4663, 0.5337, 0.0000],\n",
            "          [0.4597, 0.5403, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.5957, 0.4043, 0.0000],\n",
            "          [0.6308, 0.3692, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.7007, 0.2993, 0.0000],\n",
            "          [0.7202, 0.2798, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.6359, 0.3641, 0.0000],\n",
            "          [0.6630, 0.3370, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.5410, 0.4590, 0.0000],\n",
            "          [0.5454, 0.4546, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000],\n",
            "          [1.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000],\n",
            "          [0.9304, 0.0696, 0.0000],\n",
            "          [0.8787, 0.0236, 0.0976]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.8992, 0.1008, 0.0000],\n",
            "          [0.7447, 0.0546, 0.2008]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.8193, 0.1807, 0.0000],\n",
            "          [0.7997, 0.0804, 0.1199]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.8597, 0.1403, 0.0000],\n",
            "          [0.7076, 0.0772, 0.2152]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.9576, 0.0424, 0.0000],\n",
            "          [0.9017, 0.0115, 0.0868]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.9225, 0.0775, 0.0000],\n",
            "          [0.8527, 0.0527, 0.0947]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.7621, 0.2379, 0.0000],\n",
            "          [0.6815, 0.1179, 0.2005]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000],\n",
            "          [0.9049, 0.0951, 0.0000],\n",
            "          [0.6988, 0.0370, 0.2641]]]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "softmax_socres shape: torch.Size([4, 8, 3, 3])\n",
            "values: tensor([[[[1.5747, 1.7492],\n",
            "          [1.3344, 1.8350],\n",
            "          [1.4778, 1.7851]],\n",
            "\n",
            "         [[1.0093, 1.3817],\n",
            "          [1.2377, 1.2117],\n",
            "          [1.2499, 1.0589]],\n",
            "\n",
            "         [[1.6020, 1.0224],\n",
            "          [1.5602, 0.8358],\n",
            "          [1.5025, 0.7863]],\n",
            "\n",
            "         [[2.4326, 2.1812],\n",
            "          [1.9088, 1.9548],\n",
            "          [2.1832, 1.9427]],\n",
            "\n",
            "         [[2.1698, 2.3601],\n",
            "          [2.0842, 1.9954],\n",
            "          [2.1401, 2.2258]],\n",
            "\n",
            "         [[2.4991, 1.4703],\n",
            "          [2.0578, 1.2332],\n",
            "          [2.0615, 1.1764]],\n",
            "\n",
            "         [[2.6198, 1.0720],\n",
            "          [2.1335, 1.1735],\n",
            "          [2.1899, 0.8560]],\n",
            "\n",
            "         [[1.1448, 1.2390],\n",
            "          [1.1031, 0.9995],\n",
            "          [1.4096, 0.9710]]],\n",
            "\n",
            "\n",
            "        [[[1.6333, 2.0743],\n",
            "          [1.5914, 1.9850],\n",
            "          [1.7852, 2.2712]],\n",
            "\n",
            "         [[1.3902, 1.4824],\n",
            "          [1.3333, 1.2764],\n",
            "          [1.7475, 1.4162]],\n",
            "\n",
            "         [[1.8033, 1.1089],\n",
            "          [1.6332, 0.8113],\n",
            "          [1.9536, 1.2804]],\n",
            "\n",
            "         [[2.2536, 2.2194],\n",
            "          [2.1555, 2.1599],\n",
            "          [2.4108, 2.1548]],\n",
            "\n",
            "         [[2.4051, 2.2898],\n",
            "          [2.3002, 2.2594],\n",
            "          [2.6475, 2.4405]],\n",
            "\n",
            "         [[2.4014, 1.4652],\n",
            "          [2.1777, 1.2872],\n",
            "          [2.3610, 1.4348]],\n",
            "\n",
            "         [[2.5075, 1.3683],\n",
            "          [2.2989, 1.1178],\n",
            "          [2.5001, 1.3284]],\n",
            "\n",
            "         [[1.2931, 1.2840],\n",
            "          [1.3202, 0.9923],\n",
            "          [1.7636, 1.4349]]],\n",
            "\n",
            "\n",
            "        [[[1.3954, 1.5883],\n",
            "          [1.3592, 1.8547],\n",
            "          [1.2560, 2.0755]],\n",
            "\n",
            "         [[1.1389, 0.9657],\n",
            "          [1.4325, 1.1236],\n",
            "          [1.5854, 1.3515]],\n",
            "\n",
            "         [[1.4568, 0.9618],\n",
            "          [1.6554, 1.1071],\n",
            "          [1.8069, 1.1608]],\n",
            "\n",
            "         [[2.3366, 1.7633],\n",
            "          [2.0807, 1.7739],\n",
            "          [1.7026, 1.8489]],\n",
            "\n",
            "         [[2.0188, 2.2448],\n",
            "          [2.1706, 2.0740],\n",
            "          [2.2329, 1.8096]],\n",
            "\n",
            "         [[2.1304, 1.1950],\n",
            "          [2.0730, 1.2338],\n",
            "          [2.0303, 1.2959]],\n",
            "\n",
            "         [[2.2612, 0.7031],\n",
            "          [2.1645, 1.0995],\n",
            "          [2.0610, 1.5831]],\n",
            "\n",
            "         [[1.4726, 1.1552],\n",
            "          [1.4482, 1.2563],\n",
            "          [1.1681, 1.2713]]],\n",
            "\n",
            "\n",
            "        [[[2.0769, 2.4145],\n",
            "          [0.8295, 1.3199],\n",
            "          [1.1327, 1.7041]],\n",
            "\n",
            "         [[1.6676, 1.7909],\n",
            "          [0.9145, 0.8050],\n",
            "          [1.4834, 0.8466]],\n",
            "\n",
            "         [[2.1427, 1.5032],\n",
            "          [1.2186, 0.7123],\n",
            "          [1.5410, 1.0781]],\n",
            "\n",
            "         [[2.7894, 2.5395],\n",
            "          [1.5882, 1.4196],\n",
            "          [1.8923, 1.4300]],\n",
            "\n",
            "         [[2.8820, 2.7457],\n",
            "          [1.5286, 1.5919],\n",
            "          [1.9885, 1.8747]],\n",
            "\n",
            "         [[2.8431, 1.7519],\n",
            "          [1.7093, 0.9805],\n",
            "          [1.7853, 1.0396]],\n",
            "\n",
            "         [[3.0050, 1.5547],\n",
            "          [1.7365, 0.8337],\n",
            "          [1.8606, 0.9177]],\n",
            "\n",
            "         [[1.7002, 1.6920],\n",
            "          [0.8610, 0.8666],\n",
            "          [1.5469, 1.2031]]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "v_out shape torch.Size([4, 8, 3, 2])\n",
            "v_out: tensor([[[[1.5747, 1.7492],\n",
            "          [1.5108, 1.7720],\n",
            "          [1.5156, 1.7703]],\n",
            "\n",
            "         [[1.0093, 1.3817],\n",
            "          [1.0662, 1.3394],\n",
            "          [1.0676, 1.3383]],\n",
            "\n",
            "         [[1.6020, 1.0224],\n",
            "          [1.5840, 0.9421],\n",
            "          [1.5844, 0.9439]],\n",
            "\n",
            "         [[2.4326, 2.1812],\n",
            "          [2.1340, 2.0521],\n",
            "          [2.1367, 2.0533]],\n",
            "\n",
            "         [[2.1698, 2.3601],\n",
            "          [2.1523, 2.2855],\n",
            "          [2.1536, 2.2909]],\n",
            "\n",
            "         [[2.4991, 1.4703],\n",
            "          [2.3683, 1.4000],\n",
            "          [2.3677, 1.3997]],\n",
            "\n",
            "         [[2.6198, 1.0720],\n",
            "          [2.4079, 1.1163],\n",
            "          [2.4103, 1.1157]],\n",
            "\n",
            "         [[1.1448, 1.2390],\n",
            "          [1.1218, 1.1068],\n",
            "          [1.1212, 1.1034]]],\n",
            "\n",
            "\n",
            "        [[[1.6333, 2.0743],\n",
            "          [1.6172, 2.0401],\n",
            "          [1.6187, 2.0431]],\n",
            "\n",
            "         [[1.3902, 1.4824],\n",
            "          [1.3722, 1.4173],\n",
            "          [1.3726, 1.4187]],\n",
            "\n",
            "         [[1.8033, 1.1089],\n",
            "          [1.7257, 0.9732],\n",
            "          [1.7269, 0.9753]],\n",
            "\n",
            "         [[2.2536, 2.2194],\n",
            "          [2.2012, 2.1876],\n",
            "          [2.2006, 2.1872]],\n",
            "\n",
            "         [[2.4051, 2.2898],\n",
            "          [2.3627, 2.2775],\n",
            "          [2.3664, 2.2786]],\n",
            "\n",
            "         [[2.4014, 1.4652],\n",
            "          [2.3344, 1.4119],\n",
            "          [2.3388, 1.4154]],\n",
            "\n",
            "         [[2.5075, 1.3683],\n",
            "          [2.4316, 1.2771],\n",
            "          [2.4372, 1.2839]],\n",
            "\n",
            "         [[1.2931, 1.2840],\n",
            "          [1.3056, 1.1501],\n",
            "          [1.3054, 1.1513]]],\n",
            "\n",
            "\n",
            "        [[[1.3954, 1.5883],\n",
            "          [1.3954, 1.5883],\n",
            "          [1.3954, 1.5883]],\n",
            "\n",
            "         [[1.1389, 0.9657],\n",
            "          [1.1389, 0.9657],\n",
            "          [1.1389, 0.9657]],\n",
            "\n",
            "         [[1.4568, 0.9618],\n",
            "          [1.4568, 0.9618],\n",
            "          [1.4568, 0.9618]],\n",
            "\n",
            "         [[2.3366, 1.7633],\n",
            "          [2.3366, 1.7633],\n",
            "          [2.3366, 1.7633]],\n",
            "\n",
            "         [[2.0188, 2.2448],\n",
            "          [2.0188, 2.2448],\n",
            "          [2.0188, 2.2448]],\n",
            "\n",
            "         [[2.1304, 1.1950],\n",
            "          [2.1304, 1.1950],\n",
            "          [2.1304, 1.1950]],\n",
            "\n",
            "         [[2.2612, 0.7031],\n",
            "          [2.2612, 0.7031],\n",
            "          [2.2612, 0.7031]],\n",
            "\n",
            "         [[1.4726, 1.1552],\n",
            "          [1.4726, 1.1552],\n",
            "          [1.4726, 1.1552]]],\n",
            "\n",
            "\n",
            "        [[[2.0769, 2.4145],\n",
            "          [1.9900, 2.3382],\n",
            "          [1.9552, 2.3192]],\n",
            "\n",
            "         [[1.6676, 1.7909],\n",
            "          [1.5917, 1.6916],\n",
            "          [1.5895, 1.5476]],\n",
            "\n",
            "         [[2.1427, 1.5032],\n",
            "          [1.9758, 1.3603],\n",
            "          [1.9963, 1.3886]],\n",
            "\n",
            "         [[2.7894, 2.5395],\n",
            "          [2.6208, 2.3824],\n",
            "          [2.5036, 2.2143]],\n",
            "\n",
            "         [[2.8820, 2.7457],\n",
            "          [2.8246, 2.6967],\n",
            "          [2.7889, 2.6568]],\n",
            "\n",
            "         [[2.8431, 1.7519],\n",
            "          [2.7552, 1.6921],\n",
            "          [2.6833, 1.6438]],\n",
            "\n",
            "         [[3.0050, 1.5547],\n",
            "          [2.7032, 1.3832],\n",
            "          [2.6259, 1.3419]],\n",
            "\n",
            "         [[1.7002, 1.6920],\n",
            "          [1.6204, 1.6135],\n",
            "          [1.6287, 1.5323]]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
            "v_out shape before: torch.Size([4, 8, 3, 2])\n",
            "v_out shape: torch.Size([4, 3, 16])\n",
            "weight_out shape: torch.Size([16, 4])\n",
            "v_out reshaped: tensor([[[1.5747, 1.7492, 1.5108, 1.7720, 1.5156, 1.7703, 1.0093, 1.3817,\n",
            "          1.0662, 1.3394, 1.0676, 1.3383, 1.6020, 1.0224, 1.5840, 0.9421],\n",
            "         [1.5844, 0.9439, 2.4326, 2.1812, 2.1340, 2.0521, 2.1367, 2.0533,\n",
            "          2.1698, 2.3601, 2.1523, 2.2855, 2.1536, 2.2909, 2.4991, 1.4703],\n",
            "         [2.3683, 1.4000, 2.3677, 1.3997, 2.6198, 1.0720, 2.4079, 1.1163,\n",
            "          2.4103, 1.1157, 1.1448, 1.2390, 1.1218, 1.1068, 1.1212, 1.1034]],\n",
            "\n",
            "        [[1.6333, 2.0743, 1.6172, 2.0401, 1.6187, 2.0431, 1.3902, 1.4824,\n",
            "          1.3722, 1.4173, 1.3726, 1.4187, 1.8033, 1.1089, 1.7257, 0.9732],\n",
            "         [1.7269, 0.9753, 2.2536, 2.2194, 2.2012, 2.1876, 2.2006, 2.1872,\n",
            "          2.4051, 2.2898, 2.3627, 2.2775, 2.3664, 2.2786, 2.4014, 1.4652],\n",
            "         [2.3344, 1.4119, 2.3388, 1.4154, 2.5075, 1.3683, 2.4316, 1.2771,\n",
            "          2.4372, 1.2839, 1.2931, 1.2840, 1.3056, 1.1501, 1.3054, 1.1513]],\n",
            "\n",
            "        [[1.3954, 1.5883, 1.3954, 1.5883, 1.3954, 1.5883, 1.1389, 0.9657,\n",
            "          1.1389, 0.9657, 1.1389, 0.9657, 1.4568, 0.9618, 1.4568, 0.9618],\n",
            "         [1.4568, 0.9618, 2.3366, 1.7633, 2.3366, 1.7633, 2.3366, 1.7633,\n",
            "          2.0188, 2.2448, 2.0188, 2.2448, 2.0188, 2.2448, 2.1304, 1.1950],\n",
            "         [2.1304, 1.1950, 2.1304, 1.1950, 2.2612, 0.7031, 2.2612, 0.7031,\n",
            "          2.2612, 0.7031, 1.4726, 1.1552, 1.4726, 1.1552, 1.4726, 1.1552]],\n",
            "\n",
            "        [[2.0769, 2.4145, 1.9900, 2.3382, 1.9552, 2.3192, 1.6676, 1.7909,\n",
            "          1.5917, 1.6916, 1.5895, 1.5476, 2.1427, 1.5032, 1.9758, 1.3603],\n",
            "         [1.9963, 1.3886, 2.7894, 2.5395, 2.6208, 2.3824, 2.5036, 2.2143,\n",
            "          2.8820, 2.7457, 2.8246, 2.6967, 2.7889, 2.6568, 2.8431, 1.7519],\n",
            "         [2.7552, 1.6921, 2.6833, 1.6438, 3.0050, 1.5547, 2.7032, 1.3832,\n",
            "          2.6259, 1.3419, 1.7002, 1.6920, 1.6204, 1.6135, 1.6287, 1.5323]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "output shape torch.Size([4, 3, 4])\n",
            "output: tensor([[[ 9.9064, 11.8741, 14.5426,  8.4144],\n",
            "         [15.2197, 16.8968, 20.4057, 12.3063],\n",
            "         [12.5137, 13.7880, 14.8842,  9.5376]],\n",
            "\n",
            "        [[11.1378, 13.6187, 16.3055,  9.3687],\n",
            "         [15.4380, 17.5922, 21.0932, 12.6094],\n",
            "         [13.0852, 14.3406, 15.8139,  9.9490]],\n",
            "\n",
            "        [[ 9.1329, 11.0847, 13.2182,  7.7315],\n",
            "         [14.3721, 15.9873, 18.9229, 11.5051],\n",
            "         [11.5724, 13.1749, 14.2316,  9.0824]],\n",
            "\n",
            "        [[13.3395, 16.1498, 19.2647, 11.2656],\n",
            "         [18.0507, 20.7057, 24.5996, 14.7194],\n",
            "         [15.1536, 16.9318, 18.6040, 11.8712]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, feature_length):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.ones(feature_length))\n",
        "        self.offset = nn.Parameter(torch.zeros(feature_length))\n",
        "\n",
        "    def forward(self, activations):\n",
        "        mean = torch.mean(activations, -1, keepdim=True)\n",
        "        #print(\"mean:\", mean)\n",
        "        #print(\"activations - mean\", activations - mean)\n",
        "        variance = torch.var(activations, -1, keepdim=True, unbiased=False)\n",
        "        normalized_activations = (activations - mean) / torch.sqrt(variance + 1e-6)\n",
        "        return (normalized_activations * self.scale) + self.offset"
      ],
      "metadata": {
        "id": "-Si4-i6PTlFu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_layer_norm():\n",
        "    feature_length = 4\n",
        "    length_x = 3\n",
        "    batch_size = 5\n",
        "    layer_norm = LayerNorm(feature_length)\n",
        "\n",
        "    activations = torch.rand(batch_size, length_x, feature_length)\n",
        "\n",
        "    print(\"activations:\", activations)\n",
        "    print(\"layer_normed:\", layer_norm(activations))\n",
        "    assert layer_norm(activations).shape == activations.shape\n",
        "\n",
        "test_layer_norm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyzgWHqrWXL4",
        "outputId": "cddd7adb-28d7-4be7-e2a5-fc664a6754ea"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations: tensor([[[0.0740, 0.5761, 0.1583, 0.9082],\n",
            "         [0.0254, 0.4980, 0.5432, 0.7955],\n",
            "         [0.3154, 0.4343, 0.3936, 0.2391]],\n",
            "\n",
            "        [[0.6966, 0.8427, 0.1361, 0.3746],\n",
            "         [0.9258, 0.1272, 0.2205, 0.4163],\n",
            "         [0.5488, 0.6108, 0.0512, 0.1113]],\n",
            "\n",
            "        [[0.8538, 0.0780, 0.4456, 0.9851],\n",
            "         [0.2553, 0.5005, 0.7952, 0.3014],\n",
            "         [0.7036, 0.1147, 0.7308, 0.0979]],\n",
            "\n",
            "        [[0.7745, 0.3784, 0.5438, 0.5078],\n",
            "         [0.3485, 0.9173, 0.7833, 0.2066],\n",
            "         [0.0177, 0.0686, 0.7524, 0.0972]],\n",
            "\n",
            "        [[0.1624, 0.9529, 0.2026, 0.7624],\n",
            "         [0.3717, 0.1057, 0.9665, 0.7025],\n",
            "         [0.5528, 0.3656, 0.8212, 0.2777]]])\n",
            "layer_normed: tensor([[[-1.0581,  0.4377, -0.8070,  1.4274],\n",
            "         [-1.5818,  0.1169,  0.2790,  1.1859],\n",
            "         [-0.4032,  1.1844,  0.6411, -1.4223]],\n",
            "\n",
            "        [[ 0.6683,  1.1984, -1.3662, -0.5005],\n",
            "         [ 1.6301, -0.9563, -0.6540, -0.0198],\n",
            "         [ 0.8691,  1.1161, -1.1122, -0.8729]],\n",
            "\n",
            "        [[ 0.7380, -1.4375, -0.4066,  1.1062],\n",
            "         [-0.9768,  0.1757,  1.5611, -0.7600],\n",
            "         [ 0.9548, -0.9719,  1.0438, -1.0267]],\n",
            "\n",
            "        [[ 1.5633, -1.2088, -0.0513, -0.3032],\n",
            "         [-0.7314,  1.1996,  0.7447, -1.2129],\n",
            "         [-0.7194, -0.5500,  1.7243, -0.4549]],\n",
            "\n",
            "        [[-1.0382,  1.2563, -0.9215,  0.7033],\n",
            "         [-0.5057, -1.3217,  1.3185,  0.5089],\n",
            "         [ 0.2328, -0.6664,  1.5221, -1.0885]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, hiddenLayerWidth, d_e):\n",
        "        super().__init__()\n",
        "        self.mlp1 = nn.Parameter(torch.rand(d_e, hiddenLayerWidth))\n",
        "        self.mlp2 = nn.Parameter(torch.rand(hiddenLayerWidth, d_e))\n",
        "        self.mlp1_bias = nn.Parameter(torch.zeros(hiddenLayerWidth))\n",
        "        self.mlp2_bias = nn.Parameter(torch.zeros(d_e))\n",
        "\n",
        "    def forward(self, activations):\n",
        "        activations = torch.matmul(activations, self.mlp1) + self.mlp1_bias\n",
        "        activations = activations.relu()\n",
        "        activations = torch.matmul(activations, self.mlp2) + self.mlp2_bias\n",
        "        return activations\n"
      ],
      "metadata": {
        "id": "X7rAEAkFoNI5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_feed_forward():\n",
        "    hiddenLayerWidth = 3\n",
        "    d_e = 4\n",
        "    feed_forward = FeedForward(hiddenLayerWidth, d_e)\n",
        "    activations = torch.rand(10, 5, d_e)\n",
        "\n",
        "    print(\"activations:\", activations)\n",
        "    output = feed_forward(activations)\n",
        "    print(\"feed forward:\", output)\n",
        "    assert output.shape == activations.shape\n",
        "\n",
        "test_feed_forward()"
      ],
      "metadata": {
        "id": "mLQj6GjmUFN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0260f60-b071-4ab6-af0f-33d053614ef1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations: tensor([[[8.2009e-01, 8.3609e-01, 8.5392e-01, 6.0773e-01],\n",
            "         [5.9798e-01, 3.1981e-02, 9.2482e-01, 9.4239e-01],\n",
            "         [8.4224e-01, 2.7856e-01, 3.1861e-01, 9.4557e-01],\n",
            "         [8.7366e-01, 3.9853e-01, 3.5887e-01, 2.8971e-02],\n",
            "         [3.3410e-01, 8.8679e-01, 4.9636e-01, 2.5706e-01]],\n",
            "\n",
            "        [[7.6555e-01, 1.7312e-01, 5.7957e-01, 6.1636e-01],\n",
            "         [5.9314e-01, 3.7463e-03, 2.3211e-01, 4.5253e-01],\n",
            "         [3.1880e-01, 1.5249e-01, 5.2706e-01, 9.7245e-01],\n",
            "         [1.6125e-01, 2.1925e-01, 5.3639e-01, 1.0331e-01],\n",
            "         [7.0899e-01, 7.4258e-01, 5.8480e-01, 5.2108e-01]],\n",
            "\n",
            "        [[4.0680e-01, 4.1767e-01, 1.4233e-01, 2.0912e-01],\n",
            "         [8.4549e-01, 3.9151e-01, 4.5374e-01, 6.2639e-01],\n",
            "         [7.4198e-01, 7.4134e-01, 6.2906e-01, 6.4801e-01],\n",
            "         [3.0707e-01, 7.6654e-01, 3.1045e-01, 4.3200e-01],\n",
            "         [7.6641e-01, 9.1288e-01, 3.7193e-01, 3.4477e-01]],\n",
            "\n",
            "        [[3.3231e-01, 3.7801e-01, 7.1181e-01, 7.2664e-01],\n",
            "         [7.2847e-01, 6.6413e-01, 4.9138e-01, 2.5187e-01],\n",
            "         [6.1849e-01, 7.9067e-01, 6.0030e-01, 3.2036e-01],\n",
            "         [5.2513e-01, 4.7479e-02, 2.3818e-01, 9.2408e-01],\n",
            "         [7.3164e-01, 2.7629e-01, 2.4569e-01, 8.9403e-01]],\n",
            "\n",
            "        [[3.0511e-02, 9.9877e-01, 5.2159e-01, 4.9013e-02],\n",
            "         [2.7976e-01, 3.7284e-01, 8.5863e-01, 5.0559e-02],\n",
            "         [1.9936e-02, 1.5367e-01, 2.5458e-01, 6.6657e-02],\n",
            "         [4.1073e-01, 4.7697e-01, 8.8233e-01, 3.3740e-01],\n",
            "         [5.8499e-01, 9.6155e-01, 2.6687e-01, 7.4986e-01]],\n",
            "\n",
            "        [[5.9521e-01, 4.3610e-01, 8.7762e-04, 5.5039e-01],\n",
            "         [7.2884e-01, 1.0801e-01, 6.8976e-01, 7.1132e-01],\n",
            "         [7.8364e-02, 2.1142e-01, 5.5662e-01, 1.6276e-02],\n",
            "         [5.2486e-01, 6.9699e-01, 8.5120e-01, 3.5134e-02],\n",
            "         [9.0530e-01, 8.3822e-01, 1.6127e-01, 7.5235e-01]],\n",
            "\n",
            "        [[7.2225e-01, 3.0420e-01, 9.7396e-01, 3.6016e-01],\n",
            "         [8.0954e-01, 8.2518e-01, 8.2474e-01, 4.1826e-01],\n",
            "         [5.0359e-02, 1.3944e-01, 5.2350e-01, 8.5156e-01],\n",
            "         [5.3275e-01, 6.0156e-01, 7.5013e-01, 5.9914e-01],\n",
            "         [8.0035e-01, 1.0611e-01, 3.6206e-01, 4.8461e-01]],\n",
            "\n",
            "        [[6.6380e-01, 5.8783e-01, 7.0353e-01, 6.0040e-01],\n",
            "         [2.8820e-01, 5.4894e-01, 4.1537e-01, 8.1548e-01],\n",
            "         [7.7860e-02, 9.2846e-01, 8.1799e-01, 7.4393e-01],\n",
            "         [1.2168e-01, 2.4900e-01, 6.0582e-01, 1.4206e-01],\n",
            "         [6.4358e-02, 6.1804e-01, 2.4664e-01, 1.4839e-01]],\n",
            "\n",
            "        [[1.9130e-01, 2.4476e-01, 3.3209e-01, 8.6877e-01],\n",
            "         [3.4185e-01, 7.7932e-01, 6.9717e-01, 4.1823e-01],\n",
            "         [6.4827e-01, 8.4383e-01, 3.7951e-02, 9.0868e-02],\n",
            "         [8.5818e-02, 5.1924e-01, 6.3477e-01, 6.5266e-01],\n",
            "         [1.9208e-01, 2.5319e-02, 2.3145e-01, 6.1084e-01]],\n",
            "\n",
            "        [[5.7066e-01, 4.5998e-01, 4.7885e-01, 2.4531e-01],\n",
            "         [2.2347e-01, 4.5081e-01, 9.0973e-01, 8.8711e-01],\n",
            "         [2.0478e-02, 1.8093e-03, 5.9776e-01, 6.0698e-01],\n",
            "         [5.2543e-01, 3.2221e-01, 3.8261e-02, 1.7729e-01],\n",
            "         [1.4661e-01, 1.7214e-01, 7.4268e-01, 6.0193e-01]]])\n",
            "feed forward: tensor([[[5.3374, 1.6054, 2.4815, 3.5748],\n",
            "         [4.2772, 1.1104, 2.0523, 2.8729],\n",
            "         [4.2958, 1.1677, 1.9992, 2.8482],\n",
            "         [3.9810, 1.1172, 1.7290, 2.5340],\n",
            "         [4.2642, 1.2629, 1.9044, 2.8219]],\n",
            "\n",
            "        [[4.1252, 1.1025, 1.9011, 2.7085],\n",
            "         [3.2532, 0.7932, 1.4439, 2.0819],\n",
            "         [3.7308, 0.9444, 1.7661, 2.5090],\n",
            "         [3.1194, 0.7812, 1.3638, 2.0077],\n",
            "         [4.7629, 1.4042, 2.1792, 3.1630]],\n",
            "\n",
            "        [[3.3474, 0.8941, 1.4428, 2.1461],\n",
            "         [4.3916, 1.2276, 2.0113, 2.8889],\n",
            "         [4.9206, 1.4517, 2.2738, 3.2848],\n",
            "         [3.9935, 1.1494, 1.7867, 2.6441],\n",
            "         [4.7404, 1.4337, 2.1219, 3.1201]],\n",
            "\n",
            "        [[4.0817, 1.1032, 1.9102, 2.7391],\n",
            "         [4.4273, 1.2926, 1.9780, 2.8934],\n",
            "         [4.6143, 1.3676, 2.0842, 3.0482],\n",
            "         [3.5205, 0.8687, 1.6337, 2.3252],\n",
            "         [4.0585, 1.0887, 1.8760, 2.6846]],\n",
            "\n",
            "        [[3.9533, 1.1773, 1.7351, 2.6146],\n",
            "         [3.7513, 1.0157, 1.6779, 2.4477],\n",
            "         [2.5637, 0.5880, 1.0759, 1.6172],\n",
            "         [4.2408, 1.1861, 1.9449, 2.8108],\n",
            "         [4.7299, 1.4189, 2.1640, 3.1691]],\n",
            "\n",
            "        [[3.6602, 0.9940, 1.6199, 2.3783],\n",
            "         [4.1614, 1.0986, 1.9425, 2.7494],\n",
            "         [2.9785, 0.7343, 1.2891, 1.9083],\n",
            "         [4.4558, 1.3062, 1.9968, 2.9230],\n",
            "         [4.8422, 1.4462, 2.2051, 3.2117]],\n",
            "\n",
            "        [[4.4846, 1.2460, 2.0691, 2.9538],\n",
            "         [5.1676, 1.5548, 2.3739, 3.4361],\n",
            "         [3.3193, 0.8039, 1.5604, 2.2332],\n",
            "         [4.5774, 1.3116, 2.1224, 3.0603],\n",
            "         [3.7827, 0.9870, 1.7037, 2.4430]],\n",
            "\n",
            "        [[4.6690, 1.3436, 2.1598, 3.1103],\n",
            "         [4.0165, 1.1070, 1.8626, 2.7004],\n",
            "         [4.6274, 1.3611, 2.1725, 3.1624],\n",
            "         [3.2041, 0.8107, 1.4151, 2.0777],\n",
            "         [3.2748, 0.8937, 1.4114, 2.1291]],\n",
            "\n",
            "        [[3.4470, 0.8676, 1.6016, 2.3070],\n",
            "         [4.4263, 1.2918, 2.0220, 2.9558],\n",
            "         [4.0253, 1.1965, 1.7249, 2.5915],\n",
            "         [3.8566, 1.0480, 1.7888, 2.5975],\n",
            "         [2.9015, 0.6639, 1.3055, 1.8901]],\n",
            "\n",
            "        [[3.9527, 1.1002, 1.7590, 2.5705],\n",
            "         [4.3420, 1.1897, 2.0722, 2.9564],\n",
            "         [3.0274, 0.6936, 1.3999, 2.0059],\n",
            "         [3.2388, 0.8487, 1.3781, 2.0500],\n",
            "         [3.5436, 0.8928, 1.6498, 2.3635]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose):\n",
        "        super().__init__()\n",
        "        self.verbose = verbose\n",
        "        self.multi_head_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'], verbose)\n",
        "        self.layer_norm1 = LayerNorm(d_z)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_z)\n",
        "        self.layer_norm2 = LayerNorm(d_z)\n",
        "\n",
        "    def forward(self, z, padding_mask):\n",
        "        z = z + self.multi_head_attention(z, z, padding_mask)\n",
        "        z = self.layer_norm1(z)\n",
        "        z = z + self.feed_forward(z)\n",
        "        z = self.layer_norm2(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "ikM15oD-qghT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            encoder_layer = EncoderLayer(num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose)\n",
        "            self.layers.append(encoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, z, padding_mask):\n",
        "        for layer in self.layers:\n",
        "            z = layer(z, padding_mask)\n",
        "        return z"
      ],
      "metadata": {
        "id": "zKGc6Xwr46Vh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose):\n",
        "        super().__init__()\n",
        "        self.verbose = verbose\n",
        "        self.multi_head_self_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['MASKED'], verbose)\n",
        "        self.layer_norm1 = LayerNorm(d_x)\n",
        "        self.multi_head_global_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'], verbose)\n",
        "        self.layer_norm2 = LayerNorm(d_x)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_x)\n",
        "        self.layer_norm3 = LayerNorm(d_x)\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        x = x + self.multi_head_self_attention(x, x, tgt_mask)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = x + self.multi_head_global_attention(z, x, src_mask)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = x + self.feed_forward(x)\n",
        "        x = self.layer_norm3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GSqElGm56xaK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            decoder_layer = DecoderLayer(num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose)\n",
        "            self.layers.append(decoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(z, x, src_mask, tgt_mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LGX007WN8Bw6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, d_e, vocab_size, max_sequence_length, verbose):\n",
        "        super().__init__()\n",
        "        self.verbose = verbose\n",
        "        self.embedding = Embedding(vocab_size, d_e)\n",
        "        self.positionalEmbedding = PositionalEmbedding(d_e, max_sequence_length)\n",
        "        self.encoder = Encoder(num_encoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose)\n",
        "        self.decoder = Decoder(num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, verbose)\n",
        "        self.unembedding = Unembedding(vocab_size, d_e)\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        z = self.embedding(z) + self.positionalEmbedding(z)\n",
        "        z = self.encoder(z, src_mask)\n",
        "        x = self.embedding(x) + self.positionalEmbedding(x)\n",
        "        x = self.decoder(z, x, src_mask, tgt_mask)\n",
        "        #print(\"x after decoder:\", x.shape)\n",
        "        x = self.unembedding(x)\n",
        "        #print(\"x after unembedding:\", x.shape)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ixXJDrPF8RU9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enRawName = \"drive/MyDrive/colab data/multi30kEnTrain.txt\"\n",
        "deRawName = \"drive/MyDrive/colab data/multi30kDeTrain.txt\"\n",
        "en30kVal = \"drive/MyDrive/colab data/multi30kEnVal.txt\"\n",
        "de30kVal = \"drive/MyDrive/colab data/multi30kDeVal.txt\"\n",
        "englishCleanName = \"data/english_tokens.pkl\"\n",
        "germanCleanName = \"data/german_tokens.pkl\"\n",
        "englishSortedName = \"data/englishSorted.pkl\"\n",
        "germanSortedName = \"data/germanSorted.pkl\"\n",
        "\n",
        "truncEn = \"drive/MyDrive/colab data/truncEn.pkl\"\n",
        "truncDe = \"drive/MyDrive/colab data/truncDe.pkl\"\n",
        "\n",
        "enTokenizerName = \"drive/MyDrive/colab data/enTokenizer.pkl\"\n",
        "deTokenizerName = \"drive/MyDrive/colab data/deTokenizer.pkl\"\n",
        "pairsName = \"drive/MyDrive/colab data/pairs.pkl\"\n",
        "folder = \"drive/MyDrive/colab data/\"\n",
        "\n",
        "enTrainingFileName = folder + \"enTraining\"\n",
        "deTrainingFileName = folder + \"deTraining\"\n",
        "enTestFileName = folder + \"enTest\"\n",
        "deTestFileName = folder + \"deTest\"\n",
        "enValFileName = folder + \"enValidation\"\n",
        "deValFileName = folder + \"deValidation\"\n",
        "\n",
        "enCombinedFileName = folder + \"enCombined\"\n",
        "deCombinedFileName = folder + \"deCombined\""
      ],
      "metadata": {
        "id": "NqAcQrmPg4y0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc6Y11QfhEAv",
        "outputId": "5989625b-d13b-4903-f7bc-e1eba043325f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "\n",
        "    TOKENIZER_SUFFIX = \"_tokenizer\"\n",
        "    BOS_TOKEN = \"[SOS]\"\n",
        "    EOS_TOKEN = \"[EOS]\"\n",
        "    PAD_TOKEN = \"[PAD]\"\n",
        "    UNK_TOKEN = \"[UNK]\"\n",
        "\n",
        "    def __init__(self, src_filename, tgt_filename, src_vocab_size, tgt_vocab_size, max_sequences):\n",
        "        src_sequences = self.to_sequences(self.load_doc(src_filename), max_sequences)\n",
        "        print(len(src_sequences))\n",
        "        tgt_sequences = self.to_sequences(self.load_doc(tgt_filename), max_sequences)\n",
        "        src_sequences = [self.add_special_tokens(sequence) for sequence in src_sequences]\n",
        "        tgt_sequences = [self.add_special_tokens(sequence) for sequence in tgt_sequences]\n",
        "        self.src_tokenizer, self.tgt_tokenizer = self.setup_tokenizers(src_filename, tgt_filename, src_vocab_size, tgt_vocab_size, src_filename + SentenceDataset.TOKENIZER_SUFFIX, tgt_filename + SentenceDataset.TOKENIZER_SUFFIX)\n",
        "        # src_tokenized = self.src_tokenizer.encode_batch(src_sequences)\n",
        "        # tgt_tokenized = self.tgt_tokenizer.encode_batch(tgt_sequences)\n",
        "        # src_tensors = [torch.IntTensor(sequence.ids) for sequence in src_tokenized]\n",
        "        # tgt_tensor = [torch.IntTensor(sequence.ids) for sequence in tgt_tokenized]\n",
        "        self.pairs = self.pair_sequences(src_sequences, tgt_sequences)\n",
        "        print(\"pairs\", self.pairs)\n",
        "\n",
        "    # load doc into memory\n",
        "    def load_doc(self, filename):\n",
        "        # open the file as read only\n",
        "        file = open(filename, mode='rt')\n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        # close the file\n",
        "        file.close()\n",
        "        return text\n",
        "\n",
        "    def add_special_tokens(self, sequence):\n",
        "        #sequence = self.BOS_TOKEN + \" \" + sequence + \" \" + self.EOS_TOKEN\n",
        "        return sequence\n",
        "\n",
        "    def pair_sequences(self, src_sequences, tgt_sequences):\n",
        "        paired_sequences = list(zip(src_sequences, tgt_sequences))\n",
        "        sorted_pairs = sorted(paired_sequences, key=lambda x: len(x[0]))\n",
        "        return sorted_pairs\n",
        "\n",
        "    # split a loaded document into sequences\n",
        "    def to_sequences(self, doc, max_sequences):\n",
        "        sequences = doc.strip().split('\\n')\n",
        "        return sequences[:max_sequences]\n",
        "\n",
        "    def setup_tokenizers(self, src_filename, tgt_filename, src_vocab_size, tgt_vocab_size, src_tokenizer_name, tgt_tokenizer_name):\n",
        "        print(\"creating tokenizer for \" + src_filename)\n",
        "        src_tokenizer = Tokenizer(BPE(unk_token=SentenceDataset.UNK_TOKEN))\n",
        "        src_tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(vocab_size = src_vocab_size, special_tokens=[SentenceDataset.BOS_TOKEN, SentenceDataset.EOS_TOKEN, SentenceDataset.PAD_TOKEN, SentenceDataset.UNK_TOKEN])\n",
        "        src_tokenizer.train([src_filename], trainer=trainer)\n",
        "        pickle.dump(src_tokenizer, open(src_tokenizer_name, \"wb\"))\n",
        "\n",
        "        print(\"creating tokenizer for \" + tgt_filename)\n",
        "        tgt_tokenizer = Tokenizer(BPE(unk_token=SentenceDataset.UNK_TOKEN))\n",
        "        tgt_tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(vocab_size = tgt_vocab_size, special_tokens=[SentenceDataset.BOS_TOKEN, SentenceDataset.EOS_TOKEN, SentenceDataset.PAD_TOKEN, SentenceDataset.UNK_TOKEN])\n",
        "        tgt_tokenizer.train([tgt_filename], trainer=trainer)\n",
        "        pickle.dump(tgt_tokenizer, open(tgt_tokenizer_name, \"wb\"))\n",
        "        return src_tokenizer, tgt_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_seq, tgt_seq = self.pairs[index]\n",
        "        return src_seq, tgt_seq\n"
      ],
      "metadata": {
        "id": "PkCWRs4-khoT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PadCollate:\n",
        "    PAD_TOKEN = \"[PAD]\"\n",
        "    PAD_ID = 2\n",
        "    def __init__(self, src_tokenizer, tgt_tokenizer):\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # max_len_src = max([len(pair[0].split()) for pair in batch])\n",
        "        # max_len_tgt = max([len(pair[1].split()) for pair in batch])\n",
        "\n",
        "        max_len_src = len(self.src_tokenizer.encode(batch[-1][0]))\n",
        "        max_len_tgt = len(self.tgt_tokenizer.encode(batch[-1][1]))\n",
        "\n",
        "        self.src_tokenizer.enable_padding(pad_id = self.PAD_ID, pad_token = self.PAD_TOKEN, length=max_len_src)\n",
        "        self.src_tokenizer.enable_truncation(max_length=max_len_src)\n",
        "        self.tgt_tokenizer.enable_padding(pad_id = self.PAD_ID, pad_token = self.PAD_TOKEN, length=max_len_tgt)\n",
        "        self.tgt_tokenizer.enable_truncation(max_length=max_len_tgt)\n",
        "\n",
        "        # print(\"src batch:\", [pair[0] for pair in batch])\n",
        "        # print(\"tgt batch:\", [pair[1] for pair in batch])\n",
        "\n",
        "        src_tokenized = self.src_tokenizer.encode_batch([pair[0] for pair in batch])\n",
        "        tgt_tokenized = self.tgt_tokenizer.encode_batch([pair[1] for pair in batch])\n",
        "        # src_tokenized = [sequence.ids for sequence in src_tokenized]\n",
        "        # tgt_tokenized = [sequence.ids for sequence in tgt_tokenized]\n",
        "        # src_tensors = torch.IntTensor(src_tokenized)\n",
        "        # tgt_tensor = torch.IntTensor(tgt_tokenized)\n",
        "\n",
        "        return src_tokenized, tgt_tokenized"
      ],
      "metadata": {
        "id": "P1wzP-DDLZ1X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequenceDataset = SentenceDataset(enRawName, deRawName, 10000, 10000, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82dEUnd5lx9M",
        "outputId": "8bccb344-a15e-44c3-8350-e2fc909ff011"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "creating tokenizer for drive/MyDrive/colab data/multi30kEnTrain.txt\n",
            "creating tokenizer for drive/MyDrive/colab data/multi30kDeTrain.txt\n",
            "pairs [('A man sits on a rock.', 'Ein Mann sitzt auf einem Stein.'), ('A man is putting up a wall.', 'Ein Mann stellt eine Wand auf.'), ('A dog is running in the snow', 'Ein Hund rennt im Schnee.'), ('A dog walks through a field.', 'Ein Hund läuft durch ein Feld.'), ('A girl standing in the ocean', 'Ein Mädchen, das im Meer steht'), ('A black dog leaps over a log.', 'Ein schwarzer Hund springt über einen Baumstamm.'), ('A dog is playing with a hose.', 'Ein Hund spielt mit einem Schlauch.'), ('A guy wearing blue in a hole.', 'Ein Typ, der blau trägt, in einem Loch.'), ('A young boy plays on a swing.', 'Ein Junge spielt auf einer Schaukel.'), ('A old man having a beer alone.', 'Ein alter Mann, der allein ein Bier trinkt.'), ('A man with two dogs on a beach', 'Ein Mann mit zwei Hunden an einem Strand.'), ('Two men barbecuing at a beach.', 'Zwei Männer, die am Strand grillen.'), (\"Three people on ATV's outside.\", 'Drei Leute vor einem Geländewagen.'), ('A dog is running on the beach.', 'Ein Hund rennt am Strand.'), ('A dog is standing in the sand.', 'Ein Hund steht im Sand.'), ('A group of girls are cheering.', 'Eine Mädchengruppe jubelt.'), ('Two men on the side of a barge', 'Zwei Männer auf der Seite eines Kahns'), ('A boy in white plays baseball.', 'Ein weiß gekleideter Junge spielt Baseball.'), ('Asian man sweeping the walkway.', 'Ein asiatischer Mann kehrt den Gehweg.'), ('The lady has a black sling bag.', 'Die Dame hat eine schwarze Umhängetasche.'), ('A boy looking at a chopped log.', 'Ein Junge blickt auf einen zerkleinerten Baumstamm.'), ('A beach is full of many people.', 'Ein Strand ist voller Menschen.'), ('A woman reaching out to lights.', 'Eine Frau, die nach Streichhölzern greift.'), ('A black dog swims in the water.', 'Ein schwarzer Hund schwimmt im Wasser.'), ('A man walks by a silver vehicle.', 'Ein Mann geht an einem silbernen Fahrzeug vorbei.'), ('A child walks in a grassy field.', 'Ein Kind geht durch eine Wiese.'), ('A young girl painting a picture.', 'Ein Mädchen malt ein Bild.'), ('A little boy stands in the surf.', 'Ein kleiner Junge steht in der Brandung.'), ('A little boy in overalls crying.', 'Ein kleiner Junge in Latzhosen, der schreit.'), ('A man eating in a messy kitchen.', 'Ein Mann, der in einer unaufgeräumten Küche isst.'), ('A man at work, butchering a cow.', 'Ein Mann bei der Arbeit, wie er eine Kuh schlachtet.'), ('A man in an apron sits on a curb.', 'Ein Mann in einer Schürze sitzt auf einer Bordsteinkante.'), ('The three girls sat on the beach.', 'Die drei Mädchen saßen am Strand.'), ('A man with gloves works in a lab.', 'Ein Mann mit Handschuhen arbeitet in einem Labor.'), ('A woman holding a dog on a leash.', 'Eine Frau, die einen Hund an der Leine hält.'), ('A man is smiling at a stuffed lion', 'Ein Mann lächelt einen ausgestopften Löwen an.'), ('Two young boys making silly faces.', 'Zwei Jungen schneiden Grimassen.'), ('A brown dog running next to grass.', 'Ein brauner Hund, der neben Gras rennt.'), ('A little boy playing in the water.', 'Ein kleiner Junge spielt im Wasser.'), ('A boy strolls by a pond in a park.', 'Ein Junge schlendert in einem Park an einem Teich vorbei.'), ('A woman shops at a farmers market.', 'Eine Frau kauft auf einem Bauernmarkt ein.'), ('A boy splashing through the ocean.', 'Ein Junge, der durch das Meer planscht.'), ('Some kids playing near the street.', 'Ein paar Kinder, die in der Nähe der Straße spielen.'), ('A crowd cheers on a baseball team.', 'Eine Menschenmenge feuert ein Baseballteam an.'), ('A man getting a tattoo on his back.', 'Ein Mann, der ein Tattoo auf seinem Rücken erhält.'), ('Two kids are laughing in the grass.', 'Zwei Kinder im Gras lachen.'), ('A rock climber climbs a large rock.', 'Ein Kletterer klettert einen großen Felsen hoch.'), ('A kid jumping into a pool of water.', 'Ein Kind, das in eine Wasserlache springt.'), ('A little boy kicking a rubber ball.', 'Ein Junge kickt einen Gummiball.'), ('Two men in black eating a sandwich.', 'Zwei schwarz gekleidete Männer, die ein Vesperbrot essen.'), ('A man and a woman fish from a boat.', 'Ein Mann und eine Frau fischen von einem Boot aus.'), ('A man is pouring drinks at a table.', 'Ein Mann schenkt an einem Tisch Getränke aus.'), ('Dogs pulling a sled in a sled race.', 'Bei einem Hunderennen ziehen Hunde einen Schlitten.'), ('The dog has red straps in its back.', 'Der Hund hat rote Riemen auf seinem Rücken.'), ('Several people walk up a staircase.', 'Mehrere Leute gehen eine Treppe hoch.'), ('People stand on a colorful balcony.', 'Leute stehen auf einem bunten Balkon.'), ('A boy jumps from one bed to another.', 'Ein Junge springt von einem Bett zum anderen.'), ('A young man holding a huge chainsaw.', 'Ein junger Mann hält eine riesige Kettensäge.'), ('Two skiers stand, two sit on slopes.', 'Zwei Skifahrer stehen, zwei sitzen auf Böschungen.'), ('A big dog catches a ball on his nose', 'Ein großer Hund fängt einen Ball auf seiner Nase.'), ('2 men stand in line at a restaurant.', '2 Männer stehen in einer Reihe in einem Restaurant.'), ('Two men are hanging out and grilling', 'Zwei Männer hängen ab und grillen.'), ('Two men are working on train tracks.', 'Zwei Männer arbeiten auf Gleisen.'), ('Two people go ice skating in a rink.', 'Zwei Personen, die in einer Eislaufhalle eislaufen.'), ('Several women wait outside in a city.', 'Mehrere Frauen warten in einer Stadt im Freien.'), ('The black dog runs through the water.', 'Der schwarze Hund rennt durch das Wasser.'), ('A group of people are eating noddles.', 'Eine Gruppe von Leuten isst Nudeln.'), ('A meal is on a table in a restaurant.', 'In einem Restaurant steht eine Mahlzeit auf dem Tisch.'), (\"A man asleep in a car that's driving.\", 'Ein schlafender Mann in einem fahrenden Auto.'), ('A black man operates an orange crane.', 'Ein schwarzer Mann bedient einen orangefarbenen Kran.'), (\"A child is brushing an infant's hair.\", 'Ein Kind bürstet die Haare eines Säuglings.'), ('Two men are playing music on a bench.', 'Zwei Männer auf einer Bank musizieren.'), ('A family poses for a photo at dinner.', 'Eine Familie posiert beim Abendessen für ein Foto.'), ('A few guys playing soccer on a field.', 'Ein paar Typen spielen auf einem Feld Fußball.'), ('A smiling boy runs through the grass.', 'Ein lächelnder Junge rennt durch das Gras.'), ('Person hanging upside down from poles', 'Eine Person die mit dem Kopf nach unten von Stangen hängt.'), ('Two hikers resting by a patch of snow.', 'Zwei Wanderer machen bei einem Stückchen Schnee Pause.'), ('A light-colored dog runs on the beach.', 'Ein hell gefärbter Hund rennt am Strand.'), ('Two children running with no shoes on.', 'Zwei Kinder rennen, ohne Schuhe zu tragen.'), ('A woman and two girls dressed in pink.', 'Eine Frau und zwei Mädchen, die rosa gekleidet sind.'), ('Two brown dogs runs through the water.', 'Zwei brauen Hunden rennen durch das Wasser.'), ('A woman throwing a Frisbee on a beach.', 'Eine Frau, die am Strand eine Frisbee-Scheibe wirft.'), ('These men are practicing martial arts.', 'Diese Männer machen Kampfsport.'), ('People having a barbecue by the beach.', 'Mehrere Personen grillen am Strand.'), ('A woman on a subway is falling asleep.', 'Eine Frau in einer U-Bahn schläft ein.'), ('A man driving a green miniature train.', 'Ein Mann, der einen grünen Miniaturzug fährt.'), ('Some children watching fish in a pool.', 'Ein paar Kinder beobachten Fische in einem Becken.'), ('A dog jumping in the water at a beack.', 'Ein Hund springt an einer Bake ins Wasser.'), ('These people are cooking lots of food.', 'Diese Leute kochen jede Menge Essen.'), ('A young boy pulls a car toy up a hill.', 'Ein kleiner Junge zieht ein Spielzeugauto einen Hügel hinauf.'), ('A young boy laying face down in water.', 'Ein Junge, der mit dem Gesicht nach unten im Wasser liegt.'), ('In a tree filled park a man stretches.', 'In einem Park mit vielen Bäumen streckt sich ein Mann.'), ('A boy and a girl playing on the beach.', 'Ein Junge und ein Mädchen, die am Strand spielen.'), ('An old man is napping on a park bench.', 'Ein alter Mann macht auf einer Parkbank ein Schläfchen.'), ('A boy reaches the top of a jungle gym.', 'Ein Junger erreicht das Oberteil eines Klettergerüsts.'), ('A person riding a bike on a snowy road.', 'Eine Person fährt auf einer verschneiten Straße Fahrrad.'), ('A crowd watching air balloons at night.', 'Eine Menschenmenge betrachtet nachts Ballons.'), ('A white dog has its head on the ground.', 'Ein weißer Hund hat seinen Kopf auf dem Boden.'), ('The boys smiles underwater at the pool.', 'Der Junge lächeln unter Wasser im Schwimmbad.'), ('A black dog jumping to catch a rope toy', 'Ein schwarzer Hund springt, um ein Seilspielzeug zu fangen.'), ('A female works out near the ocean side.', 'Eine Frau arbeitet im Freien in der Nähe des Ozeans.'), ('A young boy runs while wearing sandals.', 'Ein Junge rennt in weißen Sandalen.'), ('A female blacksmith is shoeing a horse.', 'Eine Schmiedin beschlägt ein Pferd.'), ('A lady wearing a helmet holding a bike.', 'Eine Dame, die einen Helm trägt und ein Fahrrad hält.'), ('A group of young people are in a garage', 'Eine Gruppe junger Menschen ist in einer Werkstatt.'), ('Girl learning about animals at the zoo.', 'Ein Mädchen, das im Zoo etwas über Tiere lernt.'), ('Terrier dog playing with toy on blanket', 'Ein Terrier, der auf einer Decke mit einem Spielzeug spielt.'), ('Two workers toil in a smelting factory.', 'Zwei Arbeiter leisten in einer Schmelzhütte harte Arbeit.'), ('A boy is sitting on rectangular blocks.', 'Ein Junge sitzt auf rechteckigen Blöcken.'), ('City workers fixing concrete on a road.', 'Städtische Arbeiter, die Beton auf einer Straße reparieren.'), ('A woman is drinking from a green straw.', 'Eine Frau, die mit einem grünen Strohhalm trinkt.'), ('Young African man does work in a field.', 'Ein junger afrikanischer Mann arbeitet in einem Feld.'), ('A man with a green shirt on is working.', 'Ein Mann mit einem grünen Hemd arbeitet.'), ('Two beige dogs are playing in the snow.', 'Zwei beige Hunde spielen im Schnee.'), ('Two men are at the stove preparing food.', 'Zwei Männer stehen am Herd und bereiten Essen zu.'), ('Two young toddlers outside on the grass.', 'Zwei Kleinkinder im Freien auf dem Gras.'), ('Men walking down a street with children.', 'Männer, die eine Straße mit Kindern entlang laufen.'), ('A girl with pigtails plays in the water.', 'Ein Mädchen mit Zöpfen spielt im Wasser.'), ('A child happily mixing batter in a bowl.', 'Ein Kind, das strahlend einen Teig in einer Schüssel rührt.'), ('A man and woman napping on a blue couch.', 'Ein Mann und eine Frau, die auf einer blauen Couch ein Schläfchen machen.'), ('Two men squat to light candles at night.', 'Zwei Männer gehen in die Hocke, um in der Nacht Kerzen anzuzünden.'), ('Dozens of people are partying on a boat.', 'Dutzende von Leuten feiern auf einem Boot.'), ('A kid with floaters jumping into a lake.', 'Ein Kind mit Schwimmflügeln, das in einen See springt.'), ('Two children play on the path in a park.', 'Zwei Kinder spielen in einem Park auf dem Pfad.'), ('Four men sitting and working on laptops.', 'Vier sitzende Männer arbeiten an Laptops.'), ('Three boys wearing Florida Marlins hats.', 'Drei Jungen, die Florida-Marlins-Kappen tragen.'), ('This picture of a man reading is tilted.', 'Dieses Bild eines lesenden Mannes ist schräg.'), ('Commuters rush to get on the late train.', 'Pendler beeilen sich, um den Spätzug zu erreichen.'), ('Two men in tall hats frown at the camera', 'Zwei Männer in hohen Hüten blicken stirnrunzelnd in die Kamera.'), ('Two people do jumping jacks on the beach', 'Zwei Personen machen am Strand Hampelmann.'), ('The 3 dogs are cruising down the street.', 'Die 3 Hunde sind auf der Straße unterwegs.'), ('Two young children are standing in hall.', 'Zwei kleine Kinder stehen in einem Flur.'), ('Kid about to go on bike ride with parent', 'Ein Kind, das gleich mit einem seiner Eltern Fahrrad fahren wird.'), ('A white dog jumping to catch a red ball.', 'Ein weißer Hund, der springt, um einen roten Ball zu fangen.'), ('The boy has blond-hair and a dirty face.', 'Der Junge hat blonde Haare und ein schmutziges Gesicht.'), ('Dogs running on a cold but sunny morning', 'Hunde rennen an einem kalten, aber sonnigen Morgen.'), ('You know i am looking like Justin Bieber.', 'Du weißt, dass ich aussehe wie Justin Bieber.'), ('A man fixing the road with his equipment.', 'Ein Mann, der die Straße mit seiner Maschine ausbessert.'), ('A boy has blown four bubbles on the lawn.', 'Ein Junge auf dem Rasen hat vier Blasen geblasen.'), ('A man on stage singing into a microphone.', 'Ein Mann auf der Bühne singt in ein Mikrophon.'), ('The small dog is running across the lawn.', 'Der kleine Hund rennt über den Rasen.'), ('A small child doing a handstand on a bed.', 'Ein Kleinkind, das auf einem Bett Handstand macht.'), ('Two dogs are wrestling in a grassy field.', 'Zwei Hunde balgen sich auf einer Wiese.'), ('A child is sliding down a hill on a sled.', 'Ein Kind rutscht auf einem Schlitten einen Hügel hinunter.'), ('A child is laying down on a wooden bench.', 'Ein Kind liegt auf einer Holzbank.'), ('A male with a hat is juggling four balls.', 'Eine männliche Person mit einem Hut jongliert vier Bälle.'), ('Family sitting on a bench near the beach.', 'Eine Familie sitzt auf einer Bank in der Nähe des Strands.'), ('A man in a white shirt is playing tennis.', 'Ein Mann in einem weißen Hemd spielt Tennis.'), ('A girl in a green shirt jumps in the air.', 'Ein Mädchen mit einem grünen Oberteil springt in die Luft.'), ('The waterskier does a flip behind a boat.', 'Das Wasserskifahrer macht hinter einem Boot einen Salto.'), ('Someone is taking a stroll on their bike.', 'Jemand macht einen Ausflug mit dem Fahrrad.'), ('A young girl tries her hand at gardening.', 'Ein Mädchen versucht sich als Gärtnerin.'), ('A person is setting at a table in a cafe.', 'Eine Person, die in einem Café an einem Tisch sitzt.'), ('People on a crowded train or bus in Asia.', 'Leute in einem vollen Zug oder Bus in Asien.'), ('Girl is standing out on the train tracks.', 'Ein Mädchen steht auf dem Gleis.'), ('A black dog and a spotted dog are fighting', 'Ein schwarzer Hund und ein gefleckter Hund kämpfen.'), ('A man showing off his new wooden creation.', 'Ein Mann führt seine neue hölzerne Kreation vor.'), ('A couple stands behind their wedding cake.', 'Ein Paar steht hinter seiner Hochzeitstorte.'), ('A man is standing in front of a skyscraper', 'Ein Mann steht vor einem Hochhaus.'), ('A woolly dog chases a Doberman on a beach.', 'Ein flauschiger Hund rennt am Strand einem Dobermann hinterher.'), ('Skiiers at the top of a snow covered hill.', 'Skifahrer oben auf einem schneebedeckten Hügel.'), ('Men are constructing a wall in the desert.', 'Männer bauen eine Wand in der Wüste.'), ('A boy in a Gap hat is making a silly face.', 'Ein Junge mit einer Gap-Hut macht ein dummes Gesicht.'), ('The four hikers walked up the gravel road.', 'Die vier Wanderer sind die Schotterstroße hochgelaufen.'), ('A child stands ready with a baseball mitt.', 'Ein Kind steht mit einem Fanghandschuh bereit.'), ('Group of people walking on the heavy snow.', 'Eine Gruppe geht durch den Tiefschnee.'), ('A white and tan dog leaps through the air.', 'Ein weiß-lohfarbener Hund springt durch die Luft.'), ('A man on bicycle riding down a rocky hill.', 'Ein Mann, der auf einem Fahrrad einen steinigen Hügel hinunterfährt.'), ('A woman realigns her sock in a messy park.', 'Eine Frau, die in einem unordentlichen Park ihre Socke richtet.'), ('Three boys play with paddles on the beach.', 'Drei Jungen spielen am Strand mit Paddeln.'), ('A woman in a black shirt is hugging a man.', 'Eine Frau mit einem schwarzen Oberteil umarmt einen Mann.'), ('A worker in a blue hat is fixing the wall.', 'Ein Arbeiter mit blauem Schutzhelm repariert die Mauer.'), ('Four boys run down a stone paved sidewalk.', 'Vier Jungen rennen einen gepflasterten Bürgersteig entlang.'), ('A man is pulling a cart covered in chairs.', 'Ein Mann zieht einen Karren voller Stühle.'), ('A brown dog is sitting in some long grass.', 'Ein brauner Hund sitzt in langem Gras.'), ('The man climbs through the rocks and snow.', 'Der Mann klettert durch Fels und Schnee.'), ('A man in green pants walking down the road.', 'Ein Mann in grünen Hosen läuft die Straße entlang.'), ('Three people walking on a path in a meadow.', 'Drei Personen, die auf einem Pfad in einer Wiese gehen.'), ('The boy eats his food outside at the table.', 'Der Junge isst sein Essen draußen am Tisch.'), ('People jogging together on a park sidewalk.', 'Leute, die zusammen auf einem Fußweg im Park joggen.'), ('A boy in his blue swim shorts at the beach.', 'Ein junge in blauen Badehosen am Strand.'), ('The little boy rides his bicycle in a race.', 'Der kleine Junge fährt Fahrrad in einem Rennen.'), ('Men in safety vests are working on a track.', 'Männer in Schutzwesten arbeiten auf einem Gleis.'), ('Small boy carries a soccer ball on a field.', 'Ein kleiner Junge auf einem Fußballplatz trägt einen Fußball.'), ('A man in red pants jumping on a park table.', 'Ein Mann in roten Hosen, der auf einen Parktisch springt.'), ('A person stands on a structure on the lake.', 'Eine Person steht auf einem Bauwerk auf dem See.'), (\"A women's roller derby team taking a break.\", 'Das Rollschuhderby-Team einer Frau bei einer Pause.'), ('A young man cleaning a statue with a brush.', 'Ein junger Mann, der mit einer Bürste eine Statue reinigt.'), ('Old lady sitting in a room full of flowers.', 'Eine alte Dame, die in einem Raum voller Blumen sitzt.'), ('This man is smiling very big at the camera.', 'Dieser Mann lächelt sehr breit in die Kamera.'), ('A man with red-hair working on his bicycle.', 'Ein rothaariger Mann, der auf seinem Fahrrad arbeitet.'), ('The little girl is riding in a brown horse.', 'Das kleine Mädchen reitet mit einem braunen Pferd herein.'), ('A boy in a red sweater running on the beach', 'Ein Junge in einem roten Pullover, der am Strand rennt.'), ('A man in a black hat walks down the street.', 'Ein Mann mit schwarzem Hut geht die Straße entlang.'), ('A man in a yellow vest sweeping a sidewalk.', 'Ein Mann in einer gelben Weste, der einen Gehweg kehrt.'), ('A woman is pushing a young girl in a swing.', 'Eine Frau gibt einem Mädchen auf einer Schaukel Schwung.'), ('Two large tan dogs play along a sandy beach.', 'Zwei große lohfarbene Hunde spielen an einem sandigen Strand.'), ('Villagers selling their crops at the market.', 'Dorfbewohner verkaufen ihre Ernte auf dem Markt.'), ('A driver communicating on his walkie talkie.', 'Ein Fahrer kommuniziert mit seinem Walkie-Talkie.'), ('A woman standing in front of a chalk drawing', 'Eine Frau steht vor einem Kalkstein und malt.'), ('Dog running out of tunnel on obstacle course', 'Ein Hund rennt auf der Hindernisstrecke aus dem Tunnel heraus.'), ('A man and child on a ship doing maintenance.', 'Ein Mann und ein Kind auf einem Schiff bei Wartungsarbeiten.'), ('A girl blowing bubbles in the swimming pool.', 'Ein Mädchen macht im Schwimmbad Blasen.'), ('A young boy picks up a paintbrush and grins.', 'Ein Junge hebt einen Pinsel auf und grinst.'), ('A kid may be playing soccer while in a suit.', 'Ein Kind in einem Anzug spielt so etwas wie Fußball.'), ('A man is sitting behind a hard wood counter.', 'Ein Mann sitzt hinter einer Theke aus Hartholz.'), ('Two girls standing on grass face each other.', 'Zwei Mädchen stehen einander auf Gras gegenüber.'), ('A man is painting on a sidewalk in the city.', 'Ein Mann malt auf einen Gehweg in der Stadt.'), ('A asian man gives an evil eye to the camera.', 'Ein asiatischer Mann, der mit bösem Blick in die Kamera sieht.'), ('Young chefs are arranging food in a kitchen.', 'Junge Köche arrangieren in einer Küche Speisen.'), ('A man in a white t-shirt cleaning up debris.', 'Ein Mann in einem weißen T-Shirt, der Abfälle entsorgt.'), ('A vendor standing in the window of her shop.', 'Eine Verkäuferin, die im Fenster ihres Ladens steht.'), ('A man standing at a urinal with a coffee cup.', 'Ein Mann, der mit einer Tasse Kaffee an einem Urinal steht.'), ('A woman is laying on a red blanket in a park.', 'Eine Frau liegt auf einer roten Decke in einem Park.'), ('A man is standing on a ladder painting bricks', 'Ein Mann steht auf einer Leiter und malt Ziegel.'), ('A man is sleeping on a bench near a bus stop.', 'Ein Mann schläft auf einer Bank in der Nähe einer Bushaltestelle.'), ('Bikers in a bike race take a sharp left turn.', 'Zweiradfahrer in einem Rennen biegen scharf nach links ab.'), ('Men at work shoveling snow from a rail track.', 'Arbeitende Männer schaufeln Schnee von einem Gleis.'), ('A white and black dog is jumping into a pool.', 'Ein weißer und ein schwarzer Hund springen in einen Pool.'), ('Smiling little girl swimming in outdoor pool.', 'Ein lächelndes kleines Mädchen, das in einem Pool im Freien schwimmt.'), ('Man paddling a boat on a river near the bank.', 'Ein Mann, der ein Boot auf dem Fluss in der Nähe des Ufers mit Paddeln vorwärtsbewegt.'), ('Some construction workers are taking a break.', 'Ein paar Bauarbeiter, die eine Pause machen.'), ('People at a distance trying to climb a cliff.', 'Menschen in der Ferne versuchen, an einem Felsabhang hoch zu klettern.'), ('Two dogs are playing together on green grass.', 'Zwei Hunde spielen zusammen auf grünem Gras.'), ('Two boys playing in the water wearing shorts.', 'Zwei Jungen mit kurzen Hosen, die im Wasser spielen.'), ('A boy experiencing and exhibit at the museum.', 'Ein Junge, der eine Ausstellung im Museum erlebt.'), ('A tall man stirring a pot of food on a stove.', 'Ein großer Mann, der einen Topf mit Essen rührt, der auf einem Herd steht.'), ('A man is standing on a street holding a sign.', 'Ein Mann steht auf einer Straße und hält ein Schild.'), ('Child on a small motorbike near a small pond.', 'Ein Kind auf einem kleinen Motorrad in der Nähe eines kleinen Teichs.'), ('A young boy in a swimming suit sits in water.', 'Ein Junge im Schwimmanzug sitzt im Wasser.'), ('Woman in a bikini top is walking on the beach', 'Eine Frau in einem Bikini-Oberteil geht den Strand entlang.'), ('An asian man in a suit on the subway, asleep.', 'Ein asiatischer Mann in einem Anzug in der U-Bahn, schlafend.'), ('A man in dirty jeans on top of a scaffolding.', 'Ein Mann in schmutzigen Jeans oben auf einem Gerüst.'), ('A woman with glasses drinks coffee at a cafe.', 'Eine Frau mit Brille trinkt in einem Cafe Kaffee.'), ('A man in an orange shirt is taking a picture.', 'Ein Mann in einem orangefarbenen Hemd macht ein Foto.'), ('A man with a backwards hat works on machinery.', 'Ein Mann mit einem nach hinten gerichteten Hut arbeitet an Maschinen.'), (\"A little boy playing GameCube at a McDonald's.\", \"Ein kleiner Junge spielt bei McDonald's GameCube.\"), ('A group of people having a barbecue at a park.', 'Eine Gruppe von Personen, die im Park grillen.'), ('A shirtless man and a woman sitting on a dock.', 'Ein Mann mit nacktem Oberkörper und eine Frau sitzen auf einem Dock.'), ('An elderly woman pan frying food in a kitchen.', 'Eine ältere Frau brät in einer Küche etwas in der Pfanne an.'), ('A couple kissing while going up the escalator.', 'Ein küssendes Paar im Aufzug.'), ('People on bicycles waiting at an intersection.', 'Personen auf Fahrrädern, die an einer Kreuzung warten.'), ('Two bicyclists pose by a stream for a picture.', 'Zwei Radfahrer an einem Bach posieren für ein Foto.'), ('Groups of people observe fish in a large tank.', 'Menschengruppe beobachten Fische in einem großen Becken.'), ('A girl in a red bikini is jumping into a pool.', 'Ein Mädchen mit einem roten Bikini springt in ein Schwimmbecken.'), ('A farmer walks his pet pig down the dirt road.', 'Ein Bauer geht treibt sein Schwein den Feldweg entlang.'), ('A little girl climbing into a wooden playhouse.', 'Ein kleines Mädchen klettert in ein Spielhaus aus Holz.'), ('Two children sit on a small seesaw in the sand.', 'Zwei Kinder sitzen auf einer kleinen Wippe im Sand.'), ('A white dog is about to catch a yellow dog toy.', 'Ein weißer Hund ist kurz davor, ein gelbes Hundespielzeug zu fangen.'), ('A skier is overlooking a snow-covered mountain.', 'Ein Skifahrer blickt auf einen schneebedeckten Berg.'), ('A black and white dog jumps after a yellow toy.', 'Ein schwarz-weißer Hund spring nach einem gelben Spielzeug.'), ('A boy covered in suds has his face wiped clean.', 'Ein von Seifenschaum bedeckter Junge bekommt das Gesicht abgewischt.'), ('People are crossing a city street intersection.', 'An einer Kreuzung überqueren mehrere Personen die Straße.'), ('A mexican man sits under the hood of his truck.', 'Ein mexikanischer Mann sitzt unter der Motorhaube seines Lkws.'), ('A white baby boy crying over a tipped over toy.', 'Ein weißes männliches Baby weint wegen eines umgekippten Spielzeugs.'), ('Two men in a room looking at a computer screen.', 'Zwei Männer in einem Raum, die auf einen Computerbildschirm blicken.'), ('A man wearing a black jacket is playing guitar.', 'Ein Mann mit schwarzem Jackett spielt Gitarre.'), ('A young baby sucking a Binky asleep in a chair.', 'Ein kleines Baby saugt in einem Stuhl schlafend an einem Binky.'), ('Eleven little girls posing as a team in a pool.', 'Elf kleine Mädchen posieren in einem Schwimmbecken als Team.'), ('The lady in the red car is crossing the bridge.', 'Die Dame im roten Auto fährt über die Brücke.'), ('Two and four footed neighbors stop by to visit.', 'Zwei- und vierbeinige Nachbarn kommen auf einen Besuch vorbei.'), ('A man on stage performing a concert for people.', 'Ein Mann auf der Bühne, der für das Publikum ein Konzert gibt.'), ('A man walking down the street with a small boy.', 'Ein Mann, der mit einem kleinen Jungen die Straße entlanggeht.'), ('A girl removes her eye makeup with an ear swab.', 'Ein Mädchen entfernt ihr Augen-Makeup mit einem Ohrtupfer.'), ('Three women in dresses and headscarves outside.', 'Drei Frauen mit Kleidern und Kopftüchern im Freien.'), ('A woman with a large purse is walking by a gate.', 'Eine Frau mit einer großen Geldbörse geht an einem Tor vorbei.'), ('A man and a baby are in a yellow kayak on water.', 'Ein Mann und ein Baby befinden sich in einem gelben Kajak auf dem Wasser.'), ('Two men and two women sitting on steps outdoors.', 'Zwei Männer und zwei Frauen, die auf Treppenstufen im Freien sitzen.'), ('A solitary man stand on a bridge in the evening.', 'Ein einzelner Mann steht abends auf einer Brücke.'), ('Three people rest on a ledge above the moutains.', 'Drei Personen machen auf einem Felsvorsprung über den Bergen Rast.'), ('Several firefighters are responding to an alarm.', 'Mehrere Feuerwehrleute reagieren auf einen Alarm.'), ('A teenage boy is jumping on an inflatable slide.', 'Ein männlicher Teenager springt auf einer aufblasbaren Rutsche.'), ('A family playing on a tractor on a beautiful day', 'Eine Familie spielt an einem schönen Tag auf einem Traktor.'), ('A girl working at a farm market selling peppers.', 'Ein Mädchen, das auf einer Farm arbeitet und Paprika verkauft.'), ('Two people working on removing snow from a roof.', 'Zwei Personen arbeiten daran, den Schnee von einem Dach zu entfernen.'), ('A woman is walking at dusk down an urban street.', 'Eine Frau läuft in der Dämmerung eine städtische Straße entlang.'), ('Workman are completing repairs on a city street.', 'Arbeiter führen Reparaturen auf einer städtischen Straße durch.'), ('A woman in pink cuts a hamburger with a spatula.', 'Eine Frau ein Rosa schneidet einen Hamburger mit einem Bratenwender.'), ('A man standing beside the back of a nude statue.', 'Ein Mann, der neben dem Rücken einer Aktskulptur steht.'), ('Young boy and an older man waiting to check out.', 'Ein Junge und ein älterer Mann, die aufs Auschecken warten.'), ('A man wearing suspenders in standing on a train.', 'Ein Mann mit Hosenträgern, der auf einem Zug steht.'), ('A boy with glasses and plaid shirt reads a book.', 'Ein Junge mit Brille und kariertem Hemd liest ein Buch.'), ('A brown dog jumping in the air on a brown plain.', 'Ein brauner Hund spring auf einer braunen Ebene in die Luft.'), ('The man is wearing a white shirt and sunglasses.', 'Der Mann trägt ein weißes Hemd und eine Sonnenbrille.'), ('A man creating a clay object at a potters wheel.', 'Ein Mann stellt an einer Töpferscheibe ein Objekt aus Ton her.'), ('The kids play in the wooded area near the water.', 'Die Kinder spielen im Waldgebiet in der Nähe des Wassers.'), ('Kids playing at a playground on a stack of tires', 'Kinder spielen auf einem Reifenstapel auf einem Spielplatz.'), ('A woman in a light blue jacket is riding a bike.', 'Eine Frau in einer hellblauen Jacke fährt Fahrrad.'), ('Women in bike helmets take break from long ride.', 'Frauen mit Fahrradhelmen machen nach langer Fahrt eine Pause.'), ('A boy jumps from one table to another at a park.', 'Ein Junge springt in einem Park von einem Tisch auf einen anderen.'), ('A woman is sitting on a stool with an accordion.', 'Eine Frau sitzt mit einem Akkordeon auf einem Hocker.'), ('Two girls are performing tricks on a trampoline.', 'Zwei Mädchen führen auf einem Trampolin Kunststücke vor.'), ('A pair of dancers perform on a red brick street.', 'Ein Tänzerpaar führt etwas auf einer roten Ziegelstraße auf.'), ('A man studying for his exams outside a bookstore', 'Ein Mann lernt vor einer Buchhandlung auf seine Prüfung.'), ('A marketplace with rolling carts selling fruits.', 'Ein Marktplatz mit fahrbaren Wagen, wo Obst verkauft wird.'), ('Two boys posing in blue shirts and khaki shorts.', 'Zwei Jungen posieren in blauen Hemden und khakifarbenen Shorts.'), ('Boys dancing on poles in the middle of the night.', 'Jungen tanzen mitten in der Nacht auf Pfosten.'), ('A ballet class of five girls jumping in sequence.', 'Eine Ballettklasse mit fünf Mädchen, die nacheinander springen.'), ('Two skiers are making their way through woodland.', 'Zwei Skifahrer machen sich auf den Weg durch Waldland.'), ('Woman meticulously working with a sewing machine.', 'Eine Frau, die mit der Nähmaschine präzise arbeitet.'), ('A man in an orange vest standing atop a building.', 'Ein Mann in einer orangefarbenen Weste steht oben auf einem Gebäude.'), ('People walking up and down the steps to a church.', 'Leute gehen die Treppe zu einer Kirche auf und ab.'), ('Two women holding hands in the air while jumping.', 'Zwei Frauen, die sich beim Springen in der Luft an den Händen halten.'), ('Men and women on bikes stop to look at something.', 'Männer und Frauen auf Fahrrädern halten an, um sich etwas anzusehen.'), ('Three young girls dance on the beach in the sand.', 'Drei Mädchen, die am Strand im Sand tanzen.'), ('Two children are standing on a green metal fence.', 'Zwei Kinder stehen auf einem grünen Metallzaun.'), ('A woman is being interviewed at her dining table.', 'Eine Frau wird an ihrem Esstisch befragt.'), ('A woman orders a dish at a street kitchen vendor.', 'Eine Frau bestellt bei einem Straßenküchenverkäufer ein Gericht.'), ('A black dog and a white dog are standing on snow.', 'Ein schwarzer Hund und ein weißer Hund stehen im Schnee.'), ('An Asian woman in a red sweater holding her baby.', 'Eine asiatische Frau in rotem Pullover, die ihr Baby hält.'), ('A young woman at an open air market buying bread.', 'Eine junge Frau, die Brot kauft, auf einem Markt im Freien.'), ('A man with swords battling a female with a spear.', 'Ein Mann mit Schwertern, der gegen eine Frau mit einem Speer kämpft.'), ('A man in a red shirt is sitting by fruit for sale.', 'Ein Mann in einem roten Hemd sitzt neben Obst, das zu verkaufen ist.'), ('A little girl looking at a brochure on train rides', 'Ein kleines Mädchen blickt auf eine Broschüre über Zugfahrten.'), ('Two chefs prepare burgers in a restaurant kitchen.', 'Zwei Köche bereiten in einer Restaurantküche Hamburger zu.'), ('Many scooters are parked together on the sidewalk.', 'Viele Motorroller sind zusammen auf dem Gehweg geparkt.'), ('A man on a four wheeler is flying through the air.', 'Ein Mann auf einem Allradfahrzeug fliegt durch die Luft.'), ('A man dressed in a funky outfit is playing guitar.', 'Ein Mann in einem flippigen Outfit spielt Gitarre.'), ('A brunette woman walking down a street with a cup.', 'Eine brünette Frau, die mit einer Tasse die Straße entlang geht.'), ('A small girl spins in the waves in the bright sun.', 'Ein kleines Mädchen dreht sich in den Wellen in der hellen Sonne.'), ('A tan colored dog is jumping into an outdoor pool.', 'Ein lohfarbener Hund spring in einen Pool im Freien.'), ('A middle-aged woman cooking while her dog watches.', 'Eine Frau im mittleren Alter, die kocht, während ihr Hund zusieht.'), ('People waiting outside a building next to a mural.', 'Leute warten vor einem Gebäude neben einem Wandgemälde.'), ('Eight gentlemen are working with stone &amp; tile.', 'Acht Herren arbeiten mit Steinen und Fliesen.'), ('A black dog and a brown dog playing in tall weeds.', 'Ein schwarzer Hund und ein brauner Hund, die in hohem Unkraut spielen.'), ('A little girl with a tiara eating in someones lap.', 'Ein kleines Mädchen mit einem Diadem, das jemandem auf dem Schoß sitzt und etwas isst.'), ('A man in shorts is chopping wood outside a teepee.', 'Ein Mann in kurzen Hosen hackt vor einem Indianerzelt Holz.'), ('A waiter presenting an order to the kitchen staff.', 'Ein Kellner, der Küchenpersonal eine Bestellung überbringt.'), ('Two bicyclists riding beside some railroad tracks.', 'Zwei Fahrradfahrer fahren neben Eisenbahnschienen entlang.'), ('Two people with yellow backpacks hiking up a hill.', 'Zwei Leute mit gelben Rucksäcken, die einen Hügel hinauf wandern.'), ('Two gray dogs run through a field of pink heather.', 'Zwei graue Hunde rennen durch ein Feld mit rosa blühender Heide.'), ('The two racers drove the white bike down the road.', 'Die zwei Rennfahrer sind mit dem weißen Rad die Straße entlang gefahren.'), ('Two puppies run across flat stones in garden area.', 'Zwei Welpen rennen über flache Steine in einem Gartenbereich.'), ('A group of people carry things down a narrow road.', 'Eine Gruppe von Menschen trägt Dinge eine schmale Straße entlang.'), ('A young boy in a white shirt is holding a wrapper.', 'Ein Junge in einem weißen Hemd hält ein Einschlagpapier.'), ('Older man in orange jumpsuit holding a water hose.', 'Ein älterer Mann in einem orangefarbenen Overall, der einen Wasserschlauch hält.'), ('Individuals with balloons participating in a walk.', 'Personen mit Luftballons, die an einem Spaziergang teilnehmen.'), ('A man opening a barbecue oven while holding tongs.', 'Ein Mann, der einen Grillofen öffnet und eine Zange hält.'), ('Little boy pushing another little boy up the pole.', 'Ein kleiner Junge, der einen anderen kleinen Jungen den Mast hoch schiebt.'), ('Man in a red shirt riding his bicycle around water.', 'Ein Mann in einem roten Hemd, der mit dem Fahrrad um Wasser herum fährt.'), ('Man on skis looking at artwork for sale in the snow', 'Mann auf Skiern, das zu verkaufende Kunstwerke im Schnee betrachtet.'), ('A couple sit on the grass with a baby and stroller.', 'Ein Paar sitzt mit Baby und Sportwagen im Gras.'), ('A man is drilling through the frozen ice of a pond.', 'Ein Mann bohrt durch das gefrorene Eis eines Teichs.'), ('A boy jumps on his skateboard while a crowd watches', 'Ein Junge springt auf seinem Skateboard, und eine Menschenmenge sieht zu.'), ('Men wearing hard hats and safety vests are working.', 'Männer mit Schutzhelmen und Schutzwesten arbeiten.'), ('A baby is sitting on and playing with smooth rocks.', 'Ein Baby sitzt auf glatten Steinen und spielt mit ihnen.'), ('A person in a hat is playing with a boy on a beach.', 'Eine Person mit Hut, die mit einem Jungen am Strand spielt.'), ('A little girl playing in water on a frog sculpture.', 'Ein kleines Mädchen, das im Wasser auf einer Froschskulptur spielt.'), ('A person in blue shorts and wearing a Walkman jogs.', 'Eine Person in blauen Shorts, die einen Walkman trägt, joggt.'), ('A group of friends are fishing off the loading ramp', 'Eine Gruppe von Freunden, die von der Laderampe aus fischen.'), ('Three men are setting up a sledge on a snowy plain.', 'Drei Männer richten auf einer verschneiten Ebene einen Schlitten.'), ('A man in a red shirt is giving toys to a small dog.', 'Ein Mann in einem roten Hemd gibt einem kleinen Hund Spielzeuge.'), ('Colored woman rolling a bowling ball down an alley.', 'Eine farbige Frau, die eine Bowlingkugel auf eine Bahn rollt.'), ('Construction workers work on a road into the night.', 'Bauarbeiter arbeiten bis in die Nacht hinein an einer Straße.'), ('A man sleeps in a hammock next to water and a boat.', 'Ein Mann schläft in einer Hängematte neben dem Wasser und einem Boot.'), ('People are standing on a platform to board a train.', 'Menschen stehen auf einem Gleis, um in einen Zug zu steigen.'), ('People waiting in line for their favorite beverage.', 'Leute warten in einer Schlange auf ihr Lieblingsgetränk.'), (\"A woman in a red dress covers another woman's eyes.\", 'Eine Frau in einem roten Kleid bedeckt die Augen einer anderen Frau.'), ('A man on a phone and woman sitting near a painting.', 'Ein Mann am Telefon und eine Frau, die in der Nähe eines Gemäldes sitzen.'), ('A female looking out the window as a male looks in.', 'Eine weibliche Person, die aus dem Fenster blickt, während eine männliche Person hinein blickt.'), ('Three boys in size order getting wet next to a wall', 'Drei der Größe nach angeordnete Jungen neben einer Mauer, die nass werden.'), ('A boy in blue shirt splashing in water under a dock', 'Ein Junge in blauem Hemd, der unter einem Dock im Wasser planscht.'), ('A young man in a red shirt cooking in a frying pan.', 'Ein junger Mann mit rotem Hemd, der etwas in einer Pfanne zubereitet.'), ('Two young, White males are outside near many bushes.', 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'), ('A crowd is standing and waiting for the green light.', 'Eine Menschenmenge steht und wartet, bis die Ampel grün wird.'), ('A black and white dog jumps up towards a yellow toy.', 'Ein schwarz-weißer Hund spring zu einem gelben Spielzeug hoch.'), ('Three old men are watching another man prepare fish.', 'Drei alte Männer sehen einem anderen Mann zu, wie er Fisch zubereitet.'), ('A man in a black shirt plays a black-colored guitar.', 'Ein Mann in einem schwarzen Hemd spielt eine schwarze Gitarre.'), ('A young boy overlooking a crowd of inflatable boats.', 'Ein Junge blickt auf eine Ansammlung von Schlauchbooten.'), ('Two little girls and an old man have a conversation.', 'Zwei kleine Mädchen und ein alter Mann unterhalten sich.'), ('A little kid is jumping off a high dive at the pool.', 'Ein kleines Kind springt von einem Sprungturm am  hohen Brett am Schwimmbecken.'), ('A man on a four-wheeler jumps near a small building.', 'Ein Mann auf einem Allradfahrzeug springt in der Nähe eines kleinen Gebäudes.'), ('Two tennis players are talking on the tennis courts.', 'Zwei Tennisspieler sprechen in einer Tennisanlage.'), ('A brown and white dog stands outside while it snows.', 'Ein braun-weißer Hund steht im Freien, während es schneit.'), ('A child getting out of the car wearing soccer shoes.', 'Ein Kind, das auf dem Auto kommt und Fußballschuhe trägt.'), ('A young lady sits in front of a fence with a bucket.', 'Eine junge Dame sitzt vor einem Zaun mit einem Eimer.'), ('A group of people walking down a trail in the woods.', 'Eine Gruppe geht einen Pfad im Wald hinunter.'), ('A child is playing in the street, doing a cartwheel.', 'Ein Kind spielt in der Straße und schlägt ein Rad.'), ('A group of children in brown outfits are performing.', 'Eine Gruppe von Kindern in brauner Kleidung führt etwas vor.'), ('A man with a large feather in his hat rides a horse.', 'Ein Mann mit einer großen Feder im Hut reitet ein Pferd.'), ('A man and woman enjoy a cigarette outside of a shop.', 'Ein Mann und eine Frau genießen eine Zigarette vor einem Laden.'), ('Many people are standing and are watching something.', 'Viele Menschen stehen herum und sehen etwas an.'), ('An adult and a child sitting on a police motorcycle.', 'Eine erwachsene Person und ein Kind, die auf einem Polizeimotorrad sitzen.'), ('A woman in black is playing a Cello type instrument.', 'Eine Frau in Schwarz spielt ein celloartiges Instrument.'), ('A girl with a black purse sitting on a wooden bench.', 'Ein Mädchen mit einer schwarzen Handtasche sitzt auf einer Holzbank.'), ('A woman standing at the counter of a takeout window.', 'Eine Frau steht am Fenster eines Imbissfensters.'), ('Three young women perform a dance in a crowded hall.', 'Drei Frauen, die in einem vollen Saal einen Tanz vorführen.'), ('Two people are swimming in water next to a red buoy.', 'Zwei Personen schwimmen neben einer roten Boje.'), ('A fisherman is preparing his nets for his next haul.', 'Ein Fischer bereitet die Netze für seinen nächsten Fischzug vor.'), ('A small girl playing, on the sidewalk, with a stick.', 'Ein kleines Mädchen, das auf dem Gehweg mit einem Stock spielt.'), ('The sunshine behind a group of trees on a long rode.', 'Der Sonnenschein hinter einer Baumgruppe an einer langen Straße.'), ('Five people are sitting in a circle with instruments.', 'Fünf Personen sitzen mit Instrumenten im Kreis.'), ('A young boy is pushing a toy ATV around a rubber pool', 'Ein Junge schiebt ein Spielzeug-Geländefahrzeug um einen Gummi-Pool.'), ('A person in blue and red ice climbing with two picks.', 'Eine Person in blau und rot, die mit zwei Pickeln eisklettert.'), ('Toddler boy in a red hat holding on to some railings.', 'Männliches Kleinkind in einem roten Hut, das sich an einem Geländer festhält.'), ('Two construction workers take a seat on a steel beam.', 'Zwei Bauarbeiter sitzen auf einem Stahlbalken.'), ('A beach with blue and red boats, with people on shore', 'Ein Strand mit blauen und roten Booten und Leuten am Ufer.'), ('Woman on a hill by a white cross overlooking a beach.', 'Frau auf einem Hügel neben einem weißen Kreuz, die auf einen Strand blickt.'), ('A group of kids in class with their hands in the air.', 'Eine Gruppe von Kindern im Unterricht, die sich zu Wort melden.'), ('Group setting up a wooden cross near a large boulder.', 'Eine Gruppe stellt in der Nähe eines großen Felsblocks ein Holzkreuz auf.'), ('The old man in the brown hat is sitting on the bench.', 'Der alte Mann mit dem braunen Hut sitzt auf der Bank.'), ('Five construction workers dig a hole to plant a tree.', 'Fünf Bauarbeiter graben ein Loch, um einen Baum zu pflanzen.'), ('People sitting in a circle with a book in the middle.', 'Mehrere Personen sitzen im Kreis mit einem Buch in der Mitte.'), ('Parents are pushing little children in red car carts.', 'Eltern schieben kleine Kinder in roten Auto-Einkaufwagen.'), ('Three children are playing with a red ball in a park.', 'Drei Kinder spielen in einem Park mit einem roten Ball.'), ('A man and a woman can prepare meals at camp together.', 'Ein Mann und eine Frau können im Lager zusammen Mahlzeiten vorbereiten.'), ('Two women wearing hats covered in flowers are posing.', 'Zwei Frauen posieren mit Hüten, die von Blumen bedeckt sind.'), ('A teenage boy is talking to a group of teenage girls.', 'Ein männlicher Teenager spricht zu einer Gruppe weiblicher Teenager.'), ('A boy in a wetsuit jumps into a pool with a bald man.', 'Ein Junge in einem Taucheranzug springt in ein Schwimmbecken mit einem glatzköpfigen Mann.'), ('A girl in a pink shirt lies on her back in the grass.', 'Ein Mädchen, das ein rosafarbenes Oberteil trägt, liegt im Gras auf dem Rücken.'), ('Young girl in blue dress stepping over a soccer ball.', 'Ein Mädchen in einem blauen Kleid, das über einen Fußball steigt.'), ('Two children are playing on a makeshift barrel swing.', 'Zwei Kinder spielen auf einer improvisierten Fassschaukel.'), ('These two women are having fun while taking pictures.', 'Diese beiden Frauen haben Spaß und machen Fotos.'), ('This boy is playing on a playground with tires on it.', 'Dieser Junge spielt auf einem Spielplatz mit Reifen darauf.'), ('A SCUBA diver swimming deep underwater with a turtle.', 'Ein Sporttaucher, der tief unter Wasser mit einer Schildkröte schwimmt.'), ('Three working class African American men are outside.', 'Drei afroamerikanische Männer aus der Arbeiterklasse sind im Freien.'), ('The small child climbs on a red ropes on a playground.', 'Das kleine Kind klettert an roten Seilen auf einem Spielplatz.'), ('A man and his dog are grilling green beans on a grill.', 'Ein Mann und sein Hund grillen grüne Bohnen auf einem Grill.'), ('A security guard stands by a metal, lighted sculpture.', 'Ein Wachmann steht neben einer beleuchteten Metallskulptur.'), ('A woman assembles a white metal frame on the sidewalk.', 'Eine Frau baut auf dem Gehweg einen weißen Metallrahmen zusammen.'), ('A person climbing down a sheer rock cliff using a rope', 'Eine Person klettert eine steile Felswand herunter und verwendet dazu ein Seil.'), ('The group of hikers is resting in front of a mountain.', 'Die Wandergruppe macht vor einem Berg Rast.'), ('Man is standing on white sand and holding a snowboard.', 'Ein Mann steht auf weißem Sand und hält ein Snowboard.'), ('A brown-haired woman looks at a baby eating something.', 'Eine braunhaarige Frau blickt auf ein Baby, das etwas isst.'), ('A man and a woman play on a tree while others look on.', 'Ein Mann und eine Frau spielen auf einem Baum, während andere zusehen.'), ('Two people are standing in a field holding some books.', 'Zwei Personen stehen in einem Feld und halten ein paar Bücher.'), ('A groundskeeper has collected a bucket full of sticks.', 'Ein Platzwart hat einen Eimer voller Stöcke gesammelt.'), ('A mother and son read a book about dinosaurs together.', 'Eine Mutter und ein Sohn lesen zusammen ein Buch über Dinosaurier.'), ('A person is sitting behind two large baskets of bread.', 'Eine Person sitzt hinter zwei großen Brotkörben.'), ('A guy wearing protective gear is welding a steel beam.', 'Ein Mann in Schutzausrüstung schweißt einen Stahlbalken.'), ('Two children wearing jeans squirt water at each other.', 'Zwei Kinder in Jeans spritzen Wasser aufeinander.'), ('A man on a ladder wearing blue jacket and a blue jeans', 'Ein Mann auf einer Leiter mit blauer Jacke und blauen Jeans'), ('A man on stilts stands in front of a line of drummers.', 'Ein Mann auf Stelzen steht vor eine Reihe von Trommlern.'), ('Customers are waiting for service at a takeout window.', 'Kunden warten am Fenster eines Imbisses darauf, bedient zu werden.'), ('Group of people standing or sitting outside of a cafe.', 'Eine Gruppe steht oder sitzt vor einem Café.'), ('A man adjusts the knobs on a large sound mixing board.', 'Ein Mann stellt die Knöpfe eines großen Mischpults ein.'), ('A woman wearing a blue jacket reaching out to a child.', 'Eine Frau mit einer blauen Jacke, die nach einem Kind greift.'), ('A male gymnast leaps over a stack of wooden platforms.', 'Ein Turner springt über einen Stapel Holzplattformen.'), ('Four people walking across thick snow during a sunset.', 'Vier Personen, die bei Sonnenuntergang durch dicken Schnee waten.'), ('Two boys stand beside a pile of garbage on the ground.', 'Zwei Jungen stehen neben einem Haufen Müll auf dem Boden.'), ('A construction site on a street with three men working.', 'Eine Baustelle auf einer Straße mit drei arbeitenden Männern.'), ('Two children play with a balloon in mud on a sunny day.', 'Zwei Kinder spielen an einem sonnigen Tag mit einem Luftballon im Matsch.'), ('A woman in a blue jacket rides a brown pony near water.', 'Eine Frau in einer blauen Jacke, die in Wassernähe ein braunes Pony reitet.'), ('Two people having a discussion sitting in a restaurant.', 'Zwei Leute, die in einem Restaurant sitzen, diskutieren.'), ('A man sitting on a wall and looking at a body of water.', 'Ein Mann, der auf einer Wand sitzt und aufs Wasser blickt.'), ('Three men are looking at a sign on a cross in a canyon.', 'Drei Männer blicken auf ein Zeichen auf einem Kreuz in einer Schlucht.'), ('Numerous people sitting on the ground near a straw hut.', 'Zahlreiche Menschen, die in der Nähe einer Strohhütte auf dem Boden sitzen.'), ('The dark brown dog is playing with the light brown dog.', 'Der dunkelbraune und spielt mit dem hellbraunen Hund.'), ('A man in a red and white checked shirt plays in a park.', 'Ein Mann in einem rot-weiß-karierten Hemd spielt in einem Park.'), ('A man with facial hair in white clothes eating a steak.', 'Ein Mann mit Bart in weißer Kleidung, der ein Steak isst.'), ('A young man with ginger hour is playing a game of pool.', 'Ein junger Mann mit rotblondem Haar spielt Billard.'), ('A blond girl in a white dress holding a bird in a tree.', 'Ein blondes Mädchen in einem weißen Kleid, das einen Vogel in einem Baum hält.'), ('Island woman cooking outside with pineapples and fruit.', 'Eine Inselbewohnerin, die im Freien mit Ananas und Obst kocht.'), ('A large structure has broken and is laying in a roadway.', 'Ein großes Bauwerk ist kaputt gegangen und liegt auf einer Fahrbahn.'), ('A man in a white shirt rides a bicycle on a busy street.', 'Ein Mann in einem weißen Hemd fährt auf einer belebten Straße Fahrrad.'), ('Two women are sitting and talking and laughing together.', 'Zwei Frauen sitzen, reden und lachen zusammen.'), ('Elderly man with a cane bends over near a man and woman.', 'Ein älterer Mann mit einem Stock beugt sich in der Nähe eines Mannes und einer Frau vor.'), ('A group of people sitting at a table in a darkened room.', 'Eine Gruppe sitzt in einem verdunkelten Raum an einem Tisch.'), ('A group of people are sitting on stools eating some food', 'Eine Gruppe sitzt auf Hockern und isst etwas.'), ('A little girl in a denim jacket running through a field.', 'Ein kleines Mädchen in einer Jeansjacke rennt durch ein Feld.'), ('Boys on a motor-scooter riding down a busy urban street.', 'Jungen auf einem Motorroller fahren eine vielbefahrene städtische Straße entlang.'), ('Man with red shoes, white shirt and gray pants climbing.', 'Ein Mann mit roten Schuhen, weißem Hemd und grauen Hosen, der klettert.'), ('A young girl in a karate uniform holding a large trophy.', 'Ein Mädchen in einem Karateanzug hält eine große Trophäe.'), ('A smiling woman holds a person dressed in a pig costume.', 'Eine lächelnde Frau hält eine Person, die ein Schweinekostüm trägt.'), ('The man is holding the net for the boy playing baseball.', 'Der Mann hält das Netz für den Jungen, der Baseball spielt.'), ('People walking along a river near a beautiful homestead.', 'Leute gehen in der Nähe eines schönen Gehöfts einen Fluss entlang.'), ('Person sitting on concrete landing next to body of water', 'Eine Person, die auf Beton-Anlegeplatz neben einem Gewässer sitzt.'), (\"Bird's eye view of a man ascending a staircase outdoors.\", 'Vogelperspektive eines Mannes, der eine Treppe im Freien hochsteigt.'), ('A woman sitting on a bench in front of a large painting.', 'Eine Frau, die vor einem großen Gemälde auf einer Bank sitzt.'), ('Two men in the woods using a chainsaw to cut some trees.', 'Zwei Männer im Wald benutzen eine Kettensäge, um Bäume zu fällen.'), ('A boy is diving off a diving board into a swimming pool.', 'Ein Junge taucht von einem Springbrett aus in ein Schwimmbecken.'), ('A little girl in pink dances with her hands on her hips.', 'Ein kleines Mädchen in Rosa tanzt mit den Händen auf den Hüften.'), ('A truck has just crashed into the back of another truck.', 'Ein Lkw ist gerade auf das Heck eines anderen Lkw aufgefahren.'), ('Man with hat juggling in front of a captivated audience.', 'Ein Mann mit Hut, der vor einem faszinierten Publikum jongliert.'), ('The group is watch a cartoon on a small electric device.', 'Die Gruppe sieht sich auf einem kleinen elektrischen Gerät ein Video an.'), ('A man in an orange shirt is using a scraper in a sifter.', 'Ein Mann in einem orangefarbenen Hemd benutzt in einer Siebvorrichtung einen Schaber.'), ('Two men in the middle of the action of a fighting match.', 'Zwei Männer mitten in einem Kampf.'), ('A man, and girl and two horses are near a contained fire.', 'Ein Mann, ein Mädchen und zwei Pferde befinden sich in der Nähe eines eingedämmten Feuers.'), ('The regional park police helicopter is preparing to land.', 'Der Polizeihubschrauber des örtlichen Parks bereitet sich auf die Landung vor.'), ('A mother and children is fishing on a boardwalk at night.', 'Eine Mutter und Kinder fischen nachts an einer hölzernen Strandpromenade.'), ('Six males playing a game in the sand with wooden paddles.', 'Sechs männliche Personen spielen ein Spiel im Sand mit hölzernen Paddeln.'), ('A cyclist is riding a bicycle on a curved road up a hill.', 'Ein Radfahrer fährt auf einer kurvigen Straße einen Hügel hinauf.'), ('An adult and a child walk along the beach during the day.', 'Ein Erwachsener und ein Kind gehen tagsüber am Strand entlang.'), ('Brown dog with tennis ball in mouth, in water and bushes.', 'Ein brauner Hund mit einem Tennisball im Mund, in Wasser und Büschen.'), ('Two women stand together holding a pot and a pan of food.', 'Zwei Frauen stehen zusammen und halten einen Topf und eine Pfanne mit Essen.'), ('A happy young boy sits in a chair with a large Elmo doll.', 'Ein glücklicher Junge sitzt mit einer großen Elmo-Puppe in einem Stuhl.'), ('A teenage boy has a silver ring protruding from his nose.', 'Bei einem männlichen Teenager steht ein Ring von der Nase ab.'), ('Two men and a dog are standing among rolling green hills.', 'Zwei Männer und ein Hund stehen in den Rolling Green Hills.'), ('A man wearing a sleeveless shirt and construction helmet.', 'Ein Mann mit ärmellosem Hemd und Schutzhelm.'), ('Several young adults performing in martial arts clothing.', 'Mehrere junge Erwachsene, die in Kampfsportkleidung etwas vorführen.'), ('A girl in a yellow dress with the sun shining on her face', 'Ein Mädchen in einem gelben Kleid, der die Sonne ins Gesicht scheint.'), ('A construction crew working at several spots on the road.', 'Eine Bauarbeitermannschaft, die an mehreren Stellen auf der Straße arbeitet.'), ('Two emergency responders are at the scene of an incident.', 'Zwei Sanitäter sind an einer Unfallstelle.'), ('These girls are in uniforms and are playing field hockey.', 'Diese Mädchen tragen Uniformen und spielen Feldhockey.'), ('A black and brown dog is laying on a white shaggy carpet.', 'Ein schwarz-brauner Hund liegt auf einem weißen ungepflegten Teppich.'), ('A woman giving a blond-haired toddler a drink from a cup.', 'Eine Frau, die einem blonden Kleinkind aus einer Tasse zu trinken gibt.'), ('People walk by a display of underwear hanging in a stall.', 'Leute gehen an einem Stand vorbei, an dem zum Verkauf angebotene Unterwäsche hängt.'), ('The women with shorts has her hand placed on a white car.', 'Die Frau mit den kurzen Hosen hat ihre Hand auf ein weißes Auto gelegt.'), ('Two black dogs are trotting through an empty public area.', 'Zwei schwarze Hunde trotten durch einen leeren öffentlichen Bereich.'), ('A man without a shirt is walking on top of lots of rocks.', 'Ein Mann mit nacktem Oberkörper geht auf vielen Steinen.'), ('A man standing in a hole in front of a woman in a garden.', 'Ein Mann, der in einem Garten in einem Loch vor einer Frau steht.'), ('The woman in glasses is holding a red and white sale bag.', 'Eine Frau mit Brille hält eine rot-weiße Einkaufstüte.'), ('Guy playing banjo in the park as a duck enjoys the music.', 'Jemand spielt im Park Banjo, und eine Ende genießt die Musik.'), ('Two girls in bright green boots and a woman are together.', 'Zwei Mädchen in knallgrünen Stiefeln und eine Frau sind zusammen.'), ('A little boy and his bike sit outside the Kuthhoop Hotel.', 'Ein kleiner Junge sitzt mit seinem Fahrrad vor dem Kuthhoop-Hotel.'), ('A man lays on the bench to which a white dog is also tied.', 'Ein Mann liegt auf der Bank, an die auch ein weißer Hund angebunden ist.'), ('A wet black dog is carrying a green toy through the grass.', 'Ein nasser schwarzer Hund trägt ein grünes Spielzeug durch das Gras.'), ('A couple wearing white sweaters sit at a restaurant table.', 'Ein Paar mit weißen Pullovern sitzt an einem Restauranttisch.'), ('Workers wearing reflective vests working near a train car.', 'Arbeiter mit Warnwesten, die in der Nähe eines Zugwaggons arbeiten.'), ('A man wearing a helmet riding his bicycle down the street.', 'Ein Mann mit einem Helm fährt mit dem Fahrrad die Straße entlang.'), ('A person doing a skateboard flip next to a black trashcan.', 'Eine Person neben einer schwarzen Mülltonne, die einen Skateboard-Flip macht.'), ('A construction worker is building scaffolding for the job.', 'Ein Bauarbeiter baut ein Gerüst für seine Arbeit.'), ('A little child with a red cap and a duck are in the grass.', 'Ein Kleinkind mit einer roten Mütze und eine Ente sind im Gras.'), ('A man in yellow and green shorts jumping in a living room.', 'Ein Mann in gelb-grünen Shorts, der in einem Wohnzimmer springt.'), ('A dog wearing a blue harness stands in the snow and pants.', 'Ein Hund mit einem blauen Geschirr steht im Schnee und hechelt.'), ('A woman with a red jacket and her companion eating snacks.', 'Eine Frau mit einer roten Jacke und ihr Begleiter, wie sie eine Kleinigkeit essen.'), ('A young man, barefoot along side the beach, prunes a tree.', 'Ein junger Mann steht barfuß am Strand und schneidet einen Baum aus.'), ('An older black woman is operating her electric wheelchair.', 'Eine ältere schwarze Frau bedient ihren Elektrorollstuhl.'), ('People are watching a person in a weird vehicle in a plaza.', 'Leute sehen einer Person in einem seltsamen Fahrzeug auf einem Platz zu.'), ('A young child playing with a toy while laying on the floor.', 'Ein kleines Kind liegt auf dem Boden und spielt mit einem Spielzeug.'), ('A man stand there after rolling a bowling ball down a lane.', 'Ein Mann steht da, nachdem er eine Bowlingkugel auf eine Bahn geworfen hat.'), ('A young man is walking through a busy street beside a mall.', 'Ein junger Mann geht durch eine belebte Straße neben einem Einkaufszentrum.'), ('A boy sliding down a slide into a pool with colorful tubes.', 'Ein Junge rutscht eine Rutsche mit farbigen Rohren in ein Schwimmbecken herunter.'), ('A woman with reddish hair applies mascara to her eyelashes.', 'Eine Frau mit rötlichem Haar trägt Mascara auf ihre Wimpern auf.'), ('Two ladies and a man playing a card game and drinking beer.', 'Zwei Damen und ein Mann, die ein Kartenspiel spielen und Bier trinken.'), ('Two men are working on a carpentry project with hand tools.', 'Zwei Männer arbeiten mit Handwerkzeugen an einem Zimmereiprojekt.'), ('Two dogs run through the water with a rope in their mouths.', 'Zwei Hunde rennen mit einem Seil im Maul durch das Wasser.'), ('A shirtless man leading a horse that is pulling a carriage.', 'Ein Mann mit nacktem Oberkörper führt ein Pferd, das einen Wagen zieht.'), ('A girl sleeping with a baby doll wearing a princess costume', 'Ein Mädchen schläft mit einer Babypuppe mit Prinzessinnenkostüm.'), ('A young boy in a flowered apron is helping his mother cook.', 'Ein Junge in einer geblümten Schürze hilft seiner Mutter beim Kochen.'), ('A group of young people are playing in a fountain of water.', 'Eine Gruppe junger Menschen spielt in einem Brunnen.'), ('Two bakery employees wearing red aprons are preparing food.', 'Zwei Bäckereimitarbeiter mit roten Schürzen bereiten Essen zu.'), ('A young man looks at a book on the ground in a wooded area.', 'Ein junger Mann in einer Waldgegend sieht sich ein Buch auf dem Boden an.'), ('A person wearing a purple jacket stands behind a tall tree.', 'Eine Person, die eine violette Jacke trägt, steht hinter einem hohen Baum.'), ('A group of worshipers hold their services in a public park.', 'Eine Gruppe von Gläubigen hält in einem öffentlichen Park einen Gottesdienst ab.'), ('The man on the beach looking for stuff with metal detector.', 'Der Mann am Strand, der mit einem Metalldetektor nach Sachen sucht.'), ('Two little blond girls in helmets are sitting on a red ATV.', 'Zwei kleine blonde Mädchen mit Helmen sitzen auf einem roten Geländewagen.'), ('A man in a red shirt sits at a table with a glass of water.', 'Ein Mann mit einem roten Hemd sitzt mit einem Glas Wasser an einem Tisch.'), ('A man in a jumpsuit and hat tends to a large spool of rope.', 'Ein Mann mit Overall und Helm kümmert sich um eine große Seilrolle.'), ('Two hikers walk down an arid slope next to a green conifer.', 'Zwei Wanderer wandern neben einer grünen Konifere eine karge Böschung hinunter.'), ('An Asian family prepares meat on skewers at a night market.', 'Eine asiatische Familie bereitet auf einem nächtlichen Markt Fleisch auf Spießen zu.'), ('A man is carrying a trash barrel past a statue of an angel.', 'Ein Mann trägt einen Mülleimer an einer Engelsstatue vorbei.'), ('A man and woman enjoy a ride down the rapids on a warm day.', 'Ein Mann und eine Frau genießen an einem warmen Tag eine Fahrt über die Stromschnellen.'), ('A girl paddling down a large river, as seen from behind her.', 'Ein Mädchen, das einen großen Fluss hinunterpaddelt, von hinten gesehen.'), (\"A woman is reading a magazine over another woman's shoulder.\", 'Eine Frau, die einer andere Frau über die Schulter sieht, um eine Zeitschrift zu lesen.'), ('Someone working on a project using a jigsaw cutting machine.', 'Jemand arbeitet mit einer Dekupiersägemaschine an einem Projekt.'), ('A young man does a skateboard trick off of a concrete bench.', 'Ein junger Mann führt von einer Betonbank aus eine Skateboard-Nummer vor.'), ('A white male wearing glasses is blowing a bubble in a house.', 'Eine weiße männliche Person mit Brille macht in einem Haus eine Seifenblase.'), ('Two people are sitting with their backs facing cotton candy.', 'Zwei Personen sitzen und haben ihren Rücken Zuckerwatte zugewandt.'), ('A closeup of a child on a playground with adult supervision.', 'Eine Nahaufnahme von einem Kind auf einem Spielplatz unter Aufsicht von Erwachsenen.'), ('A green John Deere tractor in a field pulling a red trailer.', 'Ein grüner John Deere-Traktor auf einem Acker, der einen roten Anhänger zieht.'), ('A man in a white t-shirt is smiling as looking at something.', 'Ein Mann mit einem weißen T-Shirt lächelt, als ob er etwas ansieht.'), ('Two little boys look back as they walk across a grassy area.', 'Zwei Jungen, die durch Gras gehen, blicken zurück.'), ('A woman in jeans walking along a pathway with green railing.', 'Eine Frau in Jeans, die auf einem Pfad mit einem grünen Geländer geht.'), ('A woman squatting to face a small child while holding a dog.', 'Eine Frau, die in der Hocke sitzt, um auf Augenhöhe mit einem Kleinkind zu sein, und gleichzeitig einen Hund hält.'), ('A painter shows off his talent in front of a group of people', 'Ein Maler zeigt sein Talent vor einer Menschenansammlung.'), ('A young boy covering his face while sitting on a trampoline.', 'Ein Junge sitzt auf einem Trampolin und bedeckt sein Gesicht.'), ('A man in a red shirt is jumping from a large rock formation.', 'Ein Mann mit einem roten Hemd springt von einem großen Felsen.'), ('An elderly man is wearing overalls and holding a paintbrush.', 'Ein älterer Mann mit Latzhosen hält einen Pinsel.'), ('A little girl is swinging in a baby swing on the playground.', 'Ein kleines Mädchen schaukelt in einer Babyschaukel auf dem Spielplatz.'), ('A man is breakdancing on the floor around a crowd of people.', 'Ein Mann macht auf dem Boden Breakdance, während eine Menschenmenge um ihn herum steht.'), ('A man about to step off the edge of a desert rock formation.', 'Ein Mann, der dabei ist, einen Schritt von einer Felskante in der Wüste herunter zu machen.'), ('Several men in hard hats are operating a giant pulley system.', 'Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.'), ('A little girl is sitting in front of a large painted rainbow.', 'Ein kleines Mädchen sitzt vor einem großen gemalten Regenbogen.'), ('A beautiful bride walking on a sidewalk with her new husband.', 'Eine schöne Braut geht auf einem Gehweg mit ihrem neuen Ehemann.'), ('A boy in a red jacket pouring water on a man in a white shirt', 'Ein Junge in einer roten Jacke, der Wasser auf einen Mann in einem weißen Hemd gießt.'), (\"The young gymnast's supple body soars above the balance beam.\", 'Der gelenkige Körper des jungen Turners schwebt über dem Schwebebalken.'), ('Hockey goalie boy in red jacket crouches by goal, with stick.', 'Junger männlicher Hockey-Goalie in roter Jacke duckt sich mit Stock beim Tor.'), ('A 30 somethings man playing with his phone on a subway train.', 'Ein Mann in den Dreißigern spielt in einer U-Bahn mit seinem Telefon.'), ('Several young people sitting on a rail above a crowded beach.', 'Mehrere junge Leute sitzen auf einem Geländer über einem überfüllten Strand.'), ('A man in a home kitchen is flipping a pancake extremely high.', 'Ein Mann in einer Wohnungsküche wirft einen Pfannkuchen sehr hoch.'), ('An older guy looking at a classic, rustic, volkswagen beetle.', 'Ein älterer Typ blickt auf einen klassischen schlichten Volkswagen Käfer.'), ('Men wearing orange safety vest are working on street repairs.', 'Männer mit orangefarbenen Schutzwesten führen Straßenreparaturen durch.'), ('A number of children enjoy themselves on the coast of a city.', 'Einige Kinder vergnügen sich am  Strand einer Stadt.'), ('The woman with the hat is selling some fruits and root crops.', 'Die Frau mit dem Hut verkauft Obst und Wurzelgemüse.'), ('A child hold green shoes is walking in the sand by the water.', 'Ein Kind, das grüne Schuhe hält, geht im Sand neben dem Wasser entlang.'), ('A baby and a young child are sitting together in a highchair.', 'Ein Baby und ein Kleinkind sitzen zusammen in einem Hochstuhl.'), ('A couple holds a sign that reads Teaching children for peace.', 'Ein Paar hält eine Schild, auf dem steht: „Teaching children for peace“.'), ('A man with no shirt on and a hat is using a hammer and anvil.', 'Ein Mann mit nacktem Oberkörper und einem Hut benutzt Hammer und Amboss.'), ('A little girl in a sweater is swung around by an unseen hand.', 'Ein kleines Mädchen in einem Pullover wird von einer nicht sichtbaren Hand herumgedreht.'), ('A man with a blue baseball cap on is sleeping against a rock.', 'Ein Mann mit einer blauen Baseballkappe schläft an einen Felsen gelehnt.'), ('A gentleman in traditional garb weaving a blanket in a field.', 'Ein Herr in traditionellem Outfit, der in einem Feld eine Decke webt.'), ('Five people walking with a multicolored sky in the background.', 'Fünf gehende Personen mit einem mehrfarbigen Himmel im Hintergrund.'), ('A white dog shakes on the edge of a beach with an orange ball.', 'Ein weißer Hund schüttelt sich am Rande eines Strands mit einem orangefarbenen Ball.'), ('Some men standing in front of a building next to a parked car.', 'Ein paar Männer stehen vor einem Gebäude neben einem parkenden Auto.'), ('A woman is walking her baby with a stroller at the local park.', 'Eine Frau fährt ihr Baby in einem Sportwagen im örtlichen Park spazieren.'), ('A man lounges in a wooden basin of water while eating a fruit.', 'Ein Mann räkelt sich in einem hölzernen Wasserbehälter und isst Obst.'), ('A man wearing a yellow shirt is throwing a javelin on a track.', 'Ein Mann, der ein gelbes Hemd trägt, wirft einen Speer auf eine Bahn.'), ('There are three dogs starring at a ball in the middle of them.', 'Drei Hunde starren auf einen Ball in ihrer Mitte.'), ('A man in a reflective jacket positions himself on scaffolding.', 'Ein Mann in einer Warnweste bringt sich auf einem Gerüst in Position.'), ('A woman with dark hair wearing a bikini is sitting on a beach.', 'Eine Frau mit dunklen Haaren, die einen Bikini trägt, sitzt an einem Strand.'), ('A group of people gather and holding different types of flags.', 'Eine Menschengruppe sammelt sich und hält verschieden Fahnen.'), ('A young girl is looking through an old fashioned video camera.', 'Ein junges Mädchen blickt durch eine altmodische Videokamera.'), ('People enjoy a gathering with Pabst Blue Ribbon and Diet Coke.', 'Leute genießen eine Zusammenkunft mit Pabst Blue Ribbon und Diet Coke.'), ('A little baby dressed in green and yellow wearing a bib cries.', 'Ein kleines Baby, das in Grün und Gelb gekleidet ist und einen Latz trägt, weint.'), ('Three girls walk under an arbor on a path surrounded by trees.', 'Drei Mädchen gehen unter einer Laube einen von Bäumen umgebenen Pfad entlang.'), ('A dog running across a grassy field with a stick in its mouth.', 'Ein Hund, der mit einem Stock im Maul über eine Wiese rennt.'), ('A man with a beard and a hat is begging for money from people.', 'Ein Mann mit einem Bart und einem Hut bettelt die Leute um Geld an.'), ('A wedding day with the bride in a bright white beautiful dress', 'Ein Hochzeitstag mit der Braut in einem hellweißen schönen Kleid'), ('A man in a yellow jumpsuit rowing a boat with a bird in front.', 'Ein Mann in einem gelben Overall rudert ein Boot, vorne ein Vogel.'), ('A person in a black hat is holding multicolored juggling pins.', 'Eine schwarz gekleidete Person hält mehrfarbige Jonglierkeulen.'), ('Three people sit on wood benches set on white and orange tile.', 'Drei Personen sitzen auf Holzbänken auf weißen und orangefarbenen Fliesen.'), ('One man is playing the drums while another is singing Karaoke.', 'Ein Mann spielt die Trommeln, während ein andere Karaoke singt.'), ('A dog trots across the ground with a large stick in his mouth.', 'Ein Hund trottet mit einem großen Stock im Maul über das Feld.'), ('An adult man wearing jeans and black shirt holding a beverage.', 'Ein erwachsener Mann mit Jeans und schwarzem Hemd, der ein Getränk hält.'), ('A boy wearing black swimming trunks is standing in a fountain.', 'Ein Junge mit schwarzer Badehose steht in einem Brunnen.'), ('A large black and white dog is running through a grassy field.', 'Ein großer schwarz-weißer Hund rennt über eine Wiese.'), ('Two children are on the beach and are playing in the wet sand.', 'Zwei Kinder sind am Strand und spielen im nassen Sand.'), ('A man wearing black is playing an electric guitar at a concert.', 'Ein Mann in Schwarz spielt auf einem Konzert eine Elektrogitarre.'), ('A girl playing softball hits the ball almost directly downwards', 'Ein Mädchen, das Softball spielt, schlägt den Ball fast senkrecht nach unten.'), ('Three boys playing and biking with a pile of sand in the middle', 'Drei Jungen spielen und fahren Fahrrad mit einem Sandhügel in der Mitte.'), ('A doctor and nurses in blue scrubs are performing an operation.', 'Ein Arzt und Pflegekräfte in blauer Arbeitskleidung führen eine Operation durch.'), ('An elderly women is sitting in a chair with a cane in her hand.', 'Eine ältere Frau, die in einem Stuhl sitzt, mit einem Stock in ihrer Hand.'), ('A yellow dog and a black and white dog are running in the dirt.', 'Ein gelber Hund und ein schwarz-weißer Hund rennen auf dem Erdboden.'), ('Several people are taking a break while on a snowmobiling ride.', 'Mehrere Leute auf einer Schneemobil-Tour machen eine Pause.'), ('A man in a safety vest is kneeling down and working on a train.', 'Ein Mann mit einer Schutzweste kniet sich hin und arbeitet an einem Zug.'), ('A woman with dirty blond-hair and glasses is cutting something.', 'Eine Frau mit schmutzigen blonden Haaren und Brille schneidet etwas.'), ('A family is sitting outside enjoying themselves in a park area.', 'Eine Familie sitzt draußen in einem Parkgebiet und lässt es sich gut gehen.'), ('People walk around and mingle in a large open space with a dog.', 'Leute laufen auf einem großen offenen Platz mit einem Hund herum und vermischen sich.'), ('A man sprinkles seasonings on his barbecue in front of foliage.', 'Ein Mann streut Gewürze auf sein Grillgut, im Hintergrund ist Laub zu sehen.'), ('Two kids on wakeboards attempt to give one another a high-five.', 'Zwei Kinder auf Wakeboards versuchen, einander ein High-Five zu geben.'), ('An African-American baby is crawling on the floor near a table.', 'Ein afroamerikanisches Baby krabbelt in der Nähe eines Tisches auf dem Boden.'), ('A group of people wait at a platform while a train passes them.', 'Eine Menschengruppe wartet auf einem Bahnsteig, während ein Zug vorbeifährt.'), ('A man catches a decent sized fish and is taking it off the hook', 'Ein Mann fängt einen recht großen Fisch und nimmt ihn vom Haken.'), ('This picture is of a young girl practicing gymnastics in a gym.', 'Dieses Bild zeigt ein Mädchen, das in einer Turnhalle Gymnastik macht.'), ('A man in a blue shirt is standing on a ladder cleaning a window.', 'Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.'), ('Three dogs stand in a grassy field while a person kneels nearby.', 'Drei Hunde stehen auf einer Wiese und eine Person kniet in der Nähe.'), ('A boy in yellow glasses and red-haired girl pose for the camera.', 'Ein Junge mit einer gelben Brille und ein rothaariges Mädchen posieren für die Kamera.'), ('A boy in a dirty shirt is walking through knee-high ocean water.', 'Ein Junge in einem schmutzigen Hemd geht durch knietiefes Meerwasser.'), ('Two men and two women are preparing a large meal in the kitchen.', 'Zwei Männer und zwei Frauen bereiten in der Küche ein großes Essen zu.'), ('Lots of people walking under a awning of pink and white balloons', 'Viele Leute, die unter einem Vordach aus rosafarbenen und weißen Luftballons stehen.'), ('Three people push a piece of large machinery through the street.', 'Drei Menschen schieben eine große Maschine durch die Straße.'), ('A man is sitting at an outside bar near many soda and beer cans.', 'Ein Mann sitzt in einer Bar im Freien bei vielen Limonade- und Bierdosen.'), ('A woman is holding a little girl who is trying to catch bubbles.', 'Eine Frau hält ein kleines Mädchen, das versucht, Seifenblasen zu fangen.'), ('A kid looking over a carnival booth counter at the various toys.', 'Ein Kind sieht eine Jahrmarktsbude mit verschiedenen Spielzeugen an.'), ('A very unusually dressed man sitting beside an ice cream cooler.', 'Ein sehr ungewöhnlich bekleideter Mann, der neben einem Eiskühler sitzt.'), ('A little boy looks at his reflection in a burnished marble wall.', 'Ein kleiner Junge blickt auf sein Spiegelbild in einer polierten Marmorwand.'), ('A boy laying on the grass face down with a football at his feet.', 'Ein Junge, der mit dem Gesicht nach unten und einem Fußball zu seinen Füßen im Gras liegt.'), ('A man standing and cheering amongst a stadium of others sitting.', 'Ein Mann, der in einem Stadium zwischen sitzenden Personen steht und jemand anfeuert.'), ('Two people with helmets are riding bikes in front of a building.', 'Zwei Personen mit Schutzhelmen fahren vor einem Gebäude Fahrrad.'), ('A woman looks stone-faced in the mirror as she applies eyeliner.', 'Eine Frau blickt regungslos in den Spiegel, während sie Eyeliner aufträgt.'), ('A young boy with swimming goggles, jumping into a swimming pool.', 'Ein Junge mit Schwimmbrille, der in ein Schwimmbecken springt.'), ('A young woman smiling in the distance is enjoying a bubble bath.', 'Eine junge Frau, die in die Ferne lächelt, genießt ein Schaumbad.'), ('A woman in blue shorts and a white shirt is indoor rock climbing.', 'Eine Frau in blauen Shorts und einem weißen Hemd klettert in einer Halle.'), ('Little girl in blue swimsuit standing on a handrail near a beach.', 'Ein kleines Mädchen mit einem blauen Badeanzug, das an einem Geländer in der Nähe eines Strands steht.'), ('A young Asian boy sits on a railing behind a row of colorful hats', 'Ein asiatischer Junge sitzt auf einem Geländer hinter einer Reihe farbenfroher Hüte.'), ('A woman wearing a blue helmet rides her bicycle in a parking lot.', 'Eine Frau mit einem blauen Helm fährt auf einem Parkplatz Fahrrad.'), ('Redhead woman in pigtails and glasses sewing on a sewing machine.', 'Eine rothaarige Frau mit Zöpfen und Brille, die auf einer Nähmaschine näht.'), ('Large amount of people sitting up against the walls of buildings.', 'Viele Menschen, die an die Wände von Gebäuden angelehnt sitzen.'), ('Two men take measurements of a wall at an open construction site.', 'Zwei Männer nehmen die Maße einer Wand an einer offenen Baustelle.'), ('A man in red snow gear looks at an expanse of snow and mountains.', 'Ein Mann in rotem Schneeanzug blickt auf ein großes Gebiet mit Schnee und Bergen.'), ('A young child is climbing a rock wall in all his protective gear.', 'Ein kleines Kind klettert in vollständiger Ausrüstung eine Felswand hoch.'), ('An old man in traditional costume seems to be in a cheerful mood.', 'Ein alter Mann in traditionellem Kostüm scheint gut gelaunt zu sein.'), ('A brown, fluffy dog jumping into a swimming pool after a red toy.', 'Ein brauner, flauschiger Hund, der einem roten Spielzeug in den Pool nachspringt.'), ('A brown horse is standing behind a girl and is sniffing her hair.', 'Ein braunes Pferd steht hinter einem Mädchen und riecht an ihren Haaren.'), ('A woman in a white shirt mixing something on the kitchen counter.', 'Eine Frau in einem weißen Oberteil, die auf der Küchenarbeitsfläche etwas mischt.'), ('A woman in a white apron prepares various meats on a large grill.', 'Eine Frau in einer weißen Schürze bereitet auf einem großen Grill verschiedene Fleischsorten zu.'), ('Two women are walking in a crosswalk with a bus in the background.', 'Zwei Frauen gehen über einen Fußgängerübergang mit einem Bus im Hintergrund.'), ('Two girls crouch in front of some bushes and talk on their phones.', 'Zwei Mädchen ducken sich vor ein paar Büschen und sprechen in ihre Telefone.'), ('A woman is watching as a guy is scooping ice cream from a freezer.', 'Eine Frau sieht zu, wie ein Mann Eis aus einem Gefriergerät absticht.'), ('A man with a safety vest is kneeling down and cleaning the bricks.', 'Ein Mann mit einer Schutzweste kniet sich hin und reinigt die Ziegel.'), (\"A woman sits on a man's shoulders using a heavy brush as a hammer.\", 'Eine Frau sitzt einem Mann auf den Schultern und benutzt eine schwere Bürste als Hammer.'), ('Four men in white shirts and baseball caps sitting around a table.', 'Vier Männer in weißen Hemden und Baseballmützen sitzen um einen Tisch.'), ('Construction workers standing outside looking at wires above them.', 'Bauarbeiter, die im Freien stehen, blicken auf die Leitungen über ihnen.'), ('A group of people walking on a street in front of an AMC building.', 'Eine Gruppe geht auf einer Straße vor einem AMC-Gebäude entlang.'), ('The girl on the unicycle reaches out for the child on the scooter.', 'Das Mädchen auf dem Einrad fasst nach dem Kind auf dem Roller.'), ('Three children, baby in the center, sit in an outdoor swing chair.', 'Drei Kinder, Baby in der Mitte, sitzen in einem Hängesessel im Freien.'), ('A young child holds a spoon to its mouth while sitting in a chair.', 'Ein kleines Kind sitzt in einem Stuhl und hält einen Löffel an den Mund.'), (\"A man in a tan fisherman's cap puts lip balm on a woman in a boat.\", 'Ein Mann in einer lohfarbenen Schiffermütze trägt bei einer Frau in einem Boot Lippenschutz auf.'), ('Six women are sitting at a table together in front of a bookshelf.', 'Sechs Frauen sitzen zusammen an einem Tisch vor einem Bücherregal.'), ('A female athlete ties the laces of one of her cleats on the field.', 'Eine Sportlerin bindet auf dem Feld die Schnürsenkel eines ihrer Sportschuhe.'), ('A woman talks animatedly to her companion next to a body of water.', 'Neben einem Gewässer spricht eine Frau angeregt mit ihrem Begleiter.'), ('A mobile food station set up to serve patrons on the city streets.', 'Eine mobile Essensstation, die dazu dient, Stammgäste auf den Straßen der Stadt zu versorgen.'), ('The girl in the purple top and shorts, wearing a hat, is laughing.', 'Das Mädchen im violetten Oberteil, kurzen Hosen und Hut lacht.'), ('A man and woman, both wearing shorts, are walking down a sidewalk.', 'Ein Mann und eine Frau, beide in kurzen Hosen, gehen einen Bürgersteig entlang.'), ('A magazine vendor sits behind a very colorful collage of magazines.', 'Ein Zeitungsverkäufer sitzt hinter einer sehr farbenfrohen Zusammenstellung von Zeitschriften.'), ('A man in a hard hat is wearing a blue shirt and blue jean overalls.', 'Ein Mann mit Schutzhelm trägt ein blaues Hemd und einen Jeanslatzhose.'), ('A hockey goalie is trying to prevent a goal from the opposing team.', 'Ein Hockey-Goalie versucht, ein Tor des gegnerischen Teams zu verhindern.'), ('People sitting in a restaurant eating and one is reading the paper.', 'Menschen, die im Restaurant sitzen und essen, und einer liest die Zeitung.'), ('A little girl wearing a green dress is standing in front of puddle.', 'Ein kleines Mädchen mit einem grünen Kleid steht vor einer Pfütze.'), ('A guy standing outside with no shirt on looking up at the building.', 'Ein Mann, der ohne Hemd im Freien steht und zu dem Gebäude hochblickt.'), ('A man wearing a black shirt and goggles is running along the street', 'Ein Mann mit schwarzem Hemd und Brille rennt die Straße entlang.'), ('A boy standing at the beach holding a blue pale and a green shovel.', 'Ein Junge, der am Strand steht und einen blauen Pfosten und eine grüne Schaufel hält.'), ('A man in a black jacket is taking a photo of a man in a red jacket.', 'Ein Mann in einer schwarzen Jacke fotografiert einen Mann in einer roten Jacke.'), ('Women and men in a different country looking like they are clapping', 'Frauen und Männer in einem anderen Land, die aussehen, als ob sie klatschen.'), ('A man riding a bike wearing a green shirt with a drink in his hand.', 'Ein Mann mit einem grünen Hemd, der Fahrrad fährt und ein Getränk in der Hand hat.'), ('Asian woman in white shirt standing away from the crowd behind her.', 'Eine asiatische Frau in weißem Oberteil steht in einem gewissen Abstand von der Menschenmenge hinter ihr.'), ('A backhoe is on top of a pile of rubble from a demolished building.', 'Ein Bagger steht auf einem Schutzhaufen vor einem abgerissenen Gebäude.'), ('A green tinted hand is being held up in front of a table of people.', 'Eine grünliche Hand wird vor einem Tisch mit Leuten hochgehalten.'), ('A man wearing a black shirt smoothing out concrete in an urban area.', 'Ein Mann, der ein schwarzes Hemd trägt und in einer städtischen Umgebung Beton glättet.'), ('A woman in a white shirt is sitting at a table in a nice restaurant.', 'Eine Frau in einem weißen Rock sitzt an einem Tisch in einem hübschen Restaurant.'), ('Two women, one in green and the other in purple, washing a sidewalk.', 'Zwei Frauen, eine in Grün und die andere in Violett, die einen Gehsteig abwaschen.'), ('A woman in a red shirt is under a blanket and sleeping in a vehicle.', 'Eine Frau in einem roten Oberteil, befindet sich unter einer Decke in einem Fahrzeug und schläft.'), ('A little girl with brown hair is blowing the petals off of a flower.', 'Ein kleines Mädchen mit braunen Haaren bläst auf die Blütenblätter einer Blume.'), ('Two hands are flipping some food in a cast iron pan, with a spatula.', 'Zwei Hände geben mit einem Spachtel etwas Essbares in eine Eisenpfanne.'), ('A large ship approaching the dock with two men awaiting its arrival.', 'Ein großes Schiff, das auf das Dock zu fährt, wo zwei Männer seine Ankunft erwarten.'), ('A girl wearing a red short and a white shirt looking through a hole.', 'Ein Mädchen, das rote Shorts und ein weißes Oberteil trägt und durch ein Loch blickt.'), ('Two women, sitting at a table, with a green straw inside of a drink.', 'Zwei Frauen, die an einem Tisch sitzen, mit einem grünen Strohhalm in einem Getränk.'), ('Two police officers look at a house from a distance with binoculars.', 'Zwei Polizisten betrachten aus der Ferne ein Haus mit dem Fernglas.'), ('A woman in a striped shirt and black hair stands facing some booths.', 'Eine Frau mit schwarzen Haaren in gestreiftem Oberteil steht vor ein paar Ständen.'), ('A woman in the middle of throwing a bowling ball in a bowling alley.', 'Eine Frau, die gerade dabei ist, eine Bowlingkugel auf eine Bowlingbahn zu werfen.'), ('An Asian city at night with a large number of people walking around.', 'Eine asiatische Stadt bei Nacht mit vielen umherlaufenden Menschen.'), ('About 12 kids and a few adults get splashed by an off-camera source.', 'Ungefähr 12 Kinder und ein paar Erwachsene werden von etwas neben der Kamera bespritzt.'), ('A small boy is sitting on a bench next to a large jelly bean mascot.', 'Ein kleiner Junge sitzt auf einer Bank neben einem großen Geleebonbon-Maskottchen.'), (\"A lady that's holding a yellow bag is sitting on a chair in a store.\", 'Eine Dame, die eine gelbe Tasche hält, sitzt in einem Laden auf einem Stuhl.'), ('A man cooking something in an old fire burning oven with a apron on.', 'Ein Mann mit einer Schürze, der etwas in einem alten Holzofen zubereitet.'), ('A man in a yellow shirt vacuums a floor while looking at the camera.', 'Ein Mann in einem gelbe Hemd saugt einen Fußboden und blickt zur Kamera.'), ('Two men beating on drums and one man blowing a horn sitting outside.', 'Zwei Männer schlagen Trommeln und ein Mann bläst ein Horn; sie sitzen im Freien.'), ('A man in green holds a guitar while the other man observes his shirt.', 'Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.'), ('A man with a balloon hat and people eating outdoors at picnic tables.', 'Ein Mann mit einem Luftballonhut und Leute, die im Freien an Picknicktischen essen.'), ('A bearded traveler in a red shirt sitting in a car and reading a map.', 'Ein Reisender mit Bart in einem roten Hemd, der in einem Auto sitzt und eine Karte liest.'), ('Two people are sitting on a bench, and one women is standing by them.', 'Zwei Personen sitzen auf einer Bank, und eine Frau steht neben ihnen.'), ('A little girl in a flower print bathing suit, jumping into the ocean.', 'Ein kleines Mädchen in einem Badeanzug mit Blumenaufdruck springt ins Meer.'), ('A woman in Muslim attire is walking with a young boy down the street.', 'Eine Frau mit muslimischer Bekleidung läuft mit einem Jungen die Straße entlang.'), ('A woman is jogging on a sidewalk next to an elevated grassy platform.', 'Eine Frau joggt auf einem Gehweg neben einer erhöhten grasbewachsenen Plattform.'), ('The child in the green one piece suit is walking past a store window.', 'Das Kind im grünen Einteiler läuft an einem Ladenfenster vorüber.'), ('A young girl wearing yellow flip-flops is sitting on a large boulder.', 'Ein junges Mädchen mit gelben Flipflops sitzt auf einem großen Findling.'), ('Young man showing off by performing a karate move for surprised girl.', 'Ein junger Mann gibt gegenüber einem überraschten Mädchen mit einer Karate-Bewegung an.'), ('Two men are discussing sometime near a wall with some graffiti on it.', 'Zwei Männer diskutieren irgendwann in der Nähe einer Wand mit Graffiti.'), ('Five people are sitting around a table, outside, playing a card game.', 'Fünf Personen sitzen im Freien um einen Tisch und spielen ein Kartenspiel.'), ('A man in a plaid shirt connecting his black laptop to his microscope.', 'Ein Mann mit einem karierten Hemd, der sein schwarzes Laptop an sein Mikroskop anschließt.'), ('Boy and his family celebrating his birthday with a brightly lit cake.', 'Ein Junge und seine Familie, die mit einem hell leuchtenden Kuchen seinen Geburtstag feiern.'), ('There are three swimmers from the same team getting ready to compete.', 'Drei Schwimmer, die zum gleichen Team gehören, bereiten sich auf den Wettkampf vor.'), ('Various passengers on a bus look out the window or into the distance.', 'Mehrere Passagiere eines Busses blicken aus dem Fenster in die Ferne.'), ('Two young attractive women with shorts cross a street of a busy city.', 'Zwei junge attraktive Frauen mit Shorts überqueren in einer belebten Stadt die Straße.'), (\"A sleeping baby is in someone's arms and wearing a pink striped outfit\", 'Ein schlafenden Baby liegt jemandem im Arm und trägt ein Outfit mit rosafarbenen Streifen.'), ('A group of shirtless men are sitting in the shade on a tropical beach.', 'Eine Gruppe Männer mit nacktem Oberkörper sitzt an einem tropischen Strand im Schatten.'), ('Four girls are sitting in the grass while several men stand near them.', 'Vier Mädchen sitzen im Gras, und mehrere Männer stehen in ihrer Nähe.'), ('A woman in a green tank top is surrounded by three children, laughing.', 'Eine Frau in einem grünen Pullunder ist von drei Kindern umgeben und lacht.'), ('Two horses pull a carriage driven by a woman over snow covered ground.', 'Zwei Pferde ziehen einen von einer Frau gelenkten Wagen über einen schneebedeckten Untergrund.'), ('A man in a black jacket is standing with a group of people behind him.', 'Ein Mann in einem schwarzen Jackett steht vor einer Gruppe von Menschen.'), ('A woman in a white shirt and pink skirt is about to hit a tennis ball.', 'Eine Frau in einem weißen Oberteil und rosafarbenen Rock ist kurz davor, einen Tennisball zu schlagen.'), ('A dog with its mouth open running through a field torwards the camera.', 'Ein Hund mit offenem Maul, der durch ein Feld auf die Kamera zu rennt.'), ('A man in a blue shirt is kissing a woman with blond-hair on the cheek.', 'Ein Mann in einem blauen Hemd küsst eine Frau mit blonden Haaren auf die Wange.'), ('The young girl is swinging high above the ground on a nice summer day.', 'Das Mädchen schaukelt an einem schönen Sommertag hoch über dem Boden.'), ('A young women sits at a vending stall labeled ice creams and programs.', 'Eine junge Frau sitzt bei einem Verkaufsstand, an dem es angeblich Eis und Programme gibt.'), ('A brown horse stands near a black horse that is sitting on the ground.', 'Ein braunes Pferd steht in der Nähe eines schwarzen Pferds, das auf dem Boden sitzt.'), ('A couple walking at a gathering with a balloon in the air behind them.', 'Ein Paar,  das bei einer Zusammenkunft mit einem Luftballon unterwegs ist, der hinter ihm in der Luft schwebt.'), (\"A woman is standing next to a Japanese version of Disney's Snow White.\", \"Eine Frau steht neben einer japanischen Version von Walt Disney's Schneewittchen.\"), ('A hiker with an American flag on his backpack walks through the woods.', 'Ein Wanderer mit einer amerikanischen Flagge auf seinem Rucksack wandert durch den Wald.'), ('A woman with braids is kneeling down and adjusting string on a machine', 'Eine Frau mit Zöpfen kniet und stellt an einer Maschine eine Schnur ein.'), ('A woman with blond-hair and sunglasses sitting at a table and smiling.', 'Eine Frau mit blonden Haaren und Sonnenbrille, die an einem Tisch sitzt und lächelt.'), ('Two girls sparring with a red and blue bat while another girl watches.', 'Zwei Mädchen, die mit einem roten und einem blauen Schläger kämpfen, während ein anderes Mädchen zusieht.'), ('A man pushing a hand-truck of boxes is bending over to pick up a pear.', 'Ein Mann, der einen Handwagen mit Kisten schiebt, beugt sich nach vorne, um eine Birne aufzuheben.'), ('A man in a neon green and orange uniform is driving on a green tractor.', 'Ein Mann in einer neongrünen und orangefarbenen Uniform fährt auf einem grünen Traktor.'), ('A man wearing a reflective vest and a hard hat holds a flag in the road', 'Ein Mann, der eine reflektierende Weste und einen Schutzhelm trägt, hält eine Flagge in die Straße.'), ('Several firefighters stand outside of a building near their firetrucks.', 'Mehrere Feuerwehrleute stehen vor einem Gebäude in der Nähe ihrer Löschfahrzeuge.'), ('Girl in odd clothes reading a brochure while sitting on a wooden porch.', 'Ein Mädchen in komischer Kleidung sitzt auf einer hölzernen Veranda und liest eine Broschüre.'), ('Child in black jacket, red pants and fleece had sleeps on a red jacket.', 'Ein Kind in schwarzer Jacke, roten Hosen und Fellmütze schläft auf einer roten Jacke.'), ('An old woman sits in a transit station next to a backlit advertisement.', 'Eine alte Frau sitzt in einer Umsteigestation neben einer hinterleuchteten Werbung.'), ('A group of three individuals are working in a cluttered office setting.', 'Eine aus drei Personen bestehende Gruppe arbeitet in einer vollgepackten Büroumgebung.'), ('A man in a brown shirt is sitting on the sidewalk and playing a guitar.', 'Ein Mann in einem braunen Hemd sitzt auf dem Gehweg und spielt Gitarre.'), ('A woman reading a newspaper and a man in a green jacket riding a train.', 'Eine zeitungslesende Frau und ein Mann in einer grünen Jacke fahren Zug.'), ('A lady in a red and black striped shirt is sitting on a retaining wall.', 'Eine Frau in einem rot-schwarz-gestreiften Oberteil sitzt auf einer Stützmauer.'), ('Black and white bird standing on hand of someone holding sunflower seeds', 'Ein schwarz-weißer Vogel, der jemandem auf der Hand steht, der Sonnenblumenkerne hält.'), ('This is a man standing on a rooftop with construction in the background.', 'Dies ist ein Mann, der auf einem Dach steht, mit Bauarbeiten im Hintergrund.'), ('A man in an pilot uniform is walking down the sidewalk carrying luggage.', 'Ein Mann in einer Pilotenuniform geht mit Gepäck den Bürgersteig entlang.'), ('An adult shows a young child a fencing outfit which is set up on a tree.', 'Ein Erwachsener zeigt einem jungen Kind einen Fechtanzug, der auf einem Baum arrangiert ist.'), ('A man wearing a plastic bib with a crab on it, holds up a wooden hammer.', 'Ein Mann, der einen Kunststofflatz mit einer Krabbe darauf trägt, hält einen Holzhammer hoch.'), ('Men and women wearing white swim caps giving each other piggyback rides.', 'Männer und Frauen, die weiße Bademützen tragen und einander Huckepack nehmen.'), ('Three people stand outside around two grills where meat is being cooked.', 'Drei Personen stehen im Freien um zwei Grills, auf denen Fleisch gegart wird.'), ('A woman playing a guitar in front of a group of people standing outside.', 'Eine Frau, die Gitarre spielt, vor einer Gruppe, die im Freien steht.'), ('A female with blond-hair is cutting a watermelon on a marble countertop.', 'Eine weibliche Person mit blonden Haaren schneidet auf einer Marmorarbeitsplatte eine Wassermelone.'), ('Two people are wakeboarding in the water and are being pulled by a boat.', 'Zwei Leute machen Wakeboarding im Wasser und werden von einem Boot gezogen.'), ('An ice cream truck is stopped in front of two small apartment buildings.', 'Ein Eiswagen hält vor zwei kleinen Apartmentgebäuden.'), ('The little girl is wearing a denim dress and holding a brown teddy bear.', 'Das kleine Mädchen trägt ein Jeanskleid und hält einen braunen Teddybär.'), ('A trained police dog sits next to his handler in front of the police van.', 'Ein geschulter Polizeihund sitzt neben dem Hundeführer vor dem Polizeitransporter.'), ('A man is standing in front of a small red object that looks like a plane.', 'Ein Mann steht vor einem kleinen roten Objekt, das wie ein Flugzeug aussieht.'), ('A woman is carrying a bowl full of fruit on her head near the ocean side.', 'Eine Frau in der Nähe des Meeres trägt eine Schale voller Obst auf ihrer Hand.'), ('A man is inside a truck looking out with his left arm in front of a door.', 'Ein Mann ist in einem Lastwagen und schaut heraus, sein linker Arm vor einer Tür.'), ('Person wearing a hooded jacket sitting on snow in front of a yellow tent.', 'Eine Person mit Kapuzenjacke, die vor einem gelben Zelt im Schnee sitzt.'), ('A gray dog runs along side a pool while a yellow dog jumps into the pool.', 'Ein grauen Hund rennt neben einem Schwimmbad entlang, während ein gelber Hund in das Schwimmbad springt.'), ('A man wearing a wife-beater, sitting around fruit in a low budget market.', 'Ein Mann, der ein weißes Unterhemd trägt, sitzt in einem Billigmarkt neben Obst.'), ('A military or police officer stands by as people pass in a public square.', 'Ein Militärangehöriger oder Polizist steht in einem Park, während Menschen an ihm vorbeigehen.'), ('A young boy with his tongue stuck out is climbing onto a wooden platform.', 'Ein Junge klettern mit herausgestreckter Zunge auf eine Holzplattform.'), ('A group of people, dressed the same walking down the street, in a parade.', 'Eine gleich gekleidete Personengruppe, die bei einer Parade die Straße entlang geht.'), ('A group of fourteen is assembled in a hall with dining tables and a stage.', 'Eine aus vierzehn Personen bestehende Gruppe ist in einer Halle mit Esstischen und einer Bühne versammelt.'), ('A girl in a green Speedo top and blue goggles holds her breath underwater.', 'Ein Mädchen in grünem Speedo-Oberteil und blauer Schutzbrille hält unter Wasser den Atem an.'), ('A man and women are posing for the camera and looking very happy together.', 'Ein Mann und eine Frau posieren für die Kamera und sehen zusammen sehr glücklich aus.'), ('Two workers that are working on the side of a street in neon yellow vests.', 'Zwei Arbeiter in neonfarbenen Westen, die am Rand einer Straßen arbeiten.'), ('An asian family is picnicking at the beach while others play in the water.', 'Eine asiatische Familie macht am Strand Picknick, während andere im Wasser spielen.'), ('A girl in a white shirt is sitting on a park bench with a dog next to her.', 'Ein Mädchen in einem weißen Oberteil sitzt auf einer Parkbank mit einem Hund neben sich.'), ('Two woman in colorful costumes look at a little girl wearing a brown vest.', 'Zwei Frauen in farbenfrohen Kostümen blicken auf ein Mädchen mit einem braunen Oberteil.'), ('An injured, bloody person sitting with friends in a hospital waiting room.', 'Eine verletzte, blutende Person sitzt mit Freunden im Warteraum eines Krankenhauses.'), ('A toddler wearing a onesie is stretching to see a video game in an arcade.', 'Ein Kleinkind in einem Einteiler streckt sich, um ein Videospiel in einer Einkaufspassage zu sehen.'), ('A man in a Hawaiian shirt is playing an orange electric guitar on a stage.', 'Ein Mann mit einem Hawaii-Hemd spielt auf einer Bühne auf einer orangefarbenen Gitarre.'), ('A man has his arms around two women who are posing for a picture with him.', 'Ein Mann hat seine Arme um zwei Frauen gelegt, die für ein Bild mit ihm posieren.'), ('Two men, one standing and one on a bicycle are talking outside a building.', 'Zwei Männer, einer, der steht, und einer auf einem Fahrrad, sprechen vor einem Gebäude miteinander.'), ('A tan dog walks along a grassy path with his long pink tongue hanging out.', 'Ein lohfarbener Hund, dessen lange rosafarbene Zunge heraushängt, läuft einen Grasweg entlang.'), ('Four guys three wearing hats one not are jumping at the top of a staircase.', 'Vier Typen, von denen drei Hüte tragen und einer nicht, springen oben in einem Treppenhaus.'), ('Guy in green shirt with hand covering part of his face in restaurant booth.', 'Ein Kerl in einem grünen Hemd, dessen Hand einen Teil seines Gesichts bedeckt, in einer Nische im Restaurant.'), ('A boy wearing a red shirt is riding his bike right next to a mound of dirt.', 'Ein Junge, der eine rotes Hemd trägt, fährt neben einem Erdhügel Fahrrad.'), ('A young man wearing a black shirt takes a folding chair from a large stack.', 'Ein junger Mann in einem schwarzen Hemd nimmt einen Klappstuhl von einem großen Stapel.'), ('A man on a motorcycle without a shirt and another man standing under shade.', 'Ein Mann auf einem Motorrad ohne Hemd und ein anderer Mann, der im Schatten steht.'), ('Man with gray hair telling a story to a group of younger people on a bench.', 'Ein Mann mit grauem Haar erzählt einer Gruppe jüngerer Leute auf einer Bank eine Geschichte.'), ('A five person surgical team is about to perform an operation in a hospital.', 'Ein aus fünf Personen bestehendes OP-Team in einem Krankenhaus ist kurz davor, eine Operation durchzuführen.'), ('Black and white dog looking at camera with man bent over in the background.', 'Ein schwarz-weißer Hund, der in die Kamera blickt, mit einem gebückten Mann im Hintergrund.'), ('Three road workers in orange jackets and pants clean up with a wheelbarrow.', 'Drei Straßenarbeiter in orangenen Jacken und Hosen machen mit einer Schubkarre sauber.'), ('A woman in a bright green sweater is playing with a dragon puppet a garden.', 'Eine Frau in einem grasgrünen Pullover spielt mit einer Drachenmarionette im Garten.'), ('A boy poses for a picture and in the background a man is hanging by a rope.', 'Ein Junge posiert für ein Bild, und im Hintergrund hängt ein Mann an einem Seil.'), ('A young boy wearing a clever black and white shirt with his head bowed down', 'Ein Junge mit einem raffinierten schwarz-weißen Hemd, der seinen Kopf gesenkt hat.'), ('Six shirtless men are standing outside leaning on or standing near a fence.', 'Sechs Männer mit nacktem Oberkörper stehen im Freien und lehnen sich an einen Zaun oder stehen neben dem Zaun.'), ('People are working on the factory floor while yellow stacks of paper go by.', 'Menschen arbeiten in der Fertigung, während gelbe Papierstapel an ihnen vorbeitransportiert werden.'), ('A dog with a red collar and its tongue hanging out runs through tall grass.', 'Ein Hund mit rotem Halsband und heraushängender Zunge rennt durch hohes Gras.'), ('People waiting to cross the street in front of a pharmacy with lit up sign.', 'Leute, die vor einen Apotheke mit leuchtendem Schild darauf warten, dass sie die Straße überqueren können.'), ('A trendy girl talking on her cellphone while gliding slowly down the street.', 'Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.'), ('A young man in a black and yellow jacket is gazing at something and smiling.', 'Ein junger Mann in einer schwarz-gelben Jacke blickt etwas an und lächelt.'), ('A man in sunglasses puts his arm around a woman in a black and white blouse.', 'Ein Mann mit Sonnenbrille legt seinen Arm um eine Frau in einer schwarz-weißen Bluse.'), ('A man in a suit is running past two other gentleman, also dressed in a suit.', 'Ein Mann in einem Anzug rennt an zwei anderen Herren vorbei, die auch einen Anzug tragen.'), (\"A young blond-haired boy and a dark-haired girl are eating at a kid's table.\", 'Ein blondhaariger Junge und ein dunkelhaariges Mädchen essen an einem Kindertisch.'), ('Asian man and blond woman holding hands outdoors, man in background watches.', 'Ein asiatischer Mann und eine blonde Frau, die Händchen halten, im Freien, ein Mann im Hintergrund sieht zu.'), ('A female martial arts student demonstrates with a weapon while others watch.', 'Eine Kampfsportschülerin führt etwas mit einer Waffe vor, während andere zusehen.'), ('Closeup of a man in a bar, holding his glasses slanted in front of his face.', 'Nahaufnahme eines Mannes in einer Bar, der seine Brille schräg vor sein Gesicht hält.'), ('A man leans into a car to talk to the driver, as a man on a bicycle looks on.', 'Ein Mann lehnt sich in ein Auto, um mit dem Fahrer zu reden, während ein Mann auf einem Fahrrad zusieht.'), ('A member of an African tribe is watching the camera intently in tribal dress.', 'Ein Mitglied eines afrikanischen Stamms in Stammeskleidung blickt konzentriert in die Kamera.'), ('A man standing on a railroad track looking through his binoculars at a river.', 'Ein Mann, der auf einer Eisenbahnschiene steht und durch sein Fernglas auf einen Fluss blickt.'), ('A line of six children in bathing suits prepare to leap into a swimming pool.', 'Eine aus sechs Kindern in Badeanzügen bestehende Reihe, die bereit ist, in ein Schwimmbecken zu springen.'), ('A brunette woman is sitting in a blue folding chair and reading at the beach.', 'Eine brünette Frau sitzt in einem blauen Klappstuhl am Strand und liest.'), ('A woman with long brunette hair and a beige hoodie is standing near cabinets.', 'Eine Frau mit langem brünettem Haar und einem beigefarbenen Kapuzenteil steht in der Nähe von Schränken.'), ('A woman in traditional Islamic garb walks through a plaza with a bearded man.', 'Eine Frau in traditioneller islamischer Kleidung geht mit einem bärtigen Mann durch ein Einkaufszentrum.'), ('A group of people in kilts are playing music while a runner in black runs by.', 'Eine Gruppe von Kiltträgern spielt Musik, während jemand schwarz gekleidetes vorbei rennt.'), (\"Young woman holding a bottle, reaching out from a bench to shake a man's hand.\", 'Eine junge Frau, die eine Flasche hält, streckt von einer Bank aus ihre Hand aus, um einem Mann die Hand zu schütteln.'), ('A brown and white dog jumping up to catch a Frisbee while an audience watches.', 'Ein braun-weißer Hund springt hoch, um eine Frisbee-Scheibe zu fangen, während Zuschauer zusehen.'), ('A bald little boy holds a chicken while two men are sitting in the background.', 'Ein glatzköpfiger kleiner Junge hält ein Huhn, im Hintergrund sitzen zwei Männer.'), ('People strolling in a mall with colorful decorations hanging from the ceiling.', 'Leute schlendern in einem Einkaufszentrum, in dem bunte Dekorationen von der Decke hängen.'), ('A young man is presenting another woman with a cake with three candles on top.', 'Ein junger Mann präsentiert einer anderen Frau einen Kuchen mit drei Kerzen darauf.'), ('A man in a red shirt pins a younger man in a white shirt to a blue padded mat.', 'Ein Mann in einem roten Hemd drückt einen jüngeren Mann in einem weißen Hemd auf eine blau gepolsterte Matte.'), ('A man in a red outfit is riding a red motorbike uphill on a motocross circuit.', 'Ein Mann in rotem Outfit fährt mit einem roten Motorrad auf einer Motocross-Strecke bergaufwärts.'), ('A man is playing a small guitar-like instrument and singing into a microphone.', 'Ein Mann spielt ein kleines gitarrenähnliches Instrument und singt in ein Mikrophon.'), ('Woman in red windbreaker looking though a rooftop binoculars at the city below.', 'Eine Frau in einer roten Windjacke, die über ein auf einem Dach installiertes Fernrohr auf die darunterliegende Stadt blickt.'), ('A man and a little girl happily posing in front of their cart in a supermarket.', 'Ein Mann und ein kleines Mädchen posieren glücklich vor ihrem Einkaufswagen im Supermarkt.'), ('A young boy waves his hand at the duck in the water surrounded by a green park.', 'Ein Junge winkt einer Ente im Wasser zu, umgeben von einer Grünanlage.'), ('Two individuals, a male and a female, standing in a forested area around a tub.', 'Zwei Personen, eine männlich und eine weiblich, stehen in einem Waldgebiet um eine Wanne herum.'), (\"Three kids on a grass field, one of them searching for food in her mom's purse.\", 'Drei Kinder auf einer Wiese, von denen eines in der Tasche seiner Mutter nach etwas zu essen sucht.'), ('A boy is holding his nose and jumping off a diving board backwards into a lake.', 'Ein Junge hält seien Nase zu und springt von einem Sprungbrett aus rückwärts in einen See.'), ('A smiling woman in a purple shirt and white apron wiping her hands on a napkin.', 'Eine lächelnde Frau in violettem Oberteil und weißer Schürze, die ihre Hände an einer Serviette abwischt.'), ('A young boy examines a field of pumpkins, with some already in his wheelbarrow.', 'Ein Junge durchsucht ein Kürbisfeld, ein paar befinden sich bereits in seiner Schubkarre.'), ('A little boy and a little girl are lying on a black bench surrounded by adults.', 'Ein kleiner Junge und ein kleines Mädchen,  die umgeben von Erwachsenen auf einer schwarzen Bank liegen.'), ('People inside of a building with their heads down with a view outside of bikes.', 'Leute mit gesenkten Köpfen in einem Gebäude, während draußen Motorräder zu sehen sind.'), ('A man in a bowling alley getting ready to throw the bowling ball down the lane.', 'Ein Mann in einer Bowlinghalle bereitet sich darauf vor, die Bowlingkugel zu werfen.'), ('A lady in a black top with glasses is sprinkling powdered sugar on a bundt cake.', 'Eine Frau mit schwarzem Oberteil und Brille streut Puderzucker auf einem Gugelhupf.'), ('A elderly father and his grown son are preparing for a camping trip in the wild.', 'Ein älterer Vater und sein erwachsener Sohn bereiten sich auf einen Camping-Ausflug in der Wildnis vor.'), ('A group of youths march down the street waving flags showing the color spectrum.', 'Eine Gruppe Jugendlicher geht die Straße entlang und schwenkt Fahnen, die das Farbspektrum zeigen.'), ('A woman in a white tank top with a green flowing skirt, on stage singing a song.', 'Eine Frau einem einem weißen Pullunder mit einem grünen, wallenden Rock ein Lied singend auf der Bühne.'), ('A bike sitting in a street with a rope tied to it and a guy walking on the rope.', 'Ein Motorrad in einer Straße, an das ein Seil gebunden ist, und ein Mann, der auf dem Seil geht.'), ('A little toddler dressed in white is smiling while a lady helps him wave a flag.', 'Ein weiß gekleidetes Kleinkind lächelt, während eine Dame ihm hilft, eine Flagge zu schwenken.'), ('A white, young man in dreadlocks and a green kilt is sitting on a couch smiling.', 'Ein weißer, junger Mann mit Dreadlocks und einem grünen Kilt sitzt auf einer Couch und lächelt.'), ('Two people take in the scene as they stand together looking out over the canyon.', 'Zwei Personen stehen beieinander, blicken über die Schlucht und lassen den Anblick auf sich wirken.'), ('Skiers get caught on the dusty slopes and almost fall down and break their legs.', 'Skifahrer bleiben auf der staubigen Piste hängen, fast fallen sie und brechen sich die Beine.'), ('A young woman standing on a window ledge of brick building while child looks on.', 'Eine junge Frau steht an einer Fensterbank eines Ziegelgebäudes, während ein Kind zusieht.'), ('A man dressed as a cook enjoys a meal and bottle of wine in an empty restaurant.', 'Ein als Koch gekleideter Mann in einem leeren Restaurant genießt eine Mahlzeit und eine Flasche Wein.'), ('Several travelers either standing or sitting on what appears to be a subway car.', 'Mehrere Reisende, die in etwas, was wie eine U-Bahn aussieht, sitzen oder stehen.'), ('A man and a much younger boy, both wearing hats, taking a stroll through nature.', 'Ein Mann und ein viel jüngerer Junge, beide mit Mützen, spazieren durch die Natur.'), ('A boy jump kicking over three kids kicking wood during a tae kwon do competition.', 'Ein Junge, der während eines Taekwondo-Wettbewerbs einen Sprungtritt über drei Kinder macht und dabei auf Holz tritt.'), ('A man in a wetsuit is throwing a toddler up in the air and is ready to catch him.', 'Ein Mann in einem Taucheranzug wirft ein Krabbelkind in die Luft und ist bereit, es aufzufangen.'), ('A person with brown pants is sitting around a fenced area that has sparks flying.', 'Eine Person mit braunen Hosen sitzt neben einem eingezäunten Bereich, in dem Funken fliegen.'), ('Three people enter a building with a handwritten sign that says \"Welcome Bikers.\"', 'Drei Personen betreten ein Gebäude mit einen handgeschriebenen Schild, auf dem steht „Welcome Bikers“.'), ('A very colorful bus is pulled off to the side of the road as its passengers load.', 'Ein sehr farbenfroher Bus steht am Straßenrand, während die Passagiere zusteigen.'), ('People are gathered around and walking buy a display of clothing and other items.', 'Menschen sammeln sich um ausgestellte Kleidung und andere Artikel und gehen daran vorbei.'), ('Two male security officers are restraining another man by the shoulders and arms.', 'Zwei männliche Security-Mitarbeiter halten einen anderen Mann an Schultern und Armen fest.'), ('A bike rider wearing a red shirt and black shorts is attended to by city workers.', 'Städtische Arbeiter kümmern sich um einen Motorradfahrer mit einem roten Hemd und schwarzen Shorts.'), ('Two chefs talk together behind a tiled restaurant calendar in a fancy restaurant.', 'Zwei Köche reden hinter einer gefliesten Theke in einem schicken Restaurant miteinander.'), ('A large crowd of people stand outside in front of the entrance to a Metro station.', 'Eine große Menschenmenge steht außen vor dem Eingang einer Metrostation.'), ('A group of people riding in the back of a truck, down the road, in a country area.', 'Eine Gruppe fährt hinten auf einem Lkw mit, eine ländliche Straße entlang.'), ('A woman dressed in light purple and wearing a corsage clasps her hands in her lap.', 'Eine Frau, die lilafarben gekleidet ist und ein Mieder trägt, faltet die Hände in ihrem Schoß.'), (\"Two women hugging in a grassy, fenced field with a cow's behind in the background.\", 'Zwei Frauen, die sich auf einer eingezäunten Wiese umarmen, mit dem Hinterteil einer Kuh im Hintergrund.'), ('Three people sitting outside on small rocks behind a big bush, wearing long pants.', 'Drei Personen mit langen Hosen sitzen im Freien auf kleinen Steinen hinter einem großen Busch.'), ('Two restaurant employees exchange a plate of food under a Mongolian BBQ neon sign.', 'Zwei Restaurantmitarbeiter unter einer „Mongolian BBQ“-Leuchtreklame übergeben einen Teller mit Essen.'), ('Man wearing protective eye gear performs a science experiment while woman watches.', 'Ein Mann, der Augenschutz trägt, führt ein naturwissenschaftliches Experiment durch, während eine Frau zusieht.'), ('A very young boy sliding down a slide into a swimming pool, wearing blue floaties.', 'Ein ganz kleiner Junge mit blauen Schwimmflügeln, der über eine Rutsche in ein Schwimmbecken rutscht.'), ('A man with a ponytail and tan tank top sitting on a couch counting on his fingers.', 'Ein Mann mit Pferdeschwanz und gelbbraunem Tanktop, der auf einer Couch sitzt und etwas an seinen Fingern abzählt.'), ('A man in black attire shovels snow into the street, disregarding all public safety.', 'Ein Mann in Schwarz schaufelt Schnee auf die Straße und ignoriert dabei die öffentliche Sicherheit.'), ('A brown and black lab are outside and the black lab is catching a toy in its mouth.', 'Ein brauner und ein schwarzer Labrador im Freien, wobei der schwarze Labrador ein Spielzeug in seinem Maul hat.'), ('A man jumps off of a small stone bridge while three children and a woman watch him.', 'Ein Mann springt von einer kleinen Steinbrücke, während ihm drei Kinder und eine Frau zusehen.'), ('Two young male hikers using a map and compass to find their direction in the woods.', 'Zwei junge männliche Wanderer, die Karte und Kompass verwenden, um im Wald ihre Richtung zu finden.'), ('Three people wearing colorful costumes and masks sitting between two stone statues.', 'Drei Personen mit farbenfrohen Kostümen und Masken, die zwischen zwei Statuen aus Stein sitzen.'), ('2 people sit barefoot in a tent, one with a beer and one lounging playing a guitar.', '2 Personen sitzen barfuß in einem Zelt, eine hat ein Bier in der Hand und eine sitzt herum und spielt Gitarre.'), ('A heavyset couple interact outside a striped cabana on a beach located near a pier.', 'Ein beleibtes Paar ist vor einem gestreiften Umkleidezelt an einem Strand in der Nähe eines Piers miteinander beschäftigt.'), ('A young Asian boy leaps for joy into a pool of water, his tongue stuck out for joy.', 'Ein asiatischer Junge springt vor Freue in eine Wasserpfütze, seine Zunge ist vor Freude herausgestreckt.'), ('A man with a white shirt and tie is standing on a sidewalk between cement barriers.', 'Ein Mann mit weißem Hemd und Krawatte steht auf einem Bürgersteig zwischen Betonsperren.'), ('A bunch of elderly women play their clarinets together as they read off sheet music.', 'Eine Gruppe älterer Frauen spielt zusammen Klarinette von Notenblättern.'), ('Seven climbers are ascending a rock face whilst another man stands holding the rope.', 'Sieben Kletterer klettern eine Felswand hoch, während ein anderer Mann dasteht und das Seil hält.'), ('Many people cross a very tall footbridge with a tree-covered hill in the background.', 'Viele Menschen überqueren eine sehr hohe Fußbrücke mit einem baumbewachsenen Hügel im Hintergrund.'), ('5 athletes wearing white tops and white bottoms are doing a routine for an audience.', '5 Athleten mit weißen Tops und weißen Hosen führen einem Publikum etwas vor.'), ('A busy street with lots of people standing around talking and two are holding bikes.', 'Eine belebte Straße, wo viele Menschen herumstehen und sprechen und zwei Fahrräder halten.'), ('A soccer player in a red uniform goes after the ball, fending off a player in white.', 'Ein Fußballspieler in einem roten Dress rennt dem Ball nach und wehrt einen Spieler in Weiß ab.'), ('A snarling brown and black dog corners a brown long-haired cat under a wooden bench.', 'Ein knurrender braun-schwarzer Hund stellt eine braune Langhaarkatze unter einer Holzbank.'), ('A little boy wearing a blue baseball cap is sitting on a dock overlooking the water.', 'Ein kleiner Junge mit einer blauen Baseballkappe sitzt auf einem Dock und blickt auf das Wasser.'), ('A guy in a yellow shirt and light brown slacks is playing golf while the crowd watch.', 'Ein Mann in einem gelben Hemd und hellbraunen Hosen spielt Gold, während die Menschenmenge zusieht.'), ('A man in a gray and black sweater is sitting on a stool in front of a group of cages.', 'Ein Mann in einem grau-schwarzen Pullover sitzt auf einem Hocker vor einer Gruppe von Käfigen.'), ('A little boy is holding a green and yellow sponge while standing in front of a stove.', 'Ein kleiner Junge steht vor einem Herd und hält einen grün-gelben Schwamm.'), ('A gentleman in a purple scarf and hat is looking at money while holding an accordion.', 'Ein Herr mit violettem Schal und Hut hält ein Akkordeon und blickt auf Geld.'), ('A young man in a gray jacket stands behind the counter of a jewelery store and smiles.', 'Ein junger Mann in einer grauen Jacke steht hinter der Theke eines Juweliergeschäfts und lächelt.'), ('A pile of seaweed sits on the sand, behind it a big black dog is running in the water.', 'Ein Haufen Algen liegt auf dem Sand, dahinter rennt ein großer schwarzer Hund ins Wasser.'), ('A young guy, probably in his early twenties, shows off his culinary skills with pride.', 'Ein junger Mann, vermutlich Anfang zwanzig, führt stolz seine kulinarischen Künste vor.'), ('A man pulling a fancy rickshaw along a waterway smiles and gives the \"thumbs up\" sign.', 'Ein Mann, der eine schicke Rikscha an einem Wasserweg entlang zieht, lächelt und zeigt mit dem Daumen nach oben.'), ('There are about a dozen of men in work clothes that are getting directions for a task.', 'Ungefähr ein Dutzend Männer in Arbeitskleidung erhalten Anweisungen für eine Aufgabe.'), ('A boy in a red hat and black shirt is skateboarding near a red and white striped curb.', 'Ein Junge in roter Mütze und schwarzem Hemd fährt in der Nähe einer rot-weiß-gestreiften Bordsteinkante Skateboard.'), ('An outdoor cafe with people sitting while a man in white shirt is walking toward them.', 'Ein Cafe im Freien, in dem Leute sitzen, während ein Mann mit einem weißen Hemd auf sie zugeht.'), ('There are many people with black hair heading through some doors and a few coming out.', 'Viele Leute mit schwarzen Haaren gehen durch ein paar Türen und wenige kommen heraus.'), ('A man in a dark jacket stands next to a man dressed in brown reaching down into a bag.', 'Ein Mann in einer dunklen Jacke steht neben einem braun gekleideten Mann, der in eine Tasche greift.'), ('A man wearing swimming trunks jumps off a concrete platform into a large body of water.', 'Ein Mann, der eine Badehose trägt, springt von einer Betonplattform aus in eine großes Gewässer.'), ('A man in a black suit and briefcase hurrying somewhere, while talking on his cellphone.', 'Ein Mann in einem schwarzen Anzug und mit Brieftasche eilt irgendwo hin, während er am Handy spricht.'), ('A young man standing in front of a red freight car holding a camera and taking a photo.', 'Ein junger Mann, der vor einem roten Güterwaggon steht, eine Kamera hält und ein Foto macht.'), ('Two African American makes play their trumpets in a major city with onlookers watching.', 'Zwei afroamerikanische Männer spielen in einer größeren Stadt Trompete und werden von Zuschauern betrachtet.'), ('Young girl stirs a pot with a spoon in the kitchen while wearing a large black blanket.', 'Ein Mädchen, das eine große schwarze Decke trägt, rührt in der Küche mit einem Löffel in einem Topf.'), ('One man kissing another man on the check and both are in white shirts with black vests.', 'Ein Mann, der einen anderen Mann auf die Wange küsst, und beide tragen weiße Hemden mit schwarzen Westen.'), ('A lady in a white t-shirt is looking toward the person with their arm raised in the air.', 'Eine Dame in einem weißen T-Shirt blickt zu der Person, die ihren Arm in die Luft streckt.'), ('A young group of friends adorned with face paint and feathered headbands sit on a bench.', 'Ein Gruppe von Freunden mit Gesichtsfarbe und Federstirnbändern sitzt auf einer Bank.'), ('A line of people, some standing and some sitting, are waiting on a platform for a train.', 'Eine Reihe von Menschen, einige stehend und einige sitzend, warten auf einem Bahnsteig auf einen Zug.'), ('A man and two women wearing all black act out a scene in front of a building with steps.', 'Ein Mann und zwei Frauen ganz in Schwarz spielen eine Szene vor einem Gebäude mit Stufen.'), ('An artist consults the plan for her section of an elaborate chalk drawing on a sidewalk.', 'Eine Künstlerin sieht auf dem Plan für ihren Abschnitt eines komplizierten Kreidegemäldes auf einem Bürgersteig nach.'), ('Two persons carry a large, inflatable bottle, past a young woman and a parked white car.', 'Zwei Personen tragen eine große aufblasbare Flasche an einer jungen Frau und einem geparkten weißen Auto vorbei.'), ('There is a man on a bucking horse holding on tightly while the crowd watches at a rodeo.', 'Bei einem Rodeo hält sich ein Mann auf einem bockenden Pferd gut fest, während die Menge zusieht.'), ('A young woman on a boat in a light colored bikini kicks a man wearing a straw cowboy hat.', 'Eine junge Frau auf einem Boot in einem hellen Bikini tritt einen Mann, der einen Cowboy-Hut aus Stroh trägt.'), ('A man in sandals and white cardigan sits on a green bench while talking on his cellphone.', 'Ein Mann in Sandalen und weißer Jacke sitzt auf einer grünen Bank uns spricht am Handy.'), ('A man with a pitchfork stands near a bucket of branches across from an apartment complex.', 'Ein Mann mit einer Mistgabel steht bei einem Eimer mit Zweigen gegenüber einem Apartmentkomplex.'), ('A man with a guitar is sitting on a bench outside with three other people sitting by him.', 'Ein Mann mit einer Gitarre sitzt auf einer Bank im Freien, drei andere Personen sitzen bei ihm.'), ('A crowd of people are standing together on a sidewalk, while one man is taking a picture.', 'Eine Menschenmenge steht auf einem Bürgerteig, während ein Mann fotografiert.'), ('A man with a red jacket is shielding himself from the sun trying to read a piece of paper.', 'Ein Mann mit einer roten Jacke, der sich vor der Sonne schützt und versucht, ein Stück Papier zu lesen.'), ('A little boy is standing on the street while a man in overalls is working on a stone wall.', 'Ein kleiner Junge, der auf der Straße steht, während ein Mann in einem Overall an einer Steinwand arbeitet.'), ('Three guys riding on an elephant with a house-like structures and trees in the background.', 'Drei Männer reiten auf einem Elefanten mit hausähnlichen Gebäuden und Bäumen im Hintergrund.'), ('Surrounded by spectators, a man in a red shirt, white pants and visor, swings a golf club.', 'Ein Mann in rotem Hemd, weißen Hosen und Sonnenschild schwingt, umgeben von Zuschauern, einen Golfschläger.'), ('Three men work quickly preparing food in the kitchen of an upper-class Chinese restaurant.', 'Drei Männer arbeiten rasch und bereiten in der Küche eines vornehmen chinesischen Restaurants Speisen zu.'), ('People are standing around an American flag that is spread out, facing the wrong direction.', 'Menschen stehen um eine ausgebreitete amerikanische Fahne herum, die in die falsche Richtung zeigt.'), ('Five men, one wearing a white shirt standing on something, hanging up a picture of a child.', 'Fünf Männer, von denen einer ein weißes Hemd trägt, die auf etwas stehen und das Bild eines Kindes aufhängen.'), ('A young girl in a yellow dance, dancing on a stage with a baseball field in the background.', 'Ein Mädchen in einem gelben Tanz tanzt auf einer Bühne mit einem Baseballfeld im Hintergrund.'), ('An older man with gray hair is sitting in a chair playing a large instrument made of bamboo.', 'Ein älterer Mann mit grauem Haar, der in einem Stuhl sitzt und ein großes Instrument aus Bambus spielt.'), ('Four children are smiling as they pose together with a bicycle that is much too big for them.', 'Vier Kinder lächeln, während sie zusammen mit einem Fahrrad posieren, das viel zu groß für sie ist.'), ('A man is sitting in front of a computer monitor holding a keyboard and looking at the camera.', 'Ein Mann sitzt vor einem Computerbildschirm, hält eine Tastatur und blickt in die Kamera.'), ('A man in sitting in front of a large Calvin Klein steel advertisement with a long instrument.', 'Ein Mann, der mit einem langen Instrument vor einer großen Calvin-Klein-Stahlwerbung sitzt.'), ('A little girl in a red shirt and jeans climbs a small tree while another little girl looks on.', 'Ein kleines Mädchen mit einem roten Oberteil und Jeans klettert auf einen kleinen Baum, während ein anderes Mädchen zusieht.'), ('A person is standing with one leg propped up with an object with a blue line in his left hand.', 'Eine stehende Person hat ein Bein aufgestellt und hat ein Objekt mit einer blauen Linie in der linken Hand.'), ('A lone musician in black is on stage, playing an acoustic guitar and singing into a microphone.', 'Ein einzelner Musiker in Schwarz ist auf der Bühne, spielt akustische Gitarre und singt in ein Mikrofon.'), ('A man wearing a gray t-shirt and blue jeans stands ready to hit a golf ball at a driving range.', 'Ein Mann mit einem grauen T-Shirt und Bluejeans auf einem Driving-Range ist bereit, einen Golfball zu schlagen.'), ('A black woman and a white man working in a factory setting packing jars with candles into boxes.', 'Eine schwarze Frau und ein weißer Mann arbeiten in einer Fabrikumgebung und packen Gläser mit Kerzen in Kartons.'), ('An old weathered, bearded man wearing all black, riding a beautiful white donkey on white rocks.', 'Ein alter wettergegerbter Mann mit Bart, der ganz in Schwarz gekleidet ist, reitet auf einem schönen weißen Esel auf weißen Felsen.'), ('Boy with dark skin, standing on his head with legs spread, at the end of a floating wooden boat.', 'Ein Junge mit dunkler Haut, der am Ende eines schwimmenden Holzboots mit gespreizten Beinen auf dem Kopf steht.'), ('In a crowded concert a man in white is approaching the main singer who is wearing a yellow shirt.', 'In einem vollen Konzert nähert sich ein Mann dem Hauptsänger, der ein gelbes Hemd trägt.'), ('Two men sitting on a bench talking, with a billboard advertisement for glasses in the background.', 'Zwei Männer sitzen auf einer Bank und reden, im Hintergrund eine Reklamefläche mit Werbung für Brillen.'), ('A samurai warrior in full black dress takes his sword from the sheath on an outdoor training mat.', 'Ein Samurai-Krieger ganz in Schwarz auf einer Übungsmatte im Freien nimmt sein Schwert aus der Scheide.'), ('A little boy skateboarder is doing a trick on his board while another young skateboarder watches.', 'Ein kleiner Junge führt ein Kunststück auf seinem Skateboard aus, während ein anderer junger Skateboarder zusieht.'), ('Two jugglers using flaming torches are performing for a crowd of people who are sitting on steps.', 'Zwei Jongleure mit Fackeln geben eine Vorführung für eine dichte Menschenmenge, die auf Stufen sitzt.'), ('A man looks through a large camera-like device in a field near a camper and some parked vehicles.', 'Ein Mann blickt durch ein großes, kameraähnliches Gerät in ein Feld in der Nähe eines Wohnmobils und einiger geparkter Fahrzeuge.'), ('An Elderly man crouches to lift the covering off the grill wear several shish kabab are grilling.', 'Ein älterer Mann geht in die Hocke, um die Abdeckung des Grills hochzuheben, wo mehrere Shish Kebabs gegrillt werden.'), ('A man playing a guitar while a couple is listening and watching another man dancing to the music.', 'Ein Mann spielt Gitarre, während ein Paar zuhört und einem anderen Mann zusieht, der zur Musik tanzt.'), ('Some people with black belts, or black and red belts, are performing martial arts on a green mat.', 'Einige Personen mit schwarzen Gürteln, oder schwarzen und roten Gürteln, praktizieren Kampfsport auf einer grünen Matte.'), ('Two teenage girls, one wearing a white jersey and the other wearing a red jersey, playing soccer.', 'Zwei Teenagerinnen, eine mit einem weißen Trikot, die andere mit einem roten Trikot, spielen Fußball.'), ('Blond child with large black coat, multicolored scarf, and knit hat standing in front of a window.', 'Ein blondes Kind mit großem schwarzem Mantel, mehrfarbigem Schal und Strickmütze steht vor einem Fenster.'), ('Two young men clutch rags in their hands as a elderly man tells them how to clean the large cross.', 'Zwei junge Männer halten Lappen in ihren Händen, während ihnen ein älterer Mann erklärt, wie sie das große Kreuz reinigen sollen.'), ('Several children sit on a carnival ride in front of the face of a clown and several fake balloons.', 'Mehrere Kinder sitzen auf einem Karussell vor dem Gesicht eines Clowns und mehrerer Luftballonimitate.'), ('A varied crowd mills about (or rough-houses) on a public street, with lots of bicycles on display.', 'Eine bunt gemischte Menschenmenge läuft auf einer Straßen herum (oder macht Radau), wo viele Fahrräder ausgestellt sind.'), ('The man with the backpack is sitting in a buildings courtyard in front of an art sculpture reading.', 'Der Mann mit dem Rucksack sitzt im Hof eines Gebäudes vor einer Skulptur und liest.'), ('A girl doing a split handstand on the beach during the day with a amusement park in the background.', 'Ein Mädchen, das tagsüber am Strand einen Handstand mit Grätsche macht, während im Hintergrund ein Vergnügungspark zu sehen ist.'), ('A boy in swim trunks does a backflip into the ocean while mountains show through the fog behind him.', 'Ein Junge in Badehosen macht eine Rolle rückwärts ins Meer, hinter ihm sind durch den Nebel Berge zu sehen.'), ('The woman tries to hide from work under a black sweatshirt, but her red corduroy pants give her away.', 'Die Frau versucht, sich unter einem schwarzen Sweatshirt vor der Arbeit zu verstehen, aber ihre roten Cordhosen verraten sie.'), ('A female swimmer wearing a swim cap and nose clips moves slowly through the water is seen from below.', 'Eine Schwimmerin mit Bademütze und Nasenklemmen, die sich langsam durch das Wasser bewegt, von oben gesehen.'), ('A couple enjoy a beautiful day bicycling on a bike trail wearing bicycling safety helmets and gloves.', 'Ein Paar, das beim Fahrradfahren auf einem Radweg Fahrradhelme und Handschuhe trägt, genießt einen schönen Tag.'), ('Workers are serving up customers lined up in front of a Martins famous louisiana sausages vendor tent', 'Arbeiter bedienen Kunden, die vor einem Verkaufszelt von Martins Famous Lousiana Sausages Schlange stehen.'), ('Several people are riding on a roller coaster while reacting to going through a loop in various ways.', 'Mehrere Personen fahren auf einer Achterbahn und reagieren auf unterschiedliche Weise auf einen Looping.'), ('Five men, uniformly dressed in white shirts, tie and black slacks converse at the back of an open van.', 'Fünf Männer, die alle weiße Hemden, Krawatten und schwarze Freizeithosen tragen, unterhalten sich hinter einem Lieferwagen.'), ('One man in a blue shirt is operating a watering hose and another man in a brown shirt is moving tarps.', 'Ein Mann in einem blauen Hemd bedient einen Bewässerungsschlauch, und ein andere Mann in einem braunen Hemd bewegt Ölzeug.'), ('A family coming back from shopping and a gentlemen is reading his newspaper to the side of the street.', 'Eine Familie, die vom Einkaufen zurückkommt, und ein Herr, der am Straßenrand seine Zeitung liest.'), ('One boy in a striped shirt and one girl in a green shirt each riding on bicycles with training wheels.', 'Ein Junge in einem gestreiften Hemd und ein Mädchen in einer grünen Hemdbluse fahren auf Fahrrädern mit Stützrädern.'), ('A little girl in an elaborate green and orange dress is chasing after a pink and white balloon figure.', 'Ein kleines Mädchen in einem ausgefeilten grün-orangefarbenen Kleid rennt einer rosa-weißen Luftballonfigur nach.'), ('A person dressed in a blue coat is standing in on a busy sidewalk, studying painting of a street scene.', 'Eine Person in einem blauen Mantel steht auf einem belebten Gehweg und betrachtet ein Gemälde einer Straßenszene.'), ('A woman in a teal shirt and a beige cardigan looks away from the board game she is sitting in front of.', 'Eine Frau in einem türkisen Oberteil und einer beigefarbenen Strickjacke blickt von einem Brettspiel auf, vor dem sie sitzt.'), ('Two men in a wooden boat, one wearing yellow and one wearing black, traveling on a smooth body of water.', 'Zwei Männer in einem Holzboot, von denen einer gelb und einer schwarz angezogen ist, die auf einem glatten Gewässer unterwegs sind.'), ('A woman squatting in the grass is smiling at a little boy, as he smiles and raises his hands in the air.', 'Eine Frau, die im Gras in der Hocke sitzt, lächelt einen kleinen Jungen an, der selbst lächelt und seine Hände hoch hebt.'), ('Girl with green tank top standing in the middle of a train track with multicolor train cars to the right.', 'Ein Mädchen mit grünem Pullunder, die in der Mitte eines Zuggleises steht, rechts mehrfarbige Zugwaggons.'), ('Two boys, one in a red and one in a white uniform, fight for control over the ball during a soccer match.', 'Zwei Jungen, einer in einem roten und einer in einem weißen Dress, kämpfen bei einem Fußballspiel darum, wer die Kontrolle über den Ball gewinnt.'), ('A man wearing a yellow shirt standing in the middle of two beds that a boy is jumping on in the background', 'Ein Mann, der ein gelbes Hemd trägt und in der Mitte von zwei Betten steht, auf denen im Hintergrund ein Junge springt.'), (\"A woman carries a child in her arm and holds another child's hand as they walk outside next to a building.\", 'Eine Frau trägt ein Kind auf dem Arm und hält die Hand eines anderen Kindes, während sie neben einem Gebäuden entlanggehen.'), ('A man wearing a black helmet, blue jacket, and khaki shirts rides his bike on the street next to a red car.', 'Ein Mann mit Fahrradhelm, blauer Jacke und khakifarbenen Hosen fährt mit seinem Fahrrad auf der Straße neben einem roten Auto.'), ('A female washes her medium-sized dog outdoors in a plastic container while a friend secures it with a leash.', 'Eine weibliche Person wäscht ihren mittelgroßen Hund im Freien in einem Kunststoffbehälter, während ein Freund ihn an einer Leine sichert.'), ('A man wearing a ball cap and a blue T-shirt rides a white horse down a dirt road through lush, green nature.', 'Ein Mann mit Schildkappe und blauem T-Shirt reitet ein weißes Pferd auf einer unbefestigten Straße durch üppiges Grün.'), ('A young boy wearing a blue t-shirt holds up an odd-looking object for inspection while standing among trees.', 'Ein Junge mit einem blauen T-Shirt steht zwischen Bäumen und hält ein komisch aussehendes Objekt zur Begutachtung hoch.'), ('A man in a baseball cap cleans out a blue colored pit outside where colorful Christmas lights hang above him.', 'Ein Mann mit Baseballkappe reinigt im Freien eine blaue Grube, über ihm hängen bunte Weihnachtslichter.'), ('A man dressed in a burgundy shirt and black pants maneuvering a puppet which is holding a musical instrument.', 'Ein Mann in einem burgunderroten Hemd und schwarzen Hosen, der eine Marionette mit einem Musikinstrument bewegt.'), ('Man in blue shirt and black pants is looking at his thumb on one hand while holding glasses in his other hand.', 'Ein Mann in blauem Hemd und blauen Hosen, der auf den Daumen einer seiner Hände blickt und in der anderen Hand Gläser hält.'), ('Couple, man and woman, with little girl all of them dressed in wedding apparel while standing along shoreline.', 'Ein Paar, ein Mann und eine Frau, mit einem kleinen Mädchen, alle in Hochzeitskleidung, wie sie an der Uferlinie stehen.'), ('Several men of Indian origin are conversing and one, in particular, seems very excited about the conversation.', 'Mehrere Männer indischer Herkunft unterhalten sich, und einer scheint besonders aufgeregt zu sein.'), ('Two people in black vests are standing in front of children in white vests with an American flag between them.', 'Zwei Personen in schwarzen Hemden stehen vor Kindern in weißen Hemden mit einer amerikanischen Flagge.'), ('At the bakery, the fat old baker sleeps while his apprentice rubs the flour out of his eyes, seated beside him.', 'In der Bäckerei schläft der dicke alte Bäcker, während der Lehrling neben ihm sitzt und sich das Mehl aus den Augen reibt.'), ('Man in orange shorts builds a sand castle, combining multiple pictures into one resulting in four copies of him.', 'Ein Mann in organgefarbenen kurzen Hosen baut einen Sandburg, wobei mehrere Bilder zu einem kombiniert sind, sodass er vier Mal zu sehen ist.'), ('Two young people are approached by a flamboyant young woman dressed in a red bikini and a red feathered headress.', 'Eine extravagante jungen Frau in einem roten Bikini und einem roten Feder-Kopfschmuck kommt auf zwei junge Leute zu.'), ('A woman with a floral shirt and purse and a man with a black shirt are walking while another man walks behind them.', 'Eine Frau in einem geblümten Oberteil und Handtasche und ein Mann in einem schwarzen Hemd gehen, während ein anderer Mann hinter ihnen geht.'), ('Five hikers, one facing towards the camera and the others facing away from it, are walking through a rocky riverbed.', 'Fünf Wanderer, von denen einer in Richtung Kamera blickt und die anderen von der Kamera weg, gehen durch ein steiniges Flussbett.'), ('A child wearing black and white swim gear kneeling in shallow water over a plastic yellow boat filled with wet sand.', 'Ein Kind in schwarz-weißem Badezeug kniet im flachen Wasser über einem gelben Plastikboot, das mit nassem Sand gefüllt ist.'), ('A barefooted man wearing olive green shorts grilling hotdogs on a small propane grill while holding a blue plastic cup.', 'Ein Mann, der barfuß ist, olivgrüne kurze Hosen trägt, auf einem kleinen Propangasgrill Hotdogs grillt und gleichzeitig eine blaue Kunststofftasse hält.'), ('2 boys in the foreground in a karate competition and coaches in background looking on with another coach sitting at table.', '2 Jungen im Vordergrund bei einem Karate-Wettkampf und Trainer im Hintergrund, die zusehen, während ein anderer Trainer am Tisch sitzt.'), ('A man with a shoulder bag walking in the desert on sand with footprints behind him and the horizon with many stormy clouds.', 'Ein Mann mit einer Schultertasche geht in der Wüste auf Sand, hinter ihm Fußabdrücken und der Horizont mit vielen Sturmwolken.'), ('A young girl wearing a multicolored holding an orange ball in her right hand walking through bright green grass behind a house', 'Ein junges Mädchen, das mehrfarbig gekleidet ist, einen orangefarbenen Ball in der rechten Hand trägt und hinter einem Haus durch leuchtend grünes Gras geht.'), ('Blond woman driving a red bicycle carriage holds the tip of her hat and poses for the camera with a customer seated in the back.', 'Eine blonde Frau, die eine rote Fahrradkutsche fährt, hält die Spitze ihres Huts und posiert für die Kamera, während ein Kunde im hinteren Teil der Kutsche sitzt.'), (\"2 women wearing brightly colored clothes are sitting next to a dirt road on a rock having a conversation while they 're watching the field.\", '2 Frauen mit Kleidung in leuchtenden Farben sitzen neben einer unbefestigten Straße auf einem Stein und unterhalten sich, während sie auf das Feld blicken.'), ('A man and a woman locking arms (wearing expensive clothing) next to glass display (perhaps retail stores) on the sidewalk in an urban setting.', 'Ein Mann und eine Frau (in teurer Kleidung), die sich neben einem Glasschaufenster (vielleicht Einzelhandel) auf dem Bürgersteig in einer städtischen Umgebung untergehakt haben.'), ('A male in a black shirt, and black pants, working on the engine of an old, green antique automobile, with a yellow gas canister sitting on the grass.', 'Ein Mann in einem schwarzen Hemd und schwarzen Hosen, der auf dem Motor eines alten, grünen, antiken Autos arbeitet, während ein gelber Benzinkanister im Gras steht.'), ('A woman in a green shirt and jeans kneels on a stoop with coffee in hand, her purse beside her and a large door behind her, as she fills out paperwork.', 'Eine Frau in grünem Oberteil und Jeans kniet auf einer offenen Veranda mit einem Kaffee in der Hand, neben ihr ihre Handtasche und hinter ihr eine große Tür, während sie Formulare ausfüllt.'), ('A soccer player in a green uniform with a ball in is hands is being held up by some of his teammates, while an opposing player in red reaches for the ball.', 'Ein Fußballspieler in grünem Fußballdress mit einem Ball in seinen Händen wird von einem seiner Teamkollegen aufgehalten, während ein Spieler der gegnerischen Mannschaft in Rot nach dem Ball greift.'), (\"Three young adults are sitting around, with the girl pretending to kick one of the guys in the face while laughing, and the guy behind him looks like he's in midsentence.\", 'Drei junge Erwachsenen sitzen herum, wobei eine junge Frau so tut, als ob sie einem der jungen Männer ins Gesicht tritt und dabei lacht, und der junge Mann hinter sieht aus, als ob er gerade mitten im Satz ist.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequenceDataset.__getitem__(0))"
      ],
      "metadata": {
        "id": "L3WwzUFdRbk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e3a624-5e33-4875-eb79-b689b4e2dc27"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('A man sits on a rock.', 'Ein Mann sitzt auf einem Stein.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(sequenceDataset, batch_size=16, collate_fn = PadCollate(sequenceDataset.src_tokenizer, sequenceDataset.tgt_tokenizer))"
      ],
      "metadata": {
        "id": "zLayKBKBLAYy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src, tgt in train_dataloader:\n",
        "    print(\"batch:\", src[0].ids)\n",
        "    print(\"decoded\", sequenceDataset.src_tokenizer.decode(src[0].ids))\n",
        "    print(\"tgt\", tgt)\n",
        "\n",
        "    print(\"mask:\", src[0].attention_mask)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnqolodQCYE",
        "outputId": "c67151fa-37ee-468c-8cc1-2adda7ae29f2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: [30, 93, 398, 89, 57, 423, 15]\n",
            "decoded A man sits on a rock .\n",
            "tgt [Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]), Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]\n",
            "mask: [1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequenceDataset.__getitem__(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ZTre_Uo18S",
        "outputId": "6d6bc65d-d060-4703-ed71-e340b1d82f31"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('A man sits on a rock.', 'Ein Mann sitzt auf einem Stein.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair = sequenceDataset.__getitem__(0)\n",
        "\n",
        "num_encoder_layers = 5\n",
        "num_decoder_layers = 5\n",
        "num_heads = 8\n",
        "d_attn = 64\n",
        "d_x = 512\n",
        "d_z = 512\n",
        "d_out = 512\n",
        "d_mid = 512\n",
        "d_mlp = 2048\n",
        "d_e = 512\n",
        "vocab_size = 10000\n",
        "max_sequence_length = 100\n",
        "\n"
      ],
      "metadata": {
        "id": "vFPxq_hkffx3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(x, tokenizer):\n",
        "    x = torch.softmax(x, -1)\n",
        "    #print(\"x softmax:\", x)\n",
        "    x = torch.argmax(x, dim=-1)\n",
        "    x = x.tolist()\n",
        "    print(\"argmax x:\", x)\n",
        "    return tokenizer.decode(x)"
      ],
      "metadata": {
        "id": "ERDbLlQVzJUx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_decode(tokenizer):\n",
        "    x = torch.tensor([[0, 5], [10, 20]], dtype=torch.float32)\n",
        "    words = decode(x, tokenizer)\n",
        "    print(words)\n",
        "\n",
        "test_decode(sequenceDataset.tgt_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSetg38X8TAo",
        "outputId": "823ff807-9ab3-4633-9bc5-20bcd3ab12e8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "argmax x: [1, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(25)\n",
        "encoder_decoder_transformer = EncoderDecoderTransformer(num_encoder_layers, num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, d_e, vocab_size, max_sequence_length, False).to(device)\n",
        "opt = optim.Adam(encoder_decoder_transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "epochs = 1000\n",
        "# Large models need this to actually train\n",
        "for p in encoder_decoder_transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "#labelSmoothing = LabelSmoothing(2000, PADDING_IDX, 0.1)\n",
        "step = 0\n",
        "for i in range(epochs):\n",
        "    dataloader_iter = iter(train_dataloader)\n",
        "    losses = []\n",
        "    for src_sequence, tgt_sequence in dataloader_iter:\n",
        "        # print(\"x:\", sequence_x)\n",
        "        # print(\"z:\", sequence_z)\n",
        "        # sequence_x, sequence_z = sequenceDataset.__getitem__(i)\n",
        "        src_tokens = torch.IntTensor([sequence.ids for sequence in src_sequence]).to(device)\n",
        "        tgt_tokens = torch.IntTensor([sequence.ids for sequence in tgt_sequence]).to(device)\n",
        "        src_masks = torch.IntTensor([sequence.attention_mask for sequence in src_sequence]).to(device)\n",
        "        tgt_masks = torch.IntTensor([sequence.attention_mask for sequence in tgt_sequence]).to(device)\n",
        "        # print(\"src masks\", src_masks)\n",
        "        # print(\"tgt masks\", tgt_masks)\n",
        "        output = encoder_decoder_transformer(src_tokens, tgt_tokens, src_masks, tgt_masks)\n",
        "        #print(output.shape)\n",
        "        # print(\"output\", output.shape)\n",
        "        output_transpose = output.transpose(-1, -2) # output needs to be N, C, other dimension for torch cross entropy\n",
        "        loss = loss_function(output_transpose, tgt_tokens.long())\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        losses.append(loss.item())\n",
        "        print(\"Step\", step)\n",
        "        step += 1\n",
        "    print(\"finished epoch\", i)\n",
        "    print(\"avg loss:\", sum(losses) / len(losses))\n",
        "    expected_output = sequenceDataset.tgt_tokenizer.decode(tgt_tokens[0].tolist())\n",
        "    print(\"expected output\", expected_output)\n",
        "    decoded_output = decode(output[0], sequenceDataset.tgt_tokenizer)\n",
        "    print(\"decoded output:\", decoded_output)\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCHMIluxq6Su",
        "outputId": "f17ba196-897e-4a33-9216-93c422444f02"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0\n",
            "Step 1\n",
            "Step 2\n",
            "Step 3\n",
            "Step 4\n",
            "Step 5\n",
            "Step 6\n",
            "finished epoch 0\n",
            "avg loss: 20.817846843174525\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [6543, 235, 12, 125, 7322, 114]\n",
            "decoded output: Du Junge , einer museum und\n",
            "\n",
            "\n",
            "Step 7\n",
            "Step 8\n",
            "Step 9\n",
            "Step 10\n",
            "Step 11\n",
            "Step 12\n",
            "Step 13\n",
            "finished epoch 1\n",
            "avg loss: 13.279285703386579\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [109, 235, 3426, 100, 294, 103]\n",
            "decoded output: Ein Junge Nähmaschine in roten ein\n",
            "\n",
            "\n",
            "Step 14\n",
            "Step 15\n",
            "Step 16\n",
            "Step 17\n",
            "Step 18\n",
            "Step 19\n",
            "Step 20\n",
            "finished epoch 2\n",
            "avg loss: 10.375390461512975\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [131, 268, 235, 125, 273, 111]\n",
            "decoded output: Eine Personen Junge einer das einem\n",
            "\n",
            "\n",
            "Step 21\n",
            "Step 22\n",
            "Step 23\n",
            "Step 24\n",
            "Step 25\n",
            "Step 26\n",
            "Step 27\n",
            "finished epoch 3\n",
            "avg loss: 8.602435861315046\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [109, 235, 100, 111, 294, 111]\n",
            "decoded output: Ein Junge in einem roten einem\n",
            "\n",
            "\n",
            "Step 28\n",
            "Step 29\n",
            "Step 30\n",
            "Step 31\n",
            "Step 32\n",
            "Step 33\n",
            "Step 34\n",
            "finished epoch 4\n",
            "avg loss: 7.758228097643171\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [160, 268, 100, 125, 100, 111]\n",
            "decoded output: Zwei Personen in einer in einem\n",
            "\n",
            "\n",
            "Step 35\n",
            "Step 36\n",
            "Step 37\n",
            "Step 38\n",
            "Step 39\n",
            "Step 40\n",
            "Step 41\n",
            "finished epoch 5\n",
            "avg loss: 7.0605756895882745\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [109, 124, 100, 103, 294, 111]\n",
            "decoded output: Ein Mann in ein roten einem\n",
            "\n",
            "\n",
            "Step 42\n",
            "Step 43\n",
            "Step 44\n",
            "Step 45\n",
            "Step 46\n",
            "Step 47\n",
            "Step 48\n",
            "finished epoch 6\n",
            "avg loss: 6.675057206835065\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [109, 124, 100, 119, 100, 111]\n",
            "decoded output: Ein Mann in mit in einem\n",
            "\n",
            "\n",
            "Step 49\n",
            "Step 50\n",
            "Step 51\n",
            "Step 52\n",
            "Step 53\n",
            "Step 54\n",
            "Step 55\n",
            "finished epoch 7\n",
            "avg loss: 6.3757893698556085\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [160, 124, 100, 111, 294, 111]\n",
            "decoded output: Zwei Mann in einem roten einem\n",
            "\n",
            "\n",
            "Step 56\n",
            "Step 57\n",
            "Step 58\n",
            "Step 59\n",
            "Step 60\n",
            "Step 61\n",
            "Step 62\n",
            "finished epoch 8\n",
            "avg loss: 6.132279600415911\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [160, 124, 100, 111, 125, 111]\n",
            "decoded output: Zwei Mann in einem einer einem\n",
            "\n",
            "\n",
            "Step 63\n",
            "Step 64\n",
            "Step 65\n",
            "Step 66\n",
            "Step 67\n",
            "Step 68\n",
            "Step 69\n",
            "finished epoch 9\n",
            "avg loss: 5.844506331852505\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [160, 124, 100, 111, 294, 111]\n",
            "decoded output: Zwei Mann in einem roten einem\n",
            "\n",
            "\n",
            "Step 70\n",
            "Step 71\n",
            "Step 72\n",
            "Step 73\n",
            "Step 74\n",
            "Step 75\n",
            "Step 76\n",
            "finished epoch 10\n",
            "avg loss: 5.670528548104422\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [437, 124, 100, 111, 276, 111]\n",
            "decoded output: Mehrere Mann in einem blauen einem\n",
            "\n",
            "\n",
            "Step 77\n",
            "Step 78\n",
            "Step 79\n",
            "Step 80\n",
            "Step 81\n",
            "Step 82\n",
            "Step 83\n",
            "finished epoch 11\n",
            "avg loss: 5.449709347316197\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [160, 124, 114, 111, 111, 111]\n",
            "decoded output: Zwei Mann und einem einem einem\n",
            "\n",
            "\n",
            "Step 84\n",
            "Step 85\n",
            "Step 86\n",
            "Step 87\n",
            "Step 88\n",
            "Step 89\n",
            "Step 90\n",
            "finished epoch 12\n",
            "avg loss: 5.207427229200091\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 124, 100, 125, 111, 111]\n",
            "decoded output: Der Mann in einer einem einem\n",
            "\n",
            "\n",
            "Step 91\n",
            "Step 92\n",
            "Step 93\n",
            "Step 94\n",
            "Step 95\n",
            "Step 96\n",
            "Step 97\n",
            "finished epoch 13\n",
            "avg loss: 5.040199347904751\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 268, 100, 189, 111, 12]\n",
            "decoded output: Der Personen in dem einem ,\n",
            "\n",
            "\n",
            "Step 98\n",
            "Step 99\n",
            "Step 100\n",
            "Step 101\n",
            "Step 102\n",
            "Step 103\n",
            "Step 104\n",
            "finished epoch 14\n",
            "avg loss: 4.42555570602417\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 124, 119, 189, 1089, 230]\n",
            "decoded output: Der Mann mit dem Rucksack sitzt\n",
            "\n",
            "\n",
            "Step 105\n",
            "Step 106\n",
            "Step 107\n",
            "Step 108\n",
            "Step 109\n",
            "Step 110\n",
            "Step 111\n",
            "finished epoch 15\n",
            "avg loss: 4.9822815486363\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 124, 119, 561, 121, 230]\n",
            "decoded output: Der Mann mit rennt der sitzt\n",
            "\n",
            "\n",
            "Step 112\n",
            "Step 113\n",
            "Step 114\n",
            "Step 115\n",
            "Step 116\n",
            "Step 117\n",
            "Step 118\n",
            "finished epoch 16\n",
            "avg loss: 4.012189524514334\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 124, 119, 189, 1089, 230]\n",
            "decoded output: Der Mann mit dem Rucksack sitzt\n",
            "\n",
            "\n",
            "Step 119\n",
            "Step 120\n",
            "Step 121\n",
            "Step 122\n",
            "Step 123\n",
            "Step 124\n",
            "Step 125\n",
            "finished epoch 17\n",
            "avg loss: 3.389662742614746\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [436, 124, 119, 450, 1089, 230]\n",
            "decoded output: Der Mann mit sehen Rucksack sitzt\n",
            "\n",
            "\n",
            "Step 126\n",
            "Step 127\n",
            "Step 128\n",
            "Step 129\n",
            "Step 130\n",
            "Step 131\n",
            "Step 132\n",
            "finished epoch 18\n",
            "avg loss: 3.0708303451538086\n",
            "expected output Der Mann mit dem Rucksack sitzt\n",
            "argmax x: [8951, 124, 119, 3380, 1089, 230]\n",
            "decoded output: Dorfbewohner Mann mit Körper Rucksack sitzt\n",
            "\n",
            "\n",
            "Step 133\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-06800dc40c50>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_transpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJKGE-a_ry_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}