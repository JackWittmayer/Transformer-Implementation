{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9RH0iC1K7AuuArPSRjCBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackWittmayer/Transformer-Implementation/blob/main/EDTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37L0J9nog5yz",
        "outputId": "59ebdd56-e18b-47a7-a84f-3a630974c850"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VNf0Rr3ogy-4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "import pickle\n",
        "from unicodedata import normalize\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(25)\n",
        "random.seed(25)"
      ],
      "metadata": {
        "id": "2Hs0kEZYlwc6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_X = torch.tensor([3, 2, 0, 1], dtype=torch.int32)\n",
        "SAMPLE_Z = torch.tensor([4, 1, 7, 6], dtype=torch.int32)"
      ],
      "metadata": {
        "id": "bMXiZFPpEtZa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        embeddings = self.table(sequence)\n",
        "        return embeddings.transpose(0, 1)"
      ],
      "metadata": {
        "id": "Pk7xtwam89Hh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_embedding():\n",
        "    torch.manual_seed(25)\n",
        "    vocab_size = 4\n",
        "    embedding = Embedding(vocab_size, 4)\n",
        "    print(\"weight:\", embedding.table.weight)\n",
        "    print(\"SAMPLE_X: \", SAMPLE_X)\n",
        "    output = embedding(SAMPLE_X)\n",
        "    print(\"output:\", output)\n",
        "    for i in range(vocab_size):\n",
        "        assert output[:, i].eq(embedding.table.weight[SAMPLE_X[i]]).all()\n",
        "test_embedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StJF4qlIBYVj",
        "outputId": "e527b96b-f5ed-43ef-a58b-9c70b6645ea8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[ 0.0877, -0.6113,  0.3441, -1.2916],\n",
            "        [-0.5874,  0.8060,  1.3200,  0.4826],\n",
            "        [ 1.6671, -0.2342,  0.1074,  1.7852],\n",
            "        [ 0.7874, -0.2466,  0.2384, -0.6746]], requires_grad=True)\n",
            "SAMPLE_X:  tensor([3, 2, 0, 1], dtype=torch.int32)\n",
            "output: tensor([[ 0.7874,  1.6671,  0.0877, -0.5874],\n",
            "        [-0.2466, -0.2342, -0.6113,  0.8060],\n",
            "        [ 0.2384,  0.1074,  0.3441,  1.3200],\n",
            "        [-0.6746,  1.7852, -1.2916,  0.4826]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(10, 4)\n",
        "print(embedding.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dgUo-R3JBee",
        "outputId": "b983fb7a-9dd2-44cf-9f7c-f82cac262c07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.9314,  0.5380,  1.8837,  1.2911],\n",
            "        [-0.1041, -0.6025, -0.7860,  0.4670],\n",
            "        [ 0.3695,  1.0820, -1.9087,  1.6108],\n",
            "        [ 0.0211, -0.6054,  2.2265, -1.7176],\n",
            "        [ 0.1845, -0.1699,  0.4921, -0.7925],\n",
            "        [ 1.6591, -0.0074, -0.3345, -0.1528],\n",
            "        [-1.5218,  0.1531,  0.0445, -1.4806],\n",
            "        [ 0.1826, -0.1623, -0.8701, -0.2885],\n",
            "        [ 0.8274, -1.7458, -1.9661, -1.1676],\n",
            "        [ 0.4603,  0.7549, -0.7166, -0.1605]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Unembedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(vocab_size, embedding_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.matmul(self.weight, x)"
      ],
      "metadata": {
        "id": "EpoJIpc_CaX6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unembedding():\n",
        "    torch.manual_seed(25)\n",
        "    vocab_size = 10\n",
        "    embedding_size = 4\n",
        "    sequence_length = 4\n",
        "    input = torch.rand(embedding_size, sequence_length)\n",
        "    unembedding = Unembedding(vocab_size, embedding_size)\n",
        "\n",
        "    print(\"weight:\", unembedding.weight)\n",
        "    print(\"input: \", input)\n",
        "    output = unembedding(input)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (vocab_size, sequence_length)\n",
        "test_unembedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLZ0-F4xNOMf",
        "outputId": "f53e977f-6145-4e72-cac0-e96a9bad81a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.3947, 0.5181, 0.9726, 0.8813],\n",
            "        [0.0056, 0.3056, 0.9384, 0.7949],\n",
            "        [0.4399, 0.1766, 0.8739, 0.1425],\n",
            "        [0.4682, 0.6254, 0.3040, 0.7923],\n",
            "        [0.4691, 0.6875, 0.9917, 0.2772],\n",
            "        [0.7970, 0.2249, 0.1119, 0.6863],\n",
            "        [0.2238, 0.2678, 0.2246, 0.4711],\n",
            "        [0.0603, 0.2517, 0.3705, 0.7340],\n",
            "        [0.6466, 0.5172, 0.1176, 0.7000],\n",
            "        [0.8191, 0.0488, 0.3021, 0.2490]], requires_grad=True)\n",
            "input:  tensor([[0.7518, 0.1929, 0.0629, 0.9118],\n",
            "        [0.3828, 0.2990, 0.5933, 0.2911],\n",
            "        [0.2416, 0.5582, 0.0481, 0.3497],\n",
            "        [0.3520, 0.9528, 0.0284, 0.8488]])\n",
            "output: tensor([[1.0403, 1.6136, 0.4041, 1.5988],\n",
            "        [0.6278, 1.3736, 0.2495, 1.0969],\n",
            "        [0.6596, 0.7612, 0.1785, 0.8790],\n",
            "        [0.9437, 1.2018, 0.4376, 1.3877],\n",
            "        [0.9530, 1.1137, 0.4930, 1.2099],\n",
            "        [0.9539, 0.9373, 0.2084, 1.4138],\n",
            "        [0.4908, 0.6975, 0.1971, 0.7604],\n",
            "        [0.4896, 0.9930, 0.1918, 0.8808],\n",
            "        [0.9589, 1.0119, 0.3731, 1.3754],\n",
            "        [0.7951, 0.5784, 0.1021, 1.0780]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_size, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(max_sequence_length, embedding_size)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        positional_embeddings = self.table(torch.arange(0, sequence.shape[-1]))\n",
        "        return positional_embeddings.transpose(0, 1)"
      ],
      "metadata": {
        "id": "5xpYM9Zf_KLw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_positional_embedding():\n",
        "    embedding_size = 8\n",
        "    max_sequence_length = 10\n",
        "    positional_embedding = PositionalEmbedding(embedding_size, max_sequence_length)\n",
        "    output = positional_embedding(SAMPLE_X)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (embedding_size, SAMPLE_X.shape[0])\n",
        "test_positional_embedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l1Z_ZH8Pb_P",
        "outputId": "5c1f6d73-4290-4f63-dc79-d52d1dcfab02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tensor([[-1.5218,  0.8274, -0.0079, -0.6024],\n",
            "        [ 0.1531, -1.7458, -0.6091, -1.1570],\n",
            "        [ 0.0445, -1.9661,  1.5286,  0.9000],\n",
            "        [-1.4806, -1.1676,  1.9735,  0.5598],\n",
            "        [ 0.1826,  0.4603,  0.1646,  0.2992],\n",
            "        [-0.1623,  0.7549,  0.5387, -2.0385],\n",
            "        [-0.8701, -0.7166,  0.5112,  1.9378],\n",
            "        [-0.2885, -0.1605,  0.8526, -0.1953]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(queries, keys, values, mask):\n",
        "    keys_transposed = torch.transpose(keys, -2, -1)\n",
        "    #print(\"keys_transposed:\", keys_transposed)\n",
        "    scores = torch.matmul(keys_transposed, queries)\n",
        "    #print(\"scores:\", scores)\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    #print(\"masked scores:\", scores)\n",
        "    d_attn = keys.shape[-1]\n",
        "    scaled_scores = scores / math.sqrt(d_attn)\n",
        "    #print(\"scaled_scores:\", scaled_scores)\n",
        "    softmax_scores = torch.softmax(scaled_scores, -1)\n",
        "    #print(\"softmax_scores:\", softmax_scores)\n",
        "    return torch.matmul(values, softmax_scores)"
      ],
      "metadata": {
        "id": "DL3t3E_ThGF2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_attention():\n",
        "    d_attn = 4\n",
        "    length_x = 4\n",
        "    length_z = 3\n",
        "\n",
        "    queries = torch.rand(d_attn, length_x)\n",
        "    keys = torch.rand(d_attn, length_z)\n",
        "    values = torch.rand(d_attn, length_z)\n",
        "    print(\"queries:\", queries)\n",
        "    print(\"keys:\", keys)\n",
        "    print(\"values:\", values)\n",
        "    mask = mask = torch.tril(torch.ones(length_z, length_x) == 1)\n",
        "\n",
        "\n",
        "    v_out = attention(queries, keys, values, mask)\n",
        "    print(\"output:\", v_out)\n",
        "    assert v_out.shape == (d_attn, length_x)\n",
        "test_attention()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhGXLYp6i61z",
        "outputId": "e2179798-bdc8-4781-f68a-217951b91561"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries: tensor([[0.2312, 0.5850, 0.4959, 0.0404],\n",
            "        [0.0333, 0.5615, 0.8019, 0.2183],\n",
            "        [0.2667, 0.8491, 0.8948, 0.0137],\n",
            "        [0.2536, 0.1351, 0.4520, 0.1235]])\n",
            "keys: tensor([[0.2746, 0.1760, 0.3505],\n",
            "        [0.9246, 0.8537, 0.5464],\n",
            "        [0.9339, 0.0768, 0.0565],\n",
            "        [0.3594, 0.4961, 0.6278]])\n",
            "values: tensor([[0.3572, 0.5220, 0.1997],\n",
            "        [0.5286, 0.4723, 0.0238],\n",
            "        [0.1838, 0.2010, 0.1765],\n",
            "        [0.8587, 0.7776, 0.1199]])\n",
            "output: tensor([[0.6346, 0.3650, 0.0793, 0.0000],\n",
            "        [0.7374, 0.2779, 0.0095, 0.0000],\n",
            "        [0.3175, 0.1738, 0.0701, 0.0000],\n",
            "        [1.2242, 0.4844, 0.0476, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "class MaskStrategy(Enum):\n",
        "    UNMASKED = 1\n",
        "    MASKED = 2"
      ],
      "metadata": {
        "id": "wUJ-CbaCB9g-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, maskStrategy):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.weight_query = nn.Parameter(torch.rand(num_heads, d_attn, d_x))\n",
        "        #print(\"weight query:\", self.weight_query)\n",
        "        self.weight_key = nn.Parameter(torch.rand(num_heads, d_attn, d_z))\n",
        "        self.weight_value = nn.Parameter(torch.rand(num_heads, d_mid, d_z))\n",
        "        self.weight_out = nn.Parameter(torch.rand(d_out, d_mid * num_heads))\n",
        "        self.maskStrategy = maskStrategy\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        queries = torch.matmul(self.weight_query, x)\n",
        "        keys = torch.matmul(self.weight_key, z)\n",
        "        values = torch.matmul(self.weight_value, z)\n",
        "        #print(\"queries:\", queries)\n",
        "        #print(\"keys:\", keys)\n",
        "        #print(\"values:\", values)\n",
        "\n",
        "        # queries_with_heads = queries.reshape(self.num_heads, -1, x.shape[-1])\n",
        "        # keys_with_heads = keys.reshape(self.num_heads, -1, z.shape[-1])\n",
        "        # values_with_heads = values.reshape(self.num_heads, -1, z.shape[-1])\n",
        "\n",
        "        # print(\"queries_with_heads\", queries_with_heads)\n",
        "        # print(\"keys_with_heads\", keys_with_heads)\n",
        "        # print(\"values_with_heads\", values_with_heads)\n",
        "\n",
        "        length_x = x.shape[-1]\n",
        "        length_z = z.shape[-1]\n",
        "        if self.maskStrategy == MaskStrategy['UNMASKED']:\n",
        "            mask = torch.ones(length_z, length_x)\n",
        "        elif self.maskStrategy == MaskStrategy['MASKED']:\n",
        "            mask = torch.tril(torch.ones(length_z, length_x) == 1)\n",
        "        v_out = attention(queries, keys, values, mask)\n",
        "        #print(\"v_out:\", v_out)\n",
        "        v_out = v_out.reshape(-1, v_out.shape[-1])\n",
        "        #print(\"v_out reshaped:\", v_out)\n",
        "        return torch.matmul(self.weight_out, v_out)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CX2A1i9Z4lVO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multi_headed_attention():\n",
        "    num_heads = 2\n",
        "    d_attn = 4\n",
        "    d_x = 4\n",
        "    d_z = 4\n",
        "    d_out = 4\n",
        "    d_mid = 2\n",
        "    length_x = 4\n",
        "    length_z = 3\n",
        "\n",
        "    multi_headed_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['MASKED'])\n",
        "    x = torch.rand(d_x, length_x)\n",
        "    z = torch.rand(d_z, length_z)\n",
        "    output = multi_headed_attention(x, z)\n",
        "    print(\"output:\", output)\n",
        "    assert output.shape == (d_out, length_x)\n",
        "test_multi_headed_attention()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJuRy-3dTMY6",
        "outputId": "e916d952-4e69-472b-a030-f59f98661db8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tensor([[ 2.2665,  0.2006,  0.1284,  0.0000],\n",
            "        [ 7.0058,  0.6321,  0.3442,  0.0000],\n",
            "        [ 8.1959,  0.7536,  0.4499,  0.0000],\n",
            "        [11.8376,  1.0757,  0.6037,  0.0000]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, feature_length):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.rand(feature_length, 1))\n",
        "        self.offset = nn.Parameter(torch.rand(feature_length, 1))\n",
        "\n",
        "    def forward(self, activations):\n",
        "        mean = torch.mean(activations, -2, keepdim=True)\n",
        "        #print(\"mean:\", mean)\n",
        "        #print(\"activations - mean\", activations - mean)\n",
        "        variance = torch.std(activations, -2, keepdim=True)\n",
        "        return (((activations - mean) / variance) * self.scale) + self.offset"
      ],
      "metadata": {
        "id": "-Si4-i6PTlFu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_layer_norm():\n",
        "    feature_length = 4\n",
        "    length_x = 3\n",
        "    layer_norm = LayerNorm(feature_length)\n",
        "\n",
        "    activations = torch.rand(feature_length, length_x)\n",
        "\n",
        "    print(\"activations:\", activations)\n",
        "    print(\"layer_normed:\", layer_norm(activations))\n",
        "    assert layer_norm(activations).shape == activations.shape\n",
        "\n",
        "test_layer_norm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyzgWHqrWXL4",
        "outputId": "6a6a2074-4546-4b59-e57e-05e5076ca704"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations: tensor([[7.1962e-01, 3.8297e-01, 9.1271e-01],\n",
            "        [6.3607e-01, 7.0707e-01, 1.4284e-01],\n",
            "        [8.6427e-06, 7.6875e-01, 2.2828e-01],\n",
            "        [7.0166e-01, 9.2101e-01, 5.2097e-01]])\n",
            "layer_normed: tensor([[ 0.3874, -0.3564,  0.6635],\n",
            "        [ 0.5135,  0.4567,  0.2782],\n",
            "        [ 0.0149,  0.0349,  0.0243],\n",
            "        [ 0.7457,  0.9744,  0.5732]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, hiddenLayerWidth, d_e):\n",
        "        super().__init__()\n",
        "        self.mlp1 = nn.Parameter(torch.rand(hiddenLayerWidth, d_e))\n",
        "        self.mlp2 = nn.Parameter(torch.rand(d_e, hiddenLayerWidth))\n",
        "\n",
        "    def forward(self, activations):\n",
        "        activations = torch.matmul(self.mlp1, activations)\n",
        "        activations = activations.relu()\n",
        "        activations = torch.matmul(self.mlp2, activations)\n",
        "        return activations\n"
      ],
      "metadata": {
        "id": "X7rAEAkFoNI5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_feed_forward():\n",
        "    hiddenLayerWidth = 4\n",
        "    d_e = 4\n",
        "    feed_forward = FeedForward(hiddenLayerWidth, d_e)"
      ],
      "metadata": {
        "id": "mLQj6GjmUFN1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward = FeedForward(8, 4)\n",
        "activations = torch.rand(4, 4)\n",
        "\n",
        "print(\"activations:\", activations)\n",
        "print(\"feed forward:\", feed_forward(activations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVXTr2MKqBXo",
        "outputId": "16832644-fba6-4fb2-8a54-83ce0303cb42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations: tensor([[0.2384, 0.5974, 0.8991, 0.1890],\n",
            "        [0.1692, 0.6369, 0.6885, 0.4129],\n",
            "        [0.5404, 0.5601, 0.5734, 0.0695],\n",
            "        [0.9766, 0.5577, 0.6605, 0.9500]])\n",
            "feed forward: tensor([[3.4618, 4.0866, 4.9860, 2.7549],\n",
            "        [4.1394, 4.7213, 5.7609, 3.2795],\n",
            "        [4.7369, 5.3860, 6.5191, 3.8934],\n",
            "        [4.3997, 4.8025, 5.7954, 3.5539]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp):\n",
        "        super().__init__()\n",
        "        self.multi_head_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'])\n",
        "        self.layer_norm1 = LayerNorm(d_z)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_z)\n",
        "        self.layer_norm2 = LayerNorm(d_z)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z + self.multi_head_attention(z, z)\n",
        "        z = self.layer_norm1(z)\n",
        "        z = z + self.feed_forward(z)\n",
        "        z = self.layer_norm2(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "ikM15oD-qghT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            encoder_layer = EncoderLayer(num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp)\n",
        "            self.layers.append(encoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, z):\n",
        "        for layer in self.layers:\n",
        "            z = layer(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "zKGc6Xwr46Vh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp):\n",
        "        super().__init__()\n",
        "        self.multi_head_self_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['MASKED'])\n",
        "        self.layer_norm1 = LayerNorm(d_x)\n",
        "        self.multi_head_global_attention = MultiHeadedAttention(num_heads, d_attn, d_x, d_z, d_out, d_mid, MaskStrategy['UNMASKED'])\n",
        "        self.layer_norm2 = LayerNorm(d_x)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_x)\n",
        "        self.layer_norm3 = LayerNorm(d_x)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        x = x + self.multi_head_self_attention(x, x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = x + self.multi_head_global_attention(x, z)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = x + self.feed_forward(x)\n",
        "        x = self.layer_norm3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GSqElGm56xaK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            decoder_layer = DecoderLayer(num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp)\n",
        "            self.layers.append(decoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, z)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LGX007WN8Bw6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, d_e, vocab_size, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(vocab_size, d_e)\n",
        "        self.positionalEmbedding = PositionalEmbedding(d_e, max_sequence_length)\n",
        "        self.encoder = Encoder(num_encoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp)\n",
        "        self.decoder = Decoder(num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp)\n",
        "        self.unembedding = Unembedding(vocab_size, d_e)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        z = self.embedding(z) + self.positionalEmbedding(z)\n",
        "        z = self.encoder(z)\n",
        "        x = self.embedding(x)\n",
        "        x = self.decoder(x, z)\n",
        "        #print(\"x after decoder:\", x.shape)\n",
        "        x = self.unembedding(x)\n",
        "        #print(\"x after unembedding:\", x.shape)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ixXJDrPF8RU9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enRawName = \"drive/MyDrive/colab data/multi30kEnTrain.txt\"\n",
        "deRawName = \"drive/MyDrive/colab data/multi30kDeTrain.txt\"\n",
        "en30kVal = \"drive/MyDrive/colab data/multi30kEnVal.txt\"\n",
        "de30kVal = \"drive/MyDrive/colab data/multi30kDeVal.txt\"\n",
        "englishCleanName = \"data/english_tokens.pkl\"\n",
        "germanCleanName = \"data/german_tokens.pkl\"\n",
        "englishSortedName = \"data/englishSorted.pkl\"\n",
        "germanSortedName = \"data/germanSorted.pkl\"\n",
        "\n",
        "truncEn = \"drive/MyDrive/colab data/truncEn.pkl\"\n",
        "truncDe = \"drive/MyDrive/colab data/truncDe.pkl\"\n",
        "\n",
        "enTokenizerName = \"drive/MyDrive/colab data/enTokenizer.pkl\"\n",
        "deTokenizerName = \"drive/MyDrive/colab data/deTokenizer.pkl\"\n",
        "pairsName = \"drive/MyDrive/colab data/pairs.pkl\"\n",
        "folder = \"drive/MyDrive/colab data/\"\n",
        "\n",
        "enTrainingFileName = folder + \"enTraining\"\n",
        "deTrainingFileName = folder + \"deTraining\"\n",
        "enTestFileName = folder + \"enTest\"\n",
        "deTestFileName = folder + \"deTest\"\n",
        "enValFileName = folder + \"enValidation\"\n",
        "deValFileName = folder + \"deValidation\"\n",
        "\n",
        "enCombinedFileName = folder + \"enCombined\"\n",
        "deCombinedFileName = folder + \"deCombined\""
      ],
      "metadata": {
        "id": "NqAcQrmPg4y0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc6Y11QfhEAv",
        "outputId": "f1f210f7-1357-428d-960f-5bd104fe2f9e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "\n",
        "    TOKENIZER_SUFFIX = \"_tokenizer\"\n",
        "    BOS_TOKEN = \"[SOS]\"\n",
        "    EOS_TOKEN = \"[EOS]\"\n",
        "    PAD_TOKEN = \"[PAD]\"\n",
        "    UNK_TOKEN = \"[UNK]\"\n",
        "\n",
        "    def __init__(self, src_filename, tgt_filename, src_vocab_size, tgt_vocab_size):\n",
        "        src_sentences = self.to_sentences(self.load_doc(src_filename))\n",
        "        tgt_sentences = self.to_sentences(self.load_doc(tgt_filename))\n",
        "        src_sentences = [self.addSpecialTokens(sentence) for sentence in src_sentences]\n",
        "        tgt_sentences = [self.addSpecialTokens(sentence) for sentence in tgt_sentences]\n",
        "        self.src_tokenizer, self.tgt_tokenizer = self.setup_tokenizers(src_filename, tgt_filename, src_vocab_size, tgt_vocab_size, src_filename + SentenceDataset.TOKENIZER_SUFFIX, tgt_filename + SentenceDataset.TOKENIZER_SUFFIX)\n",
        "        src_tokenized = self.src_tokenizer.encode_batch(src_sentences)\n",
        "        tgt_tokenized = self.tgt_tokenizer.encode_batch(tgt_sentences)\n",
        "        src_tensors = [torch.IntTensor(sequence.ids) for sequence in src_tokenized]\n",
        "        tgt_tensor = [torch.IntTensor(sequence.ids) for sequence in tgt_tokenized]\n",
        "        self.pairs = self.pair_sequences(src_tensors, tgt_tensor)\n",
        "\n",
        "    # load doc into memory\n",
        "    def load_doc(self, filename):\n",
        "        # open the file as read only\n",
        "        file = open(filename, mode='rt')\n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        # close the file\n",
        "        file.close()\n",
        "        return text\n",
        "\n",
        "    def addSpecialTokens(self, sequence):\n",
        "        sequence = SentenceDataset.BOS_TOKEN + sequence + SentenceDataset.EOS_TOKEN\n",
        "        return sequence\n",
        "\n",
        "    def pair_sequences(self, src_sequences, tgt_sequences):\n",
        "        pairs = []\n",
        "        for i in range(len(src_sequences)):\n",
        "            pairs.append((src_sequences[i], tgt_sequences[i]))\n",
        "        return pairs\n",
        "\n",
        "    # split a loaded document into sentences\n",
        "    def to_sentences(self, doc):\n",
        "        return doc.strip().split('\\n')\n",
        "\n",
        "    def setup_tokenizers(self, src_filename, tgt_filename, src_vocab_size, tgt_vocab_size, src_tokenizer_name, tgt_tokenizer_name):\n",
        "        print(\"creating tokenizer for \" + src_filename)\n",
        "        src_tokenizer = Tokenizer(BPE(unk_token=SentenceDataset.UNK_TOKEN))\n",
        "        src_tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(vocab_size = src_vocab_size, special_tokens=[SentenceDataset.BOS_TOKEN, SentenceDataset.EOS_TOKEN, SentenceDataset.PAD_TOKEN, SentenceDataset.UNK_TOKEN])\n",
        "        src_tokenizer.train([src_filename], trainer=trainer)\n",
        "        pickle.dump(src_tokenizer, open(src_tokenizer_name, \"wb\"))\n",
        "\n",
        "        print(\"creating tokenizer for \" + tgt_filename)\n",
        "        tgt_tokenizer = Tokenizer(BPE(unk_token=SentenceDataset.UNK_TOKEN))\n",
        "        tgt_tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(vocab_size = tgt_vocab_size, special_tokens=[SentenceDataset.BOS_TOKEN, SentenceDataset.EOS_TOKEN, SentenceDataset.PAD_TOKEN, SentenceDataset.UNK_TOKEN])\n",
        "        tgt_tokenizer.train([tgt_filename], trainer=trainer)\n",
        "        pickle.dump(tgt_tokenizer, open(tgt_tokenizer_name, \"wb\"))\n",
        "        return src_tokenizer, tgt_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.pairs[index]"
      ],
      "metadata": {
        "id": "PkCWRs4-khoT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequenceDataset = SentenceDataset(enRawName, deRawName, 2000, 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82dEUnd5lx9M",
        "outputId": "e1ee060c-16a5-46ac-b772-72b656cef971"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating tokenizer for drive/MyDrive/colab data/multi30kEnTrain.txt\n",
            "creating tokenizer for drive/MyDrive/colab data/multi30kDeTrain.txt\n",
            "[0, 138, 171, 13, 1808, 132, 1793, 120, 280, 338, 938, 210, 1221, 15, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequenceDataset.__getitem__(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ZTre_Uo18S",
        "outputId": "1875a9a5-894c-4a03-99f4-99bf3f7bc7d2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([   0,  138,  171,   13, 1808,  132, 1793,  120,  280,  338,  938,  210,\n",
            "        1221,   15,    1], dtype=torch.int32), tensor([   0,  160,  351,  649,  217,  444,  148,  457,  100,  121,  513,  788,\n",
            "         102, 1207,  500,   14,    1], dtype=torch.int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair = sequenceDataset.__getitem__(0)\n",
        "sequence_z = pair[0]\n",
        "sequence_x = pair[1]\n",
        "\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "num_heads = 8\n",
        "d_attn = 64\n",
        "d_x = 512\n",
        "d_z = 512\n",
        "d_out = 512\n",
        "d_mid = 512\n",
        "d_mlp = 2048\n",
        "d_e = 512\n",
        "vocab_size = 2000\n",
        "max_sequence_length = 100\n",
        "\n",
        "encoder_decoder_transformer = EncoderDecoderTransformer(num_encoder_layers, num_decoder_layers, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, d_e, vocab_size, max_sequence_length)\n",
        "output = encoder_decoder_transformer(sequence_x, sequence_z)\n",
        "print(\"output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFPxq_hkffx3",
        "outputId": "7c79466a-cd6a-496f-f64b-862cefe40781"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tensor([[128.7010, 128.8575, 128.8577,  ..., 128.8579, 128.8577, 128.8581],\n",
            "        [113.6734, 113.9075, 113.9076,  ..., 113.9080, 113.9079, 113.9081],\n",
            "        [125.9031, 125.8873, 125.8874,  ..., 125.8878, 125.8876, 125.8878],\n",
            "        ...,\n",
            "        [122.2063, 122.4274, 122.4275,  ..., 122.4280, 122.4278, 122.4279],\n",
            "        [119.7615, 119.6788, 119.6788,  ..., 119.6792, 119.6791, 119.6793],\n",
            "        [115.0268, 115.0118, 115.0118,  ..., 115.0123, 115.0121, 115.0123]],\n",
            "       grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "x = output.transpose(0, 1)\n",
        "print(\"x:\", x)\n",
        "x = torch.softmax(x, -1)\n",
        "print(\"x softmax:\", x)\n",
        "x = torch.argmax(x, dim=-1)\n",
        "print(\"argmax x:\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YXMnq-_Xkff",
        "outputId": "425ebeed-32d0-481c-baa1-de3d52a998ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 15])\n",
            "x: tensor([[112.4095, 115.1396, 116.1140,  ..., 124.1159, 117.6144, 113.8082],\n",
            "        [112.4091, 115.1391, 116.1135,  ..., 124.1155, 117.6139, 113.8076],\n",
            "        [112.4036, 115.1666, 116.1268,  ..., 124.1245, 117.6131, 113.8099],\n",
            "        ...,\n",
            "        [112.4395, 115.1805, 116.1912,  ..., 124.2022, 117.6688, 113.8203],\n",
            "        [112.4084, 115.1385, 116.1132,  ..., 124.1148, 117.6133, 113.8070],\n",
            "        [112.4445, 115.3520, 115.8624,  ..., 123.8243, 117.4075, 113.7522]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "x softmax: tensor([[9.4449e-11, 1.4483e-09, 3.8374e-09,  ..., 1.1461e-05, 1.7205e-08,\n",
            "         3.8249e-10],\n",
            "        [9.4457e-11, 1.4483e-09, 3.8376e-09,  ..., 1.1462e-05, 1.7205e-08,\n",
            "         3.8247e-10],\n",
            "        [9.3355e-11, 1.4794e-09, 3.8644e-09,  ..., 1.1494e-05, 1.7084e-08,\n",
            "         3.8096e-10],\n",
            "        ...,\n",
            "        [9.2743e-11, 1.4376e-09, 3.9501e-09,  ..., 1.1905e-05, 1.7311e-08,\n",
            "         3.6891e-10],\n",
            "        [9.4434e-11, 1.4482e-09, 3.8379e-09,  ..., 1.1459e-05, 1.7202e-08,\n",
            "         3.8242e-10],\n",
            "        [9.5732e-11, 1.7531e-09, 2.9204e-09,  ..., 8.3807e-06, 1.3692e-08,\n",
            "         3.5401e-10]], grad_fn=<SoftmaxBackward0>)\n",
            "argmax x: tensor([969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969,\n",
            "        969])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(x, tokenizer):\n",
        "    #print(\"x:\", x)\n",
        "    x = x.transpose(0, 1)\n",
        "    x = torch.softmax(x, -1)\n",
        "    #print(\"x softmax:\", x)\n",
        "    x = torch.argmax(x, dim=-1)\n",
        "    x = x.tolist()\n",
        "    print(\"argmax x:\", x)\n",
        "    return tokenizer.decode(x)"
      ],
      "metadata": {
        "id": "ERDbLlQVzJUx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_output = decode(output, sequenceDataset.tgt_tokenizer)\n",
        "print(\"decoded output:\", decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jD-XL3DYb1K",
        "outputId": "90f3e762-5640-45f5-af38-d2391e7fafda"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "argmax x: [1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415]\n",
            "decoded output: bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoRd9BvTXe0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(encoder_decoder_transformer.parameters(), lr=0.05, betas=(0.9, 0.98), eps=1e-9)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "print(sequence_z)\n",
        "print(sequence_x)\n",
        "for i in range(1000):\n",
        "    # sequence_x, sequence_z = sequenceDataset.__getitem__(i)\n",
        "    output = encoder_decoder_transformer(sequence_x, sequence_z)\n",
        "    decoded_output = decode(output, sequenceDataset.tgt_tokenizer)\n",
        "    print(\"decoded output:\", decoded_output)\n",
        "    output = output.transpose(0, 1)\n",
        "    loss = loss_function(output, sequence_x.long())\n",
        "    print(\"loss:\", loss)\n",
        "    print()\n",
        "    print()\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCHMIluxq6Su",
        "outputId": "8f8a5fa8-06ff-49c8-e64d-810721f0b382"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0,  138,  171,   13, 1808,  132, 1793,  120,  280,  338,  938,  210,\n",
            "        1221,   15,    1], dtype=torch.int32)\n",
            "tensor([   0,  160,  351,  649,  217,  444,  148,  457,  100,  121,  513,  788,\n",
            "         102, 1207,  500,   14,    1], dtype=torch.int32)\n",
            "argmax x: [1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415, 1415]\n",
            "decoded output: bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens bens\n",
            "loss: tensor(18.6713, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: . . . . . . . . . . . . . . . . .\n",
            "loss: tensor(11.7611, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "decoded output: Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(10.4530, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788]\n",
            "decoded output: viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel\n",
            "loss: tensor(12.0245, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [102, 457, 102, 457, 457, 457, 457, 457, 102, 457, 457, 457, 457, 457, 457, 457, 457]\n",
            "decoded output: er Freien er Freien Freien Freien Freien Freien er Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(17.5070, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649]\n",
            "decoded output: weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße\n",
            "loss: tensor(25.1801, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
            "decoded output: der der der der der der der der der der der der der der der der der\n",
            "loss: tensor(33.6803, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207]\n",
            "decoded output: Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü\n",
            "loss: tensor(38.3603, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444]\n",
            "decoded output: sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind\n",
            "loss: tensor(38.1390, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(34.6141, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351]\n",
            "decoded output: junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge\n",
            "loss: tensor(33.8001, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: in in in in in in in in in in in in in in in in in\n",
            "loss: tensor(30.9651, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: in in in in in in in in in in in in in in in in in\n",
            "loss: tensor(21.4253, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457, 457]\n",
            "decoded output: Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(19.5261, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "decoded output: \n",
            "loss: tensor(17.9700, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "decoded output: im im im im im im im im im im im im im im im im im\n",
            "loss: tensor(17.3956, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788]\n",
            "decoded output: viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel viel\n",
            "loss: tensor(17.7571, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649]\n",
            "decoded output: weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße\n",
            "loss: tensor(17.0428, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei Zwei\n",
            "loss: tensor(16.0915, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
            "decoded output: der der der der der der der der der der der der der der der der der\n",
            "loss: tensor(14.3346, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [1, 1, 500, 1, 500, 500, 1, 500, 500, 500, 500, 500, 500, 500, 500, 1, 500]\n",
            "decoded output: sche sche sche sche sche sche sche sche sche sche sche sche\n",
            "loss: tensor(11.3521, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n",
            "decoded output: sche sche sche sche sche sche sche sche sche sche sche sche sche sche sche sche sche\n",
            "loss: tensor(11.0103, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "decoded output: Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(10.9996, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 217, 217, 217, 217, 0, 217, 217, 217, 217, 217, 217, 0, 217]\n",
            "decoded output: Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(9.0745, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: er er er er er er er er er er er er er er er er er\n",
            "loss: tensor(8.4515, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444]\n",
            "decoded output: sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind\n",
            "loss: tensor(8.2774, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444]\n",
            "decoded output: sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind sind\n",
            "loss: tensor(7.5445, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 351, 1207, 1207, 351, 351, 351, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207]\n",
            "decoded output: junge junge Bü Bü junge junge junge Bü Bü Bü Bü Bü Bü Bü Bü Bü Bü\n",
            "loss: tensor(7.4792, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351]\n",
            "decoded output: junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge junge\n",
            "loss: tensor(7.1170, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: . . . . . . . . . . . . . . . . .\n",
            "loss: tensor(6.7974, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: weiße weiße . . . . . . . . . . . . . . .\n",
            "loss: tensor(6.3026, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649]\n",
            "decoded output: weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße\n",
            "loss: tensor(5.7205, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 0, 788]\n",
            "decoded output: viel viel viel viel viel viel viel viel viel viel viel viel\n",
            "loss: tensor(5.4681, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 102, 102, 102, 102, 102, 0, 102, 102, 102, 102, 102, 0, 102]\n",
            "decoded output: er er er er er er er er er er er\n",
            "loss: tensor(5.0387, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 102, 102, 102, 102, 0, 0, 102, 102, 102, 102, 102, 0, 102]\n",
            "decoded output: er er er er er er er er er er\n",
            "loss: tensor(4.1688, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 513, 160, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: Zwei Nähe Zwei Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(3.3780, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 100, 100, 100, 100, 100, 160, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: Zwei Zwei Zwei Zwei in in in in in Zwei in in in in in in in\n",
            "loss: tensor(3.9772, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 100, 160, 100, 100, 100, 100, 100, 160, 100, 100, 100, 100, 100, 160, 100]\n",
            "decoded output: Zwei Zwei in Zwei in in in in in Zwei in in in in in Zwei in\n",
            "loss: tensor(4.2571, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 160, 500]\n",
            "decoded output: Zwei Zwei Zwei Zwei sche sche sche sche sche sche sche sche sche sche sche Zwei sche\n",
            "loss: tensor(3.9334, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 160, 500]\n",
            "decoded output: Zwei Zwei Zwei Zwei sche sche sche sche sche sche sche sche sche sche sche Zwei sche\n",
            "loss: tensor(3.4398, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "decoded output: Zwei Zwei Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(3.2718, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "decoded output: weiße weiße Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(3.3214, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 649, 217]\n",
            "decoded output: weiße weiße weiße weiße Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer Männer weiße Männer\n",
            "loss: tensor(3.1731, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 649, 1]\n",
            "decoded output: weiße weiße weiße weiße weiße\n",
            "loss: tensor(3.0324, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351, 1, 351, 1]\n",
            "decoded output: junge junge\n",
            "loss: tensor(3.0338, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 351, 0, 0, 457, 0, 0, 457, 457, 457, 457, 457, 0, 457, 457]\n",
            "decoded output: junge Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(3.8154, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [14, 14, 457, 457, 14, 14, 457, 14, 14, 457, 457, 457, 14, 457, 14, 457, 457]\n",
            "decoded output: . . Freien Freien . . Freien . . Freien Freien Freien . Freien . Freien Freien\n",
            "loss: tensor(3.9052, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [14, 14, 14, 14, 788, 14, 788, 788, 14, 788, 788, 788, 788, 788, 14, 788, 788]\n",
            "decoded output: . . . . viel . viel viel . viel viel viel viel viel . viel viel\n",
            "loss: tensor(3.3948, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 14, 160, 102, 160, 102, 14, 160, 102, 102, 102, 102, 102, 160, 102, 102]\n",
            "decoded output: Zwei Zwei . Zwei er Zwei er . Zwei er er er er er Zwei er er\n",
            "loss: tensor(3.1807, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 14, 160, 102, 160, 102, 160, 160, 102, 102, 102, 102, 102, 160, 102, 102]\n",
            "decoded output: Zwei Zwei . Zwei er Zwei er Zwei Zwei er er er er er Zwei er er\n",
            "loss: tensor(2.9305, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 160, 788, 160, 788, 160, 788, 788, 788, 788, 14, 788, 14, 788]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei viel Zwei viel Zwei viel viel viel viel . viel . viel\n",
            "loss: tensor(2.8011, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [457, 457, 457, 148, 148, 148, 100, 148, 100, 148, 148, 148, 148, 649, 148, 148, 148]\n",
            "decoded output: Freien Freien Freien im im im in im in im im im im weiße im im im\n",
            "loss: tensor(3.0974, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 100, 100, 444, 121, 121, 121, 444, 100, 121, 121, 121, 121, 100, 121, 121, 121]\n",
            "decoded output: in in in sind der der der sind in der der der der in der der der\n",
            "loss: tensor(2.7966, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: in in in in in in in in in in in in in in in in in\n",
            "loss: tensor(2.7068, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 100, 500, 100, 100, 0, 0, 100, 500, 100, 100, 500, 100, 500, 0, 500]\n",
            "decoded output: in sche in in in sche in in sche in sche sche\n",
            "loss: tensor(3.1753, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 100, 100, 217, 1, 1, 0, 1, 217, 217, 0, 1, 217, 1, 0, 1]\n",
            "decoded output: in in Männer Männer Männer Männer\n",
            "loss: tensor(3.0110, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 351, 0, 0, 1, 0, 217, 1, 1, 0, 1, 217, 1, 1, 1]\n",
            "decoded output: junge Männer Männer\n",
            "loss: tensor(2.7524, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 0, 0, 351, 1, 0, 217, 1, 1, 0, 1, 217, 1, 0, 1]\n",
            "decoded output: junge junge Männer Männer\n",
            "loss: tensor(2.8920, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 1, 351, 217, 351, 1, 1, 1, 1, 351, 1, 1, 1, 351, 1, 1]\n",
            "decoded output: Zwei junge Männer junge junge junge\n",
            "loss: tensor(2.7707, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 351, 217, 217, 160, 351, 121, 121, 121, 160, 121, 217, 217, 121, 121, 121]\n",
            "decoded output: Zwei Zwei junge Männer Männer Zwei junge der der der Zwei der Männer Männer der der der\n",
            "loss: tensor(2.7142, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 14, 351, 160, 14, 160, 351, 160, 14, 14, 160, 14, 14, 14, 160, 160]\n",
            "decoded output: Zwei Zwei . junge Zwei . Zwei junge Zwei . . Zwei . . . Zwei Zwei\n",
            "loss: tensor(3.0492, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 160, 14, 351, 14, 14, 14, 14, 14, 14, 14, 351, 14, 14]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei . junge . . . . . . . junge . .\n",
            "loss: tensor(2.7299, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 14, 457, 649, 14, 351, 14, 14, 14, 14, 649, 14, 14, 351, 457, 14]\n",
            "decoded output: Zwei Zwei . Freien weiße . junge . . . . weiße . . junge Freien .\n",
            "loss: tensor(2.9151, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 649, 351, 351, 649, 14, 351, 14, 14, 14, 14, 649, 14, 14, 14, 14, 14]\n",
            "decoded output: Zwei weiße junge junge weiße . junge . . . . weiße . . . . .\n",
            "loss: tensor(2.5940, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 351, 0, 649, 513, 351, 513, 513, 513, 513, 649, 513, 513, 513, 513, 513]\n",
            "decoded output: im junge weiße Nähe junge Nähe Nähe Nähe Nähe weiße Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(2.5538, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 0, 788, 513, 351, 0, 513, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: junge viel Nähe junge Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(2.4565, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 0, 788, 788, 351, 0, 788, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: junge viel viel junge viel Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(2.4221, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 788, 0, 0, 1, 351, 0, 1, 1, 788, 1, 1, 1, 1, 1, 1]\n",
            "decoded output: viel junge viel\n",
            "loss: tensor(2.4748, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 100, 160, 0, 1, 351, 0, 1, 1, 788, 1, 1, 1, 1, 160, 1]\n",
            "decoded output: in Zwei junge viel Zwei\n",
            "loss: tensor(2.5305, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 100, 160, 160, 1, 351, 0, 1, 1, 100, 1, 1, 1, 1, 100, 1]\n",
            "decoded output: Zwei in Zwei Zwei junge in in\n",
            "loss: tensor(2.4689, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 100, 160, 217, 1207, 351, 160, 1207, 1207, 100, 1207, 1207, 1207, 1207, 100, 1207]\n",
            "decoded output: Zwei in Zwei Männer Bü junge Zwei Bü Bü in Bü Bü Bü Bü in Bü\n",
            "loss: tensor(2.3887, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 100, 160, 217, 121, 351, 160, 121, 121, 217, 121, 121, 121, 121, 217, 121]\n",
            "decoded output: Zwei in Zwei Männer der junge Zwei der der Männer der der der der Männer der\n",
            "loss: tensor(2.4208, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 217, 1207, 217, 217, 121, 500, 217, 121, 121, 121, 121, 121, 121, 351, 121, 121]\n",
            "decoded output: weiße Männer Bü Männer Männer der sche Männer der der der der der der junge der der\n",
            "loss: tensor(2.5386, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 217, 444, 217, 217, 121, 500, 217, 121, 121, 121, 121, 121, 121, 351, 121, 121]\n",
            "decoded output: weiße Männer sind Männer Männer der sche Männer der der der der der der junge der der\n",
            "loss: tensor(2.5329, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 0, 444, 217, 217, 121, 500, 217, 121, 121, 121, 121, 121, 121, 351, 121, 121]\n",
            "decoded output: weiße sind Männer Männer der sche Männer der der der der der der junge der der\n",
            "loss: tensor(2.4464, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 0, 444, 160, 217, 121, 444, 217, 121, 121, 121, 121, 121, 121, 351, 121, 121]\n",
            "decoded output: weiße sind Zwei Männer der sind Männer der der der der der der junge der der\n",
            "loss: tensor(2.3675, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 351, 0, 160, 444, 148, 160, 444, 444, 444, 444, 444, 444, 351, 444, 444]\n",
            "decoded output: Zwei Zwei junge Zwei sind im Zwei sind sind sind sind sind sind junge sind sind\n",
            "loss: tensor(2.2007, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 0, 0, 513, 148, 0, 513, 513, 513, 513, 513, 444, 148, 513, 513]\n",
            "decoded output: Zwei junge Nähe im Nähe Nähe Nähe Nähe Nähe sind im Nähe Nähe\n",
            "loss: tensor(2.1611, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 0, 160, 788, 148, 160, 788, 788, 788, 788, 788, 788, 148, 788, 788]\n",
            "decoded output: junge Zwei viel im Zwei viel viel viel viel viel viel im viel viel\n",
            "loss: tensor(2.1022, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 457, 217, 788, 148, 217, 788, 788, 788, 788, 788, 788, 148, 788, 788]\n",
            "decoded output: junge Freien Männer viel im Männer viel viel viel viel viel viel im viel viel\n",
            "loss: tensor(2.0510, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 217, 217, 217, 788, 148, 217, 788, 788, 788, 788, 788, 788, 148, 148, 788]\n",
            "decoded output: Männer Männer Männer viel im Männer viel viel viel viel viel viel im im viel\n",
            "loss: tensor(2.0916, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 217, 217, 788, 148, 217, 788, 788, 788, 788, 788, 788, 788, 788, 788]\n",
            "decoded output: Zwei Männer Männer Männer viel im Männer viel viel viel viel viel viel viel viel viel\n",
            "loss: tensor(2.0842, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 457, 217, 102, 148, 217, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: Zwei Männer Freien Männer er im Männer er er er er er er er er er\n",
            "loss: tensor(2.0218, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 351, 0, 217, 102, 148, 217, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: junge Männer er im Männer er er er er er er er er er\n",
            "loss: tensor(2.0230, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 649, 102, 649, 102, 148, 649, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: weiße er weiße er im weiße er er er er er er er er er\n",
            "loss: tensor(2.4073, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 217, 444, 217, 444, 148, 217, 444, 121, 121, 121, 444, 444, 444, 121, 121]\n",
            "decoded output: Männer sind Männer sind im Männer sind der der der sind sind sind der der\n",
            "loss: tensor(2.2999, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 444, 217, 444, 444, 217, 444, 444, 444, 444, 444, 444, 148, 444, 444]\n",
            "decoded output: Zwei Männer sind Männer sind sind Männer sind sind sind sind sind sind im sind sind\n",
            "loss: tensor(2.3989, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 351, 500, 500, 351, 500, 500, 500, 500, 500, 500, 148, 500, 500]\n",
            "decoded output: Zwei junge sche junge sche sche junge sche sche sche sche sche sche im sche sche\n",
            "loss: tensor(2.3618, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 513, 217, 513, 513, 217, 513, 513, 513, 513, 513, 513, 148, 513, 513]\n",
            "decoded output: Zwei Männer Nähe Männer Nähe Nähe Männer Nähe Nähe Nähe Nähe Nähe Nähe im Nähe Nähe\n",
            "loss: tensor(2.2683, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 513, 217, 513, 148, 217, 513, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: Zwei Männer Nähe Männer Nähe im Männer Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(2.0131, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 457, 513, 457, 513, 148, 457, 513, 513, 513, 513, 513, 513, 513, 513, 513]\n",
            "decoded output: Zwei Zwei Freien Nähe Freien Nähe im Freien Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe\n",
            "loss: tensor(2.2327, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 457, 102, 457, 102, 148, 457, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: Zwei Zwei Freien er Freien er im Freien er er er er er er er er er\n",
            "loss: tensor(1.9790, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 457, 0, 649, 457, 649, 148, 0, 649, 649, 649, 649, 649, 649, 649, 649, 649]\n",
            "decoded output: Zwei Freien weiße Freien weiße im weiße weiße weiße weiße weiße weiße weiße weiße weiße\n",
            "loss: tensor(2.6988, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 217, 649, 217, 649, 148, 217, 649, 649, 649, 649, 649, 649, 649, 649, 649]\n",
            "decoded output: Zwei Männer weiße Männer weiße im Männer weiße weiße weiße weiße weiße weiße weiße weiße weiße\n",
            "loss: tensor(1.9322, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 351, 351, 14, 351, 14, 148, 351, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: Zwei junge junge . junge . im junge . . . . . . . . .\n",
            "loss: tensor(2.3739, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 351, 351, 14, 351, 14, 148, 351, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: Zwei junge junge . junge . im junge . . . . . . . . .\n",
            "loss: tensor(2.3266, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 351, 351, 1, 351, 1, 1, 351, 1, 1, 1, 1, 1, 1, 148, 1, 1]\n",
            "decoded output: junge junge junge junge im\n",
            "loss: tensor(2.3259, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 217, 217, 1, 217, 1, 1, 217, 1, 1, 1, 1, 1, 1, 148, 1, 1]\n",
            "decoded output: Männer Männer Männer Männer im\n",
            "loss: tensor(2.2288, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 457, 1, 457, 1, 1, 457, 1, 513, 513, 513, 1, 1, 148, 513, 1]\n",
            "decoded output: Freien Freien Freien Freien Nähe Nähe Nähe im Nähe\n",
            "loss: tensor(2.1603, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 457, 513, 457, 513, 513, 457, 513, 513, 513, 513, 513, 513, 148, 513, 513]\n",
            "decoded output: Freien Freien Nähe Freien Nähe Nähe Freien Nähe Nähe Nähe Nähe Nähe Nähe im Nähe Nähe\n",
            "loss: tensor(2.0813, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 444, 160, 513, 444, 160, 513, 513, 513, 513, 513, 513, 148, 513, 513]\n",
            "decoded output: Zwei Zwei sind Zwei Nähe sind Zwei Nähe Nähe Nähe Nähe Nähe Nähe im Nähe Nähe\n",
            "loss: tensor(2.0536, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 444, 160, 444, 160, 160, 444, 444, 444, 444, 444, 444, 500, 444, 444]\n",
            "decoded output: Zwei Zwei sind Zwei sind Zwei Zwei sind sind sind sind sind sind sche sind sind\n",
            "loss: tensor(2.2429, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 100, 160, 100, 160, 160, 100, 100, 100, 100, 100, 100, 500, 100, 100]\n",
            "decoded output: Zwei Zwei in Zwei in Zwei Zwei in in in in in in sche in in\n",
            "loss: tensor(2.1680, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 351, 351, 100, 351, 100, 351, 351, 100, 100, 100, 100, 100, 100, 500, 100, 100]\n",
            "decoded output: junge junge in junge in junge junge in in in in in in sche in in\n",
            "loss: tensor(2.0802, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 351, 351, 121, 351, 121, 351, 351, 121, 121, 121, 121, 121, 121, 500, 121, 121]\n",
            "decoded output: junge junge der junge der junge junge der der der der der der sche der der\n",
            "loss: tensor(2.0198, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 457, 1, 457, 1, 457, 457, 1, 1, 1, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Freien Freien Freien Freien Freien sche\n",
            "loss: tensor(1.9660, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 457, 1, 457, 1, 457, 457, 1, 1, 1, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Freien Freien Freien Freien Freien sche\n",
            "loss: tensor(1.9507, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 500, 148, 1, 148, 148, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "decoded output: im im sche im im im\n",
            "loss: tensor(2.4438, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 500, 148, 14, 148, 148, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: im im sche im . im im . . . . . . . . .\n",
            "loss: tensor(2.4212, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 500, 148, 14, 148, 148, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: im im sche im . im im . . . . . . . . .\n",
            "loss: tensor(2.3612, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 457, 500, 457, 14, 457, 457, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: Freien Freien sche Freien . Freien Freien . . . . . . . . .\n",
            "loss: tensor(2.2852, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 500, 160, 102, 160, 160, 102, 102, 513, 102, 102, 102, 513, 102, 102]\n",
            "decoded output: Zwei Zwei sche Zwei er Zwei Zwei er er Nähe er er er Nähe er er\n",
            "loss: tensor(2.2367, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 102, 160, 102, 160, 160, 102, 102, 102, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei Zwei er Zwei er Zwei Zwei er er er er er er sche er er\n",
            "loss: tensor(1.9369, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 351, 351, 121, 351, 121, 351, 351, 121, 121, 121, 121, 121, 121, 500, 121, 121]\n",
            "decoded output: junge junge der junge der junge junge der der der der der der sche der der\n",
            "loss: tensor(1.9252, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 351, 351, 121, 351, 121, 351, 351, 121, 121, 121, 121, 121, 121, 500, 121, 121]\n",
            "decoded output: junge junge der junge der junge junge der der der der der der sche der der\n",
            "loss: tensor(1.8944, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 100, 148, 100, 148, 148, 100, 100, 100, 100, 100, 100, 500, 100, 100]\n",
            "decoded output: im im in im in im im in in in in in in sche in in\n",
            "loss: tensor(1.8836, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 100, 148, 100, 148, 148, 100, 100, 100, 100, 100, 100, 500, 100, 100]\n",
            "decoded output: im im in im in im im in in in in in in sche in in\n",
            "loss: tensor(1.9040, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 0, 148, 100, 148, 148, 100, 100, 500, 100, 100, 1207, 0, 100, 100]\n",
            "decoded output: im im im in im im in in sche in in Bü in in\n",
            "loss: tensor(2.9657, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 148, 500, 148, 100, 148, 148, 100, 100, 0, 100, 100, 500, 100, 100, 100]\n",
            "decoded output: im im sche im in im im in in in in sche in in in\n",
            "loss: tensor(2.9259, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 457, 457, 500, 457, 102, 457, 457, 102, 102, 0, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: sche Freien Freien sche Freien er Freien Freien er er er er er sche er er\n",
            "loss: tensor(2.5189, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 457, 457, 649, 457, 500, 457, 457, 160, 102, 500, 102, 102, 160, 102, 102, 102]\n",
            "decoded output: Zwei Freien Freien weiße Freien sche Freien Freien Zwei er sche er er Zwei er er er\n",
            "loss: tensor(3.2563, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 457, 457, 121, 457, 121, 457, 457, 500, 121, 121, 121, 121, 121, 649, 121, 121]\n",
            "decoded output: Zwei Freien Freien der Freien der Freien Freien sche der der der der der weiße der der\n",
            "loss: tensor(2.7861, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 351, 649, 351, 121, 351, 351, 121, 121, 121, 121, 121, 649, 121, 121, 121]\n",
            "decoded output: Zwei Zwei junge weiße junge der junge junge der der der der der weiße der der der\n",
            "loss: tensor(2.6280, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 160, 160, 444, 160, 444, 160, 160, 444, 444, 444, 444, 444, 649, 444, 444, 444]\n",
            "decoded output: weiße Zwei Zwei sind Zwei sind Zwei Zwei sind sind sind sind sind weiße sind sind sind\n",
            "loss: tensor(2.8030, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 148, 649, 148, 148, 513, 148, 148, 513, 513, 513, 513, 513, 649, 513, 513, 513]\n",
            "decoded output: weiße im weiße im im Nähe im im Nähe Nähe Nähe Nähe Nähe weiße Nähe Nähe Nähe\n",
            "loss: tensor(2.8254, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 148, 649, 649, 148, 1207, 148, 148, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207]\n",
            "decoded output: weiße im weiße weiße im Bü im im Bü Bü Bü Bü Bü Bü Bü Bü Bü\n",
            "loss: tensor(2.6369, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 148, 649, 148, 148, 1207, 148, 148, 1207, 1207, 1207, 1207, 1207, 500, 1207, 1207, 1207]\n",
            "decoded output: im weiße im im Bü im im Bü Bü Bü Bü Bü sche Bü Bü Bü\n",
            "loss: tensor(2.3863, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 500, 0, 0, 102, 0, 0, 102, 148, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: sche er er im er er er er er er er\n",
            "loss: tensor(3.0320, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [457, 457, 500, 457, 100, 100, 100, 148, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: Freien Freien sche Freien in in in im in in in in in in in in in\n",
            "loss: tensor(3.3907, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [457, 457, 500, 457, 100, 100, 100, 457, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: Freien Freien sche Freien in in in Freien in in in in in in in in in\n",
            "loss: tensor(3.2250, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [457, 457, 457, 457, 457, 100, 457, 457, 100, 500, 100, 100, 100, 500, 100, 100, 100]\n",
            "decoded output: Freien Freien Freien Freien Freien in Freien Freien in sche in in in sche in in in\n",
            "loss: tensor(2.7390, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 217, 217, 500, 217, 148, 217, 217, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "decoded output: junge Männer Männer sche Männer im Männer Männer im im im im im im im im im\n",
            "loss: tensor(2.3848, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 351, 160, 0, 160, 160, 0, 0, 0, 0, 0, 649, 0, 0, 0]\n",
            "decoded output: Zwei Zwei junge Zwei Zwei Zwei weiße\n",
            "loss: tensor(2.7201, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 0, 351, 0, 121, 0, 0, 121, 160, 121, 121, 121, 649, 121, 121, 121]\n",
            "decoded output: Zwei junge der der Zwei der der der weiße der der der\n",
            "loss: tensor(2.5398, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 0, 121, 121, 121, 0, 0, 121, 121, 121, 121, 121, 649, 121, 121, 121]\n",
            "decoded output: Zwei der der der der der der der der weiße der der der\n",
            "loss: tensor(2.4252, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 217, 217, 121, 121, 14, 217, 217, 14, 14, 14, 14, 14, 500, 14, 14, 14]\n",
            "decoded output: Männer Männer der der . Männer Männer . . . . . sche . . .\n",
            "loss: tensor(2.3171, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 148, 148, 14, 14, 14, 148, 457, 14, 14, 14, 14, 14, 1207, 148, 14, 14]\n",
            "decoded output: weiße im im . . . im Freien . . . . . Bü im . .\n",
            "loss: tensor(2.6022, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 0, 457, 1207, 1207, 457, 457, 457, 457, 1207, 1207, 1207, 1207, 457, 1207, 1207, 1207]\n",
            "decoded output: weiße Freien Bü Bü Freien Freien Freien Freien Bü Bü Bü Bü Freien Bü Bü Bü\n",
            "loss: tensor(2.8478, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 1207, 1207, 457, 649, 457, 457, 102, 1207, 102, 102, 457, 102, 102, 102]\n",
            "decoded output: weiße weiße weiße Bü Bü Freien weiße Freien Freien er Bü er er Freien er er er\n",
            "loss: tensor(2.6536, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 0, 649, 1207, 1207, 649, 649, 649, 649, 102, 649, 102, 102, 649, 102, 102, 1207]\n",
            "decoded output: weiße weiße Bü Bü weiße weiße weiße weiße er weiße er er weiße er er Bü\n",
            "loss: tensor(2.6824, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 0, 100, 513, 513, 100, 100, 100, 100, 788, 513, 788, 788, 100, 788, 788, 788]\n",
            "decoded output: weiße in Nähe Nähe in in in in viel Nähe viel viel in viel viel viel\n",
            "loss: tensor(2.4497, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 100, 513, 513, 444, 100, 100, 444, 788, 513, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: in Nähe Nähe sind in in sind viel Nähe viel viel sind viel viel viel\n",
            "loss: tensor(2.2445, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 160, 444, 444, 148, 148, 444, 788, 500, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei im Zwei sind sind im im sind viel sche viel viel sind viel viel viel\n",
            "loss: tensor(2.0685, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 160, 160, 148, 148, 148, 148, 500, 500, 500, 500, 148, 500, 500, 500]\n",
            "decoded output: Zwei im Zwei Zwei im im im im sche sche sche sche im sche sche sche\n",
            "loss: tensor(2.0795, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 0, 0, 351, 148, 148, 351, 500, 500, 500, 500, 351, 500, 500, 500]\n",
            "decoded output: Zwei im junge im im junge sche sche sche sche junge sche sche sche\n",
            "loss: tensor(2.0690, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 0, 0, 217, 148, 148, 217, 121, 217, 121, 121, 217, 121, 121, 121]\n",
            "decoded output: Zwei junge Männer im im Männer der Männer der der Männer der der der\n",
            "loss: tensor(2.0179, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 0, 0, 217, 351, 351, 217, 121, 121, 121, 121, 217, 217, 121, 121]\n",
            "decoded output: Zwei junge Männer junge junge Männer der der der der Männer Männer der der\n",
            "loss: tensor(1.9951, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 0, 0, 217, 351, 351, 217, 121, 121, 121, 121, 217, 217, 121, 121]\n",
            "decoded output: Zwei junge Männer junge junge Männer der der der der Männer Männer der der\n",
            "loss: tensor(1.9377, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 100, 649, 649, 100, 100, 100, 100, 1, 1, 1, 1, 100, 513, 1, 1]\n",
            "decoded output: Zwei in weiße weiße in in in in in Nähe\n",
            "loss: tensor(1.9015, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 100, 649, 649, 100, 148, 148, 100, 513, 1, 1, 1, 100, 1, 1, 1]\n",
            "decoded output: Zwei in weiße weiße in im im in Nähe in\n",
            "loss: tensor(1.8814, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 649, 649, 444, 148, 148, 444, 513, 1, 1, 1, 444, 1, 1, 1]\n",
            "decoded output: Zwei im weiße weiße sind im im sind Nähe sind\n",
            "loss: tensor(1.8149, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 788, 649, 444, 148, 148, 444, 513, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei im viel weiße sind im im sind Nähe viel viel viel sind viel viel viel\n",
            "loss: tensor(2.0417, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 14, 14, 1207, 148, 148, 1207, 513, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei im . . Bü im im Bü Nähe . . . Bü . . .\n",
            "loss: tensor(2.0943, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 14, 14, 1207, 148, 148, 1207, 513, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei im . . Bü im im Bü Nähe . . . Bü . . .\n",
            "loss: tensor(2.0158, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 14, 14, 1207, 148, 148, 1207, 649, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei im . . Bü im im Bü weiße . . . Bü . . .\n",
            "loss: tensor(1.8998, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 1207, 457, 457, 1207, 649, 102, 102, 102, 1207, 102, 102, 102]\n",
            "decoded output: Zwei junge er er Bü Freien Freien Bü weiße er er er Bü er er er\n",
            "loss: tensor(1.8252, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 1207, 351, 351, 1207, 649, 1, 1, 1, 1207, 1, 1, 1]\n",
            "decoded output: Zwei junge Bü junge junge Bü weiße Bü\n",
            "loss: tensor(1.8145, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 100, 457, 457, 100, 649, 1, 1, 1, 100, 1, 1, 1]\n",
            "decoded output: Zwei junge in Freien Freien in weiße in\n",
            "loss: tensor(1.8070, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 1, 1, 100, 148, 148, 100, 649, 1, 1, 1, 100, 1, 1, 1]\n",
            "decoded output: Zwei im in im im in weiße in\n",
            "loss: tensor(1.7522, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 1, 1, 1207, 148, 148, 1207, 649, 1, 148, 1, 1207, 1, 1, 1]\n",
            "decoded output: Zwei im Bü im im Bü weiße im Bü\n",
            "loss: tensor(2.4870, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 1207, 148, 148, 1207, 121, 500, 148, 500, 1207, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche Bü im im Bü der sche im sche Bü sche sche sche\n",
            "loss: tensor(2.3784, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 1207, 351, 351, 1207, 121, 500, 351, 500, 1207, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche Bü junge junge Bü der sche junge sche Bü sche sche sche\n",
            "loss: tensor(2.2623, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 513, 513, 1207, 351, 351, 1207, 121, 513, 513, 513, 1207, 513, 513, 513]\n",
            "decoded output: Zwei junge Nähe Nähe Bü junge junge Bü der Nähe Nähe Nähe Bü Nähe Nähe Nähe\n",
            "loss: tensor(1.6905, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 513, 513, 444, 457, 457, 444, 121, 513, 513, 513, 444, 513, 513, 513]\n",
            "decoded output: Zwei junge Nähe Nähe sind Freien Freien sind der Nähe Nähe Nähe sind Nähe Nähe Nähe\n",
            "loss: tensor(1.6763, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 457, 513, 513, 444, 457, 457, 444, 121, 513, 513, 513, 444, 513, 513, 513]\n",
            "decoded output: Zwei Freien Nähe Nähe sind Freien Freien sind der Nähe Nähe Nähe sind Nähe Nähe Nähe\n",
            "loss: tensor(1.6153, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 457, 649, 649, 1207, 457, 457, 1207, 121, 649, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei Freien weiße weiße Bü Freien Freien Bü der weiße weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.5825, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 788, 788, 1207, 148, 148, 1207, 121, 788, 788, 788, 1207, 788, 788, 788]\n",
            "decoded output: Zwei im viel viel Bü im im Bü der viel viel viel Bü viel viel viel\n",
            "loss: tensor(1.5623, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 148, 217, 217, 100, 148, 148, 100, 121, 217, 217, 217, 100, 217, 217, 217]\n",
            "decoded output: Zwei im Männer Männer in im im in der Männer Männer Männer in Männer Männer Männer\n",
            "loss: tensor(1.5519, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 351, 148, 148, 351, 121, 500, 500, 500, 351, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche junge im im junge der sche sche sche junge sche sche sche\n",
            "loss: tensor(1.5553, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 100, 457, 457, 100, 121, 500, 500, 500, 100, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche in Freien Freien in der sche sche sche in sche sche sche\n",
            "loss: tensor(1.5114, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 457, 513, 513, 100, 457, 457, 100, 121, 513, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei Freien Nähe Nähe in Freien Freien in der Nähe Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.4730, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 457, 513, 513, 444, 457, 457, 444, 121, 513, 513, 513, 444, 513, 513, 513]\n",
            "decoded output: Zwei Freien Nähe Nähe sind Freien Freien sind der Nähe Nähe Nähe sind Nähe Nähe Nähe\n",
            "loss: tensor(1.4489, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 148, 148, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind im im sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.4435, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 1207, 148, 148, 1207, 121, 788, 788, 788, 1207, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel Bü im im Bü der viel viel viel Bü viel viel viel\n",
            "loss: tensor(1.4348, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 148, 148, 1207, 121, 649, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Bü im im Bü der weiße weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.4087, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 100, 457, 457, 100, 121, 102, 102, 102, 100, 102, 102, 102]\n",
            "decoded output: Zwei junge er er in Freien Freien in der er er er in er er er\n",
            "loss: tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 100, 457, 457, 100, 121, 513, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei junge . . in Freien Freien in der Nähe Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.3752, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 100, 148, 148, 100, 121, 500, 500, 500, 100, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche in im im in der sche sche sche in sche sche sche\n",
            "loss: tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 444, 148, 148, 444, 121, 500, 500, 500, 444, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche sind im im sind der sche sche sche sind sche sche sche\n",
            "loss: tensor(1.3542, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 148, 457, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind im Freien sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.3506, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 457, 457, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind Freien Freien sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.3425, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 1207, 457, 457, 1207, 121, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei junge . . Bü Freien Freien Bü der . . . Bü . . .\n",
            "loss: tensor(1.3337, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 100, 148, 148, 100, 121, 14, 14, 14, 100, 14, 14, 14]\n",
            "decoded output: Zwei junge . . in im im in der . . . in . . .\n",
            "loss: tensor(1.3268, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 100, 148, 148, 100, 121, 500, 500, 500, 100, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche in im im in der sche sche sche in sche sche sche\n",
            "loss: tensor(1.3167, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 100, 457, 457, 100, 121, 500, 500, 500, 100, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche in Freien Freien in der sche sche sche in sche sche sche\n",
            "loss: tensor(1.3071, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 457, 457, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind Freien Freien sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.2988, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 444, 148, 148, 444, 121, 217, 217, 217, 444, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer sind im im sind der Männer Männer Männer sind Männer Männer Männer\n",
            "loss: tensor(1.2899, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 1207, 148, 148, 1207, 121, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei junge Männer Männer Bü im im Bü der . . . Bü . . .\n",
            "loss: tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 457, 457, 1207, 121, 649, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Bü Freien Freien Bü der weiße weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.2779, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 457, 457, 1207, 121, 649, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Bü Freien Freien Bü der weiße weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.2725, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 148, 148, 100, 121, 788, 788, 788, 100, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel in im im in der viel viel viel in viel viel viel\n",
            "loss: tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 148, 148, 100, 121, 788, 788, 788, 100, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel in im im in der viel viel viel in viel viel viel\n",
            "loss: tensor(1.2671, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 444, 457, 457, 444, 121, 217, 217, 217, 444, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer sind Freien Freien sind der Männer Männer Männer sind Männer Männer Männer\n",
            "loss: tensor(1.2632, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 457, 457, 1207, 121, 649, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Bü Freien Freien Bü der weiße weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.2632, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 1207, 148, 148, 1207, 121, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei junge . . Bü im im Bü der . . . Bü . . .\n",
            "loss: tensor(1.2612, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 148, 148, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind im im sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 457, 457, 100, 121, 788, 788, 788, 100, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel in Freien Freien in der viel viel viel in viel viel viel\n",
            "loss: tensor(1.2596, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 457, 457, 100, 121, 513, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei junge Männer Männer in Freien Freien in der Nähe Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.2580, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 100, 148, 148, 100, 121, 649, 649, 649, 100, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße in im im in der weiße weiße weiße in weiße weiße weiße\n",
            "loss: tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 1207, 457, 457, 1207, 121, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei junge . . Bü Freien Freien Bü der . . . Bü . . .\n",
            "loss: tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 444, 457, 457, 444, 121, 14, 14, 14, 444, 14, 14, 14]\n",
            "decoded output: Zwei junge . . sind Freien Freien sind der . . . sind . . .\n",
            "loss: tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 148, 148, 444, 121, 788, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind im im sind der viel viel viel sind viel viel viel\n",
            "loss: tensor(1.2556, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 513, 513, 100, 148, 148, 100, 121, 513, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei junge Nähe Nähe in im im in der Nähe Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.2550, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 100, 457, 457, 100, 121, 649, 649, 649, 100, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße in Freien Freien in der weiße weiße weiße in weiße weiße weiße\n",
            "loss: tensor(1.2543, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 1207, 148, 148, 1207, 121, 14, 14, 14, 1207, 14, 14, 14]\n",
            "decoded output: Zwei junge . . Bü im im Bü der . . . Bü . . .\n",
            "loss: tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 1207, 148, 148, 1207, 121, 217, 217, 217, 1207, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer Bü im im Bü der Männer Männer Männer Bü Männer Männer Männer\n",
            "loss: tensor(1.2530, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 513, 513, 444, 457, 457, 444, 121, 513, 513, 513, 444, 513, 513, 513]\n",
            "decoded output: Zwei junge Nähe Nähe sind Freien Freien sind der Nähe Nähe Nähe sind Nähe Nähe Nähe\n",
            "loss: tensor(1.2530, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 148, 148, 100, 121, 513, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei junge viel viel in im im in der Nähe Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.2519, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 100, 148, 148, 100, 14, 121, 14, 14, 100, 14, 14, 14]\n",
            "decoded output: Zwei junge weiße weiße in im im in . der . . in . . .\n",
            "loss: tensor(2.4063, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 100, 457, 457, 100, 14, 121, 14, 14, 100, 14, 14, 14]\n",
            "decoded output: Zwei junge . . in Freien Freien in . der . . in . . .\n",
            "loss: tensor(2.2498, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 1207, 148, 148, 1207, 788, 121, 788, 788, 1207, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel Bü im im Bü viel der viel viel Bü viel viel viel\n",
            "loss: tensor(2.0276, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 148, 148, 1207, 513, 121, 513, 513, 1207, 513, 513, 513]\n",
            "decoded output: Zwei junge weiße weiße Bü im im Bü Nähe der Nähe Nähe Bü Nähe Nähe Nähe\n",
            "loss: tensor(1.8064, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 513, 513, 100, 457, 457, 100, 513, 121, 513, 513, 100, 513, 513, 513]\n",
            "decoded output: Zwei junge Nähe Nähe in Freien Freien in Nähe der Nähe Nähe in Nähe Nähe Nähe\n",
            "loss: tensor(1.6312, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 444, 148, 148, 444, 500, 121, 500, 500, 444, 500, 500, 500]\n",
            "decoded output: Zwei junge er er sind im im sind sche der sche sche sind sche sche sche\n",
            "loss: tensor(1.5133, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 100, 148, 148, 100, 500, 121, 500, 500, 100, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche in im im in sche der sche sche in sche sche sche\n",
            "loss: tensor(1.4128, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 1207, 457, 457, 1207, 217, 513, 217, 217, 1207, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer Bü Freien Freien Bü Männer Nähe Männer Männer Bü Männer Männer Männer\n",
            "loss: tensor(1.3740, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 1207, 457, 457, 1207, 649, 513, 649, 649, 1207, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Bü Freien Freien Bü weiße Nähe weiße weiße Bü weiße weiße weiße\n",
            "loss: tensor(1.3506, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 100, 148, 148, 100, 649, 513, 649, 649, 100, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße in im im in weiße Nähe weiße weiße in weiße weiße weiße\n",
            "loss: tensor(1.3281, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 444, 457, 457, 444, 121, 513, 121, 121, 444, 121, 121, 121]\n",
            "decoded output: Zwei junge der der sind Freien Freien sind der Nähe der der sind der der der\n",
            "loss: tensor(1.3320, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 444, 457, 457, 444, 121, 513, 121, 121, 444, 121, 121, 121]\n",
            "decoded output: Zwei junge der der sind Freien Freien sind der Nähe der der sind der der der\n",
            "loss: tensor(1.3264, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 500, 500, 1207, 148, 148, 1207, 500, 513, 500, 500, 1207, 500, 500, 500]\n",
            "decoded output: Zwei junge sche sche Bü im im Bü sche Nähe sche sche Bü sche sche sche\n",
            "loss: tensor(1.3321, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 457, 457, 100, 217, 513, 217, 217, 100, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer in Freien Freien in Männer Nähe Männer Männer in Männer Männer Männer\n",
            "loss: tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 100, 457, 457, 100, 649, 513, 649, 649, 100, 649, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße in Freien Freien in weiße Nähe weiße weiße in weiße weiße weiße\n",
            "loss: tensor(1.3192, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 444, 148, 148, 444, 14, 513, 14, 14, 444, 14, 14, 14]\n",
            "decoded output: Zwei junge . . sind im im sind . Nähe . . sind . . .\n",
            "loss: tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 457, 457, 444, 788, 513, 788, 788, 444, 788, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind Freien Freien sind viel Nähe viel viel sind viel viel viel\n",
            "loss: tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 1207, 457, 457, 1207, 788, 788, 102, 788, 1207, 513, 788, 788]\n",
            "decoded output: Zwei junge er er Bü Freien Freien Bü viel viel er viel Bü Nähe viel viel\n",
            "loss: tensor(1.5339, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 148, 148, 100, 217, 217, 217, 217, 100, 513, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer in im im in Männer Männer Männer Männer in Nähe Männer Männer\n",
            "loss: tensor(1.5329, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 100, 457, 457, 100, 1, 513, 1, 1, 100, 1, 1, 1]\n",
            "decoded output: Zwei junge in Freien Freien in Nähe in\n",
            "loss: tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 121, 444, 148, 148, 444, 102, 444, 102, 102, 513, 444, 102, 102]\n",
            "decoded output: Zwei junge er der sind im im sind er sind er er Nähe sind er er\n",
            "loss: tensor(2.1950, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 444, 457, 457, 444, 102, 444, 102, 102, 102, 513, 102, 102]\n",
            "decoded output: Zwei junge er er sind Freien Freien sind er sind er er er Nähe er er\n",
            "loss: tensor(1.8711, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 148, 148, 100, 788, 100, 788, 788, 513, 513, 788, 788]\n",
            "decoded output: Zwei junge viel viel in im im in viel in viel viel Nähe Nähe viel viel\n",
            "loss: tensor(1.5850, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 457, 457, 100, 217, 100, 217, 217, 513, 217, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer in Freien Freien in Männer in Männer Männer Nähe Männer Männer Männer\n",
            "loss: tensor(1.5270, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 513, 148, 148, 513, 102, 513, 102, 102, 513, 102, 102, 102]\n",
            "decoded output: Zwei junge er er Nähe im im Nähe er Nähe er er Nähe er er er\n",
            "loss: tensor(1.4828, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 513, 148, 148, 513, 14, 513, 14, 14, 14, 500, 14, 14]\n",
            "decoded output: Zwei junge . . Nähe im im Nähe . Nähe . . . sche . .\n",
            "loss: tensor(1.4623, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 457, 457, 444, 788, 444, 788, 788, 788, 1207, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind Freien Freien sind viel sind viel viel viel Bü viel viel\n",
            "loss: tensor(1.4311, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 444, 148, 148, 444, 1, 444, 1, 1, 1, 1207, 1, 1]\n",
            "decoded output: Zwei junge sind im im sind sind Bü\n",
            "loss: tensor(1.4183, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 100, 457, 457, 100, 121, 100, 121, 121, 121, 500, 121, 121]\n",
            "decoded output: Zwei junge der der in Freien Freien in der in der der der sche der der\n",
            "loss: tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 513, 148, 148, 513, 217, 513, 217, 217, 217, 500, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer Nähe im im Nähe Männer Nähe Männer Männer Männer sche Männer Männer\n",
            "loss: tensor(1.3684, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 513, 457, 457, 513, 788, 513, 788, 788, 788, 500, 788, 788]\n",
            "decoded output: Zwei junge er er Nähe Freien Freien Nähe viel Nähe viel viel viel sche viel viel\n",
            "loss: tensor(1.3647, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 444, 457, 457, 444, 102, 444, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei junge er er sind Freien Freien sind er sind er er er sche er er\n",
            "loss: tensor(1.3477, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 444, 148, 148, 444, 14, 444, 14, 14, 14, 500, 14, 14]\n",
            "decoded output: Zwei junge der der sind im im sind . sind . . . sche . .\n",
            "loss: tensor(1.3306, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 513, 457, 457, 513, 1207, 513, 1207, 1207, 1207, 500, 1207, 1207]\n",
            "decoded output: Zwei junge der der Nähe Freien Freien Nähe Bü Nähe Bü Bü Bü sche Bü Bü\n",
            "loss: tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 513, 148, 148, 513, 1, 513, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge Nähe im im Nähe Nähe sche\n",
            "loss: tensor(1.3232, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 100, 457, 457, 100, 102, 100, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei junge er er in Freien Freien in er in er er er sche er er\n",
            "loss: tensor(1.3114, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 513, 148, 148, 513, 788, 513, 788, 788, 788, 500, 788, 788]\n",
            "decoded output: Zwei junge viel viel Nähe im im Nähe viel Nähe viel viel viel sche viel viel\n",
            "loss: tensor(1.3076, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 513, 457, 457, 513, 1, 513, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge der der Nähe Freien Freien Nähe Nähe sche\n",
            "loss: tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 1, 1, 100, 148, 148, 100, 1, 100, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge in im im in in sche\n",
            "loss: tensor(1.2954, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 457, 457, 100, 217, 100, 217, 217, 217, 500, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer in Freien Freien in Männer in Männer Männer Männer sche Männer Männer\n",
            "loss: tensor(1.2925, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 102, 102, 513, 148, 148, 513, 102, 513, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei junge er er Nähe im im Nähe er Nähe er er er sche er er\n",
            "loss: tensor(1.2834, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 513, 457, 457, 513, 1, 513, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge viel viel Nähe Freien Freien Nähe Nähe sche\n",
            "loss: tensor(1.2831, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 14, 14, 100, 148, 148, 100, 14, 100, 14, 14, 14, 500, 14, 14]\n",
            "decoded output: Zwei junge . . in im im in . in . . . sche . .\n",
            "loss: tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 100, 457, 457, 100, 121, 100, 121, 121, 121, 500, 121, 121]\n",
            "decoded output: Zwei junge der der in Freien Freien in der in der der der sche der der\n",
            "loss: tensor(1.2852, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 148, 148, 100, 1, 100, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge Männer Männer in im im in in sche\n",
            "loss: tensor(1.2656, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 444, 148, 148, 444, 788, 444, 788, 788, 788, 500, 788, 788]\n",
            "decoded output: Zwei junge viel viel sind im im sind viel sind viel viel viel sche viel viel\n",
            "loss: tensor(1.2596, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 513, 457, 457, 513, 649, 513, 649, 649, 649, 500, 649, 649]\n",
            "decoded output: Zwei junge weiße weiße Nähe Freien Freien Nähe weiße Nähe weiße weiße weiße sche weiße weiße\n",
            "loss: tensor(1.2667, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 148, 148, 100, 102, 100, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei junge Männer Männer in im im in er in er er er sche er er\n",
            "loss: tensor(1.2635, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 217, 100, 457, 457, 100, 1, 100, 217, 217, 1, 500, 217, 217]\n",
            "decoded output: Zwei junge Männer Männer in Freien Freien in in Männer Männer sche Männer Männer\n",
            "loss: tensor(1.2535, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 513, 457, 457, 513, 1207, 513, 1207, 1207, 1207, 500, 1207, 1207]\n",
            "decoded output: Zwei junge weiße weiße Nähe Freien Freien Nähe Bü Nähe Bü Bü Bü sche Bü Bü\n",
            "loss: tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 649, 649, 444, 148, 148, 444, 14, 444, 14, 14, 14, 500, 14, 14]\n",
            "decoded output: Zwei junge weiße weiße sind im im sind . sind . . . sche . .\n",
            "loss: tensor(1.2574, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 217, 100, 513, 457, 457, 513, 102, 513, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Zwei junge Männer in Nähe Freien Freien Nähe er Nähe er er er sche er er\n",
            "loss: tensor(2.2090, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 121, 121, 100, 457, 457, 100, 1, 100, 1, 1, 1, 500, 1, 1]\n",
            "decoded output: Zwei junge der der in Freien Freien in in sche\n",
            "loss: tensor(1.2753, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 351, 788, 788, 100, 148, 148, 100, 788, 100, 148, 788, 14, 500, 788, 788]\n",
            "decoded output: Zwei junge viel viel in im im in viel in im viel . sche viel viel\n",
            "loss: tensor(2.8640, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 457, 160, 513, 102, 351, 160, 351, 351, 102, 351, 102, 102, 102, 500, 102, 102]\n",
            "decoded output: Freien Zwei Nähe er junge Zwei junge junge er junge er er er sche er er\n",
            "loss: tensor(5.0857, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 160, 217, 0, 0, 160, 217, 513, 513, 217, 217, 500, 217, 217, 217]\n",
            "decoded output: Zwei Zwei Zwei Männer Zwei Männer Nähe Nähe Männer Männer sche Männer Männer Männer\n",
            "loss: tensor(9.5836, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 0, 14, 14, 444, 14, 14, 444, 457, 14, 14, 14, 457, 444, 14, 500]\n",
            "decoded output: Zwei . . sind . . sind Freien . . . Freien sind . sche\n",
            "loss: tensor(11.0618, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 788, 788, 500, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 500, 788, 788]\n",
            "decoded output: in viel viel sche viel viel viel viel viel viel viel viel viel viel sche viel viel\n",
            "loss: tensor(8.2587, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [513, 513, 513, 513, 1207, 513, 500, 1207, 513, 500, 513, 1207, 1207, 513, 513, 1207, 1207]\n",
            "decoded output: Nähe Nähe Nähe Nähe Bü Nähe sche Bü Nähe sche Nähe Bü Bü Nähe Nähe Bü Bü\n",
            "loss: tensor(6.4953, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 500, 649, 649, 649, 649, 649]\n",
            "decoded output: in weiße weiße weiße weiße weiße weiße weiße weiße weiße weiße sche weiße weiße weiße weiße weiße\n",
            "loss: tensor(7.1365, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 148, 148, 148, 121, 148, 121, 121, 148, 148, 148, 148, 121, 500, 121, 121, 121]\n",
            "decoded output: in im im im der im der der im im im im der sche der der der\n",
            "loss: tensor(5.0108, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 351, 457, 457, 457, 457, 351, 351, 351, 457, 351, 351, 457, 457, 457, 457, 457]\n",
            "decoded output: junge junge Freien Freien Freien Freien junge junge junge Freien junge junge Freien Freien Freien Freien Freien\n",
            "loss: tensor(4.7681, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 14, 0, 14, 0, 0, 100, 14, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "decoded output: . . in . in in in in in in in in\n",
            "loss: tensor(3.6550, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 102, 0, 0, 513, 102, 102, 102, 102, 102, 102, 102, 102, 102]\n",
            "decoded output: er Nähe er er er er er er er er er\n",
            "loss: tensor(3.2016, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 1, 1, 1, 160, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "decoded output: Zwei Zwei Zwei Zwei\n",
            "loss: tensor(3.6367, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 217, 217, 160, 217, 500, 217, 217, 217, 217, 217, 217, 217, 217]\n",
            "decoded output: Zwei Zwei Zwei Zwei Männer Männer Zwei Männer sche Männer Männer Männer Männer Männer Männer Männer Männer\n",
            "loss: tensor(3.3707, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 121, 649, 788, 649, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788, 788]\n",
            "decoded output: weiße der weiße viel weiße viel viel viel viel viel viel viel viel viel viel viel viel\n",
            "loss: tensor(3.6836, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 788, 788, 788, 788, 788, 788, 788, 788, 649, 788, 788, 788, 788, 788]\n",
            "decoded output: weiße weiße weiße viel viel viel viel viel viel viel viel weiße viel viel viel viel viel\n",
            "loss: tensor(3.6836, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 148, 649, 148, 148, 649, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "decoded output: weiße im weiße im im weiße im im im im im im im im im im im\n",
            "loss: tensor(3.4410, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 100, 100, 100, 100, 100, 100, 1, 100, 1, 649, 100, 100, 649, 100, 100]\n",
            "decoded output: weiße weiße in in in in in in in weiße in in weiße in in\n",
            "loss: tensor(3.4093, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 102, 102, 102, 649, 457, 457, 102, 649, 457, 457, 457, 457, 457, 457, 457, 457]\n",
            "decoded output: weiße er er er weiße Freien Freien er weiße Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(3.0056, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 0, 457, 0, 0, 0, 457, 457, 0, 457, 457, 457, 457, 457]\n",
            "decoded output: Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(2.9447, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 0, 0, 0, 457, 457, 0, 0, 457, 457, 457, 457, 457, 457, 457, 457]\n",
            "decoded output: Freien Freien Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(2.9457, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 160, 160, 0, 14, 14, 160, 14, 14, 0, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: Zwei Zwei . . Zwei . . . . . . . .\n",
            "loss: tensor(2.9460, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 160, 14, 14, 160, 14, 14, 160, 160, 14, 14, 14, 14, 14]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei . . Zwei . . Zwei Zwei . . . . .\n",
            "loss: tensor(2.8877, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 1, 160, 1, 1, 160, 1, 1, 1, 160, 160, 1, 1, 160, 1, 1]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei Zwei Zwei\n",
            "loss: tensor(2.9894, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 1, 160, 1, 1, 160, 1, 1, 1, 1, 1, 1, 160, 1, 1]\n",
            "decoded output: Zwei Zwei Zwei Zwei Zwei Zwei\n",
            "loss: tensor(2.7806, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 788, 1207, 1207, 1207, 788, 1207, 788, 1207, 1207, 788, 1207, 1207, 1207, 351, 1207, 1207]\n",
            "decoded output: junge viel Bü Bü Bü viel Bü viel Bü Bü viel Bü Bü Bü junge Bü Bü\n",
            "loss: tensor(2.9870, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 788, 148, 148, 148, 788, 148, 148, 148, 148, 788, 148, 148, 148, 351, 148, 148]\n",
            "decoded output: junge viel im im im viel im im im im viel im im im junge im im\n",
            "loss: tensor(2.9531, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [351, 649, 148, 148, 148, 351, 351, 148, 148, 148, 351, 148, 148, 148, 351, 148, 148]\n",
            "decoded output: junge weiße im im im junge junge im im im junge im im im junge im im\n",
            "loss: tensor(2.9001, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [100, 0, 14, 14, 14, 0, 0, 14, 14, 14, 0, 14, 14, 14, 0, 14, 14]\n",
            "decoded output: in . . . . . . . . . . .\n",
            "loss: tensor(2.8548, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 14, 14, 1, 0, 0, 14, 14, 14, 0, 14, 14, 14, 0, 14, 14]\n",
            "decoded output: . . . . . . . . . .\n",
            "loss: tensor(2.7660, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 1, 1, 102, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "decoded output: er\n",
            "loss: tensor(2.6873, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 102, 102, 102, 0, 0, 102, 102, 102, 102, 102, 102, 102, 0, 102, 102]\n",
            "decoded output: er er er er er er er er er er er er\n",
            "loss: tensor(2.7450, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 457, 457, 102, 0, 0, 457, 457, 457, 457, 457, 457, 457, 0, 457, 457]\n",
            "decoded output: Freien Freien er Freien Freien Freien Freien Freien Freien Freien Freien Freien\n",
            "loss: tensor(2.6832, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 0, 1207, 1207, 1207, 500, 160, 1207, 500, 1207, 1207, 1207, 1207, 1207, 500, 1207, 1207]\n",
            "decoded output: sche Bü Bü Bü sche Zwei Bü sche Bü Bü Bü Bü Bü sche Bü Bü\n",
            "loss: tensor(2.7004, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 217, 217, 217, 160, 160, 217, 160, 217, 217, 217, 217, 217, 160, 217, 217]\n",
            "decoded output: Zwei Zwei Männer Männer Männer Zwei Zwei Männer Zwei Männer Männer Männer Männer Männer Zwei Männer Männer\n",
            "loss: tensor(2.6626, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 14, 14, 14, 160, 160, 14, 160, 14, 14, 14, 14, 14, 160, 14, 14]\n",
            "decoded output: Zwei Zwei . . . Zwei Zwei . Zwei . . . . . Zwei . .\n",
            "loss: tensor(2.6300, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 1, 1, 102, 160, 160, 1, 160, 1, 1, 1, 1, 1, 160, 1, 1]\n",
            "decoded output: Zwei Zwei er Zwei Zwei Zwei Zwei\n",
            "loss: tensor(2.5665, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 788, 788, 102, 160, 160, 788, 160, 788, 788, 160, 788, 788, 160, 788, 788]\n",
            "decoded output: Zwei Zwei viel viel er Zwei Zwei viel Zwei viel viel Zwei viel viel Zwei viel viel\n",
            "loss: tensor(2.5435, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 0, 788, 788, 102, 0, 0, 788, 0, 788, 788, 0, 788, 788, 0, 788, 788]\n",
            "decoded output: viel viel er viel viel viel viel viel viel viel\n",
            "loss: tensor(2.4821, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 500, 1207, 513, 102, 500, 500, 1207, 500, 1207, 1207, 1207, 1207, 1207, 500, 1207, 1207]\n",
            "decoded output: sche sche Bü Nähe er sche sche Bü sche Bü Bü Bü Bü Bü sche Bü Bü\n",
            "loss: tensor(2.4514, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [148, 148, 14, 100, 14, 148, 148, 100, 14, 14, 14, 14, 14, 14, 148, 14, 14]\n",
            "decoded output: im im . in . im im in . . . . . . im . .\n",
            "loss: tensor(2.4784, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [148, 148, 217, 100, 217, 148, 148, 457, 217, 217, 217, 217, 217, 217, 148, 217, 217]\n",
            "decoded output: im im Männer in Männer im im Freien Männer Männer Männer Männer Männer Männer im Männer Männer\n",
            "loss: tensor(2.4511, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 148, 457, 100, 457, 148, 148, 457, 457, 457, 457, 457, 457, 457, 500, 457, 457]\n",
            "decoded output: sche im Freien in Freien im im Freien Freien Freien Freien Freien Freien Freien sche Freien Freien\n",
            "loss: tensor(2.3966, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 0, 457, 0, 457, 513, 513, 457, 457, 457, 457, 457, 457, 457, 500, 457, 457]\n",
            "decoded output: sche Freien Freien Nähe Nähe Freien Freien Freien Freien Freien Freien Freien sche Freien Freien\n",
            "loss: tensor(2.7731, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 0, 513, 0, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 500, 513, 513]\n",
            "decoded output: sche Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe Nähe sche Nähe Nähe\n",
            "loss: tensor(2.6000, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 0, 513, 0, 513, 100, 100, 100, 513, 513, 513, 513, 513, 513, 500, 513, 513]\n",
            "decoded output: sche Nähe Nähe in in in Nähe Nähe Nähe Nähe Nähe Nähe sche Nähe Nähe\n",
            "loss: tensor(2.4745, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 500, 500, 0, 14, 148, 148, 500, 14, 14, 14, 14, 14, 14, 500, 14, 14]\n",
            "decoded output: sche sche sche . im im sche . . . . . . sche . .\n",
            "loss: tensor(3.0610, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 148, 500, 102, 148, 148, 500, 160, 148, 102, 102, 500, 217, 102, 500, 102, 102]\n",
            "decoded output: sche im sche er im im sche Zwei im er er sche Männer er sche er er\n",
            "loss: tensor(3.0107, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 100, 160, 102, 102, 121, 160, 160, 102, 102, 102, 102, 102, 102, 160, 102, 102]\n",
            "decoded output: Zwei in Zwei er er der Zwei Zwei er er er er er er Zwei er er\n",
            "loss: tensor(2.9418, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 121, 160, 121, 121, 121, 649, 160, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207, 1207]\n",
            "decoded output: weiße der Zwei der der der weiße Zwei Bü Bü Bü Bü Bü Bü Bü Bü Bü\n",
            "loss: tensor(3.5491, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 160, 351, 351, 649, 649, 160, 351, 351, 351, 1207, 351, 351, 351, 351, 351]\n",
            "decoded output: weiße weiße Zwei junge junge weiße weiße Zwei junge junge junge Bü junge junge junge junge junge\n",
            "loss: tensor(3.1752, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [160, 160, 160, 160, 351, 160, 351, 160, 351, 351, 351, 351, 351, 351, 351, 351, 351]\n",
            "decoded output: Zwei Zwei Zwei Zwei junge Zwei junge Zwei junge junge junge junge junge junge junge junge junge\n",
            "loss: tensor(2.9694, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [0, 160, 160, 160, 457, 0, 457, 0, 457, 457, 457, 513, 457, 457, 457, 457, 457]\n",
            "decoded output: Zwei Zwei Zwei Freien Freien Freien Freien Freien Nähe Freien Freien Freien Freien Freien\n",
            "loss: tensor(2.9929, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 500, 500, 500, 788, 788, 788, 500, 457, 788, 788, 513, 500, 788, 457, 788, 788]\n",
            "decoded output: sche sche sche sche viel viel viel sche Freien viel viel Nähe sche viel Freien viel viel\n",
            "loss: tensor(3.1240, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [500, 500, 500, 500, 14, 500, 500, 500, 14, 14, 148, 14, 14, 14, 14, 14, 14]\n",
            "decoded output: sche sche sche sche . sche sche sche . . im . . . . . .\n",
            "loss: tensor(2.7253, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [148, 148, 148, 148, 14, 148, 148, 148, 14, 14, 14, 513, 14, 14, 14, 14, 14]\n",
            "decoded output: im im im im . im im im . . . Nähe . . . . .\n",
            "loss: tensor(2.7175, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 217, 649, 217, 649, 217, 217, 217, 649, 513, 217, 217, 217, 217]\n",
            "decoded output: weiße weiße weiße weiße Männer weiße Männer weiße Männer Männer Männer weiße Nähe Männer Männer Männer Männer\n",
            "loss: tensor(2.8749, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 217, 649, 649, 649, 217, 217, 217, 649, 217, 217, 217, 217, 217]\n",
            "decoded output: weiße weiße weiße weiße Männer weiße weiße weiße Männer Männer Männer weiße Männer Männer Männer Männer Männer\n",
            "loss: tensor(2.6866, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [649, 649, 649, 649, 1207, 649, 649, 649, 1207, 1207, 1207, 649, 1207, 1207, 1207, 1207, 1207]\n",
            "decoded output: weiße weiße weiße weiße Bü weiße weiße weiße Bü Bü Bü weiße Bü Bü Bü Bü Bü\n",
            "loss: tensor(2.6562, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n",
            "argmax x: [444, 444, 444, 444, 100, 444, 444, 444, 100, 100, 100, 444, 1207, 100, 100, 100, 100]\n",
            "decoded output: sind sind sind sind in sind sind sind in in in sind Bü in in in in\n",
            "loss: tensor(2.5955, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-129f425f00ea>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJKGE-a_ry_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}