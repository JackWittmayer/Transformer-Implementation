{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8576,"status":"ok","timestamp":1668729580813,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"6D_W7a6D1Wh6","outputId":"93ad3a77-5fdf-4096-89fb-be4f9fe1b739"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 4.7 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.13.2\n"]}],"source":["!pip install tokenizers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3101,"status":"ok","timestamp":1668729583911,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"p1A-GVox07sY"},"outputs":[],"source":["import re\n","import string\n","import os\n","import pickle\n","from unicodedata import normalize\n","from collections import Counter\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from torch.nn.functional import log_softmax, pad\n","\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.pre_tokenizers import Whitespace\n","from tokenizers.trainers import BpeTrainer\n","\n","import random\n","\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668729583911,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"XpHKI8WMK0lM"},"outputs":[],"source":["device = torch.device('cuda')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668729583911,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"YjTsSsYf_baI"},"outputs":[],"source":["random.seed(\"25\")"]},{"cell_type":"markdown","metadata":{"id":"uLciHaXdGDAX"},"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"7TO5GWfqKNNm"},"outputs":[],"source":["enRawName = \"drive/MyDrive/colab data/multi30kEnTrain.txt\"\n","deRawName = \"drive/MyDrive/colab data/multi30kDeTrain.txt\"\n","en30kVal = \"drive/MyDrive/colab data/multi30kEnVal.txt\"\n","de30kVal = \"drive/MyDrive/colab data/multi30kDeVal.txt\"\n","englishCleanName = \"data/english_tokens.pkl\"\n","germanCleanName = \"data/german_tokens.pkl\"\n","englishSortedName = \"data/englishSorted.pkl\"\n","germanSortedName = \"data/germanSorted.pkl\"\n","\n","truncEn = \"drive/MyDrive/colab data/truncEn.pkl\"\n","truncDe = \"drive/MyDrive/colab data/truncDe.pkl\"\n","\n","enTokenizerName = \"drive/MyDrive/colab data/enTokenizer.pkl\"\n","deTokenizerName = \"drive/MyDrive/colab data/deTokenizer.pkl\"\n","pairsName = \"drive/MyDrive/colab data/pairs.pkl\"\n","folder = \"drive/MyDrive/colab data/\"\n","\n","enTrainingFileName = folder + \"enTraining\"\n","deTrainingFileName = folder + \"deTraining\"\n","enTestFileName = folder + \"enTest\"\n","deTestFileName = folder + \"deTest\"\n","enValFileName = folder + \"enValidation\"\n","deValFileName = folder + \"deValidation\"\n","\n","enCombinedFileName = folder + \"enCombined\"\n","deCombinedFileName = folder + \"deCombined\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"lwin0ALnKS4q"},"outputs":[],"source":["# load doc into memory\n","def load_doc(filename):\n","    # open the file as read only\n","    file = open(filename, mode='rt')\n","    # read all text\n","    text = file.read()\n","    # close the file\n","    file.close()\n","    return text"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"d8iH3pUDKUAz"},"outputs":[],"source":["# split a loaded document into sentences\n","def to_sentences(doc):\n","    return doc.strip().split('\\n')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"VbUz8uUgKU-b"},"outputs":[],"source":["# clean a list of lines\n","def clean_lines(lines):\n","    cleaned = list()\n","    # prepare regex for char filtering\n","    re_print = re.compile('[^%s]' % re.escape(string.printable))\n","    # prepare translation table for removing punctuation\n","    #table = str.maketrans('', '', string.punctuation)\n","    for line in lines:\n","        # normalize unicode characters\n","        line = normalize('NFD', line).encode('ascii', 'ignore')\n","        line = line.decode('UTF-8')\n","        # tokenize on white space\n","        line = line.split()\n","        # convert to lower case\n","        #line = [word.lower() for word in line]\n","        # remove punctuation from each token\n","        #line = [word.translate(table) for word in line]\n","        # remove non-printable chars form each token\n","        line = [re_print.sub('', w) for w in line]\n","        # remove tokens with numbers in them\n","        line = [word for word in line if word.isalpha()]\n","        # store as string\n","        cleaned.append(' '.join(line))\n","    return cleaned"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"ak3BlJDpKV_K"},"outputs":[],"source":["def cleanLine(line, addSOS=False):\n","    # prepare regex for char filtering\n","    #re_print = re.compile('[^%s]' % re.escape(string.printable))\n","    # normalize unicode characters\n","    #line = normalize('NFD', line).encode('ascii', 'ignore')\n","    #line = line.decode('UTF-8')\n","    # tokenize on white space\n","    line = line.split()\n","    # convert to lower case\n","    #line = [word.lower() for word in line]\n","    # remove punctuation from each token\n","    #line = [word.translate(table) for word in line]\n","    # remove non-printable chars form each token\n","    #line = [re_print.sub('', w) for w in line]\n","    if addSOS:\n","        line.insert(0, \"[SOS]\")\n","    line.append(\"[EOS]\")\n","    line = (' '.join(line))\n","    return line"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668729583912,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"},"user_tz":300},"id":"0RZiMDKqKXA7"},"outputs":[],"source":["def pairSentences(englishSentences, germanSentences):\n","    skips = [\"\", \".\"]\n","    pairs = []\n","    for i in range(len(englishSentences)):\n","        englishSentences[i] = cleanLine(englishSentences[i])\n","        germanSentences[i] = cleanLine(germanSentences[i], False)\n","        if englishSentences[i] in skips or germanSentences[i] in skips:\n","            continue\n","        enLen = len(englishSentences[i])\n","        deLen = len(germanSentences[i])\n","        \n","        if (enLen / deLen) > 10 or (deLen / enLen) > 10:\n","            print(len(englishSentences[i]))\n","            print(len(germanSentences[i]))\n","            print(\"English:\", englishSentences[i])\n","            print(\"German:\", germanSentences[i])\n","            continue\n","        if enLen <= 3 or deLen <= 3:\n","            continue\n","        pairs.append((englishSentences[i], germanSentences[i]))\n","    pairs = sorted(pairs, key=lambda x: len(x[0].split(\" \")))\n","    return pairs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kg0DiefSLHaq","executionInfo":{"status":"ok","timestamp":1668730070445,"user_tz":300,"elapsed":486537,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}},"outputId":"24d96e76-6123-496a-8879-d5f1710c6be8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"v9Fm8YcktIiG","executionInfo":{"status":"ok","timestamp":1668730070446,"user_tz":300,"elapsed":8,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def writeLinesWithNewLines(lines, fileName):\n","  file = open(fileName, \"w\")\n","  for line in lines:\n","    file.write(line + \"\\n\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lJJX6sAswBEu","executionInfo":{"status":"ok","timestamp":1668730070446,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def createDatasets(suffix = \".txt\", size=10000):\n","  enLines = to_sentences(load_doc(englishRawName))\n","  deLines = to_sentences(load_doc(germanRawName))\n","\n","  temp = list(zip(enLines, deLines))\n","  random.shuffle(temp)\n","  res1, res2 = zip(*temp)\n","  # res1 and res2 come out as tuples, and so must be converted to lists.\n","  enLines, deLines = list(res1)[:size], list(res2)[:size]\n","\n","  trainEnLines = enLines[:(int)(0.8*len(enLines))]\n","  testEnLines = enLines[(int)(0.8*len(enLines)):(int)(0.9*len(enLines))]\n","  valEnLines = enLines[(int)(0.9*len(enLines)):]\n","\n","  trainDeLines = deLines[:(int)(0.8*len(deLines))]\n","  testDeLines = deLines[(int)(0.8*len(deLines)):(int)(0.9*len(deLines))]\n","  valDeLines = deLines[(int)(0.9*len(deLines)):]\n","\n","  enFileNames = [enTrainingFileName, enTestFileName, enValFileName, enCombinedFileName]\n","  deFileNames = [deTrainingFileName, deTestFileName, deValFileName, deCombinedFileName]\n","\n","  enFileNames = [name + suffix for name in enFileNames]\n","  deFileNames = [name + suffix for name in deFileNames]\n","  enDatasets = [trainEnLines, testEnLines, valEnLines, enLines]\n","  deDatasets = [trainDeLines, testDeLines, valDeLines, deLines]\n","\n","  enPair = (enDatasets, enFileNames)\n","  dePair = (deDatasets, deFileNames)\n","\n","  for pair in [enPair, dePair]:\n","    for i in range(len(pair[0])):\n","      writeLinesWithNewLines(pair[0][i], pair[1][i])\n","  "]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3jRc_KSXPJny","executionInfo":{"status":"ok","timestamp":1668730070447,"user_tz":300,"elapsed":8,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def createTrainTestVal(numLines):\n","  trainEnLines = to_sentences(load_doc(enTrainingFileName))\n","  testEnLines = to_sentences(load_doc(enTestFileName))\n","  valEnLines = to_sentences(load_doc(enValFileName))\n","\n","  trainDeLines = to_sentences(load_doc(deTrainingFileName))\n","  testDeLines = to_sentences(load_doc(deTestFileName))\n","  valDeLines = to_sentences(load_doc(deValFileName))\n","\n","  trainEnLines, trainDeLines = \\\n","              zip(*random.sample(list(zip(trainEnLines, trainDeLines)), (int) (0.8 * numLines)))\n","  testEnLines, testDeLines = \\\n","              zip(*random.sample(list(zip(testEnLines, testDeLines)), (int)(0.1* numLines)))\n","  valEnLines, valDeLines = \\\n","              zip(*random.sample(list(zip(valEnLines, valDeLines)), (int)(0.1*numLines)))\n","\n","  enAll = trainEnLines + testEnLines + valEnLines\n","  deAll = trainDeLines + testDeLines + valDeLines\n","\n","  return trainEnLines, trainDeLines, testEnLines, testDeLines, valEnLines, valDeLines, enAll, deAll\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"npMpD1Mxhrwk","executionInfo":{"status":"ok","timestamp":1668730070447,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["# englishSentences = to_sentences(load_doc(englishRawName))\n","# germanSentences = to_sentences(load_doc(germanRawName))\n","\n","# temp = list(zip(englishSentences, germanSentences))\n","# random.shuffle(temp)\n","# res1, res2 = zip(*temp)\n","# # res1 and res2 come out as tuples, and so must be converted to lists.\n","# englishSentences, germanSentences = list(res1), list(res2)\n","\n","# writeLinesWithNewLines(englishSentences[:(int)(0.8*len(englishSentences))], folder + \"training.en\")\n","# writeLinesWithNewLines(germanSentences[:(int)(0.8*len(germanSentences))], folder + \"training.de\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DvPdS3gBmrk7","executionInfo":{"status":"ok","timestamp":1668730070447,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["# writeLinesWithNewLines(englishSentences[(int)(0.8*len(englishSentences)):(int)(0.9*len(englishSentences))], folder + \"test.en\")\n","# writeLinesWithNewLines(germanSentences[(int)(0.8*len(germanSentences)):(int)(0.9*len(germanSentences))], folder + \"test.de\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"rnmOOUGmnbC_","executionInfo":{"status":"ok","timestamp":1668730070447,"user_tz":300,"elapsed":6,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["# writeLinesWithNewLines(englishSentences[(int)(0.9*len(englishSentences)):], enVal)\n","# writeLinesWithNewLines(germanSentences[(int)(0.9*len(germanSentences)):], deVal)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pxOZ_X56KYCz","executionInfo":{"status":"ok","timestamp":1668730070447,"user_tz":300,"elapsed":6,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["import random\n","class SentenceDataset(Dataset):\n","    def __init__(self, enFileName, deFileName, newPairs = True):\n","        englishSentences = to_sentences(load_doc(enFileName))\n","        germanSentences = to_sentences(load_doc(deFileName))\n","        if not os.path.exists(pairsName) or newPairs:\n","            print(\"Creating pairs...\")\n","            #self.englishSentences, self.germanSentences = \\\n","             # zip(*random.sample(list(zip(self.englishSentences, self.germanSentences)), numLines))\n","            englishSentences = list(englishSentences)\n","            germanSentences = list(germanSentences)\n","            self.pairs = pairSentences(englishSentences, germanSentences)\n","            print(len(self.pairs))\n","            pickle.dump(self.pairs, open(pairsName, \"wb\"))\n","            # pickle.dump(englishSentences, open(truncEn, \"wb\"))\n","            # pickle.dump(germanSentences, open(truncDe, \"wb\"))\n","        else:\n","            # self.englishSentences = pickle.load(open(truncEn, \"rb\"))\n","            # self.germanSentences = pickle.load(open(truncDe, \"rb\"))\n","            print(\"Loading pairs...\")\n","            self.pairs = pickle.load(open(pairsName, \"rb\"))\n","        \n","    def __len__(self):\n","        return len(self.pairs)\n","    \n","    def __getitem__(self, index):\n","        return self.pairs[index]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-AIq72ayysCO","executionInfo":{"status":"ok","timestamp":1668730070448,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def setupTokenizers(enDataName, deDataName, newTokenizer = False, vocab_size_src=60000, vocab_size_tgt = 37000, enTokenizerName = folder+\"en10ktokenizer.pkl\", deTokenizerName = folder + \"de10ktokenizer.pkl\"):\n","  if not os.path.exists(enTokenizerName) or newTokenizer:\n","      print(\"creating en tokenizer...\")\n","      enTokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n","      enTokenizer.pre_tokenizer = Whitespace()\n","      trainer = BpeTrainer(vocab_size = vocab_size_src, special_tokens=[\"[SOS]\", \"[EOS]\", \"[PAD]\", \"[UNK]\"])\n","      enTokenizer.train([enDataName], trainer=trainer)\n","      pickle.dump(enTokenizer, open(enTokenizerName, \"wb\"))\n","  if not os.path.exists(deTokenizerName) or newTokenizer:\n","      print(\"creating de tokenizer...\")\n","      deTokenizer = Tokenizer(BPE())\n","      deTokenizer.pre_tokenizer = Whitespace()\n","      trainer = BpeTrainer(vocab_size = vocab_size_tgt, special_tokens=[\"[SOS]\", \"[EOS]\", \"[PAD]\", \"[UNK]\"])\n","      deTokenizer.train([deDataName], trainer=trainer)\n","      pickle.dump(deTokenizer, open(deTokenizerName, \"wb\"))\n","  else:\n","      print(\"Loading tokenizer...\")\n","      enTokenizer = pickle.load(open(enTokenizerName, \"rb\"))\n","      deTokenizer = pickle.load(open(deTokenizerName, \"rb\"))\n","  return enTokenizer, deTokenizer"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3chyfSXDKZSv","executionInfo":{"status":"ok","timestamp":1668730070448,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["import time\n","PADDING_IDX = 2\n","class PadCollate:\n","    \"\"\"\n","    a variant of callate_fn that pads according to the longest sequence in\n","    a batch of sequences\n","    \"\"\"\n","\n","    def __init__(self, enTokenizer, deTokenizer):\n","          self.enTokenizer = enTokenizer\n","          self.deTokenizer = deTokenizer\n","\n","    def pad_collate(self, batch):\n","        \"\"\"\n","        args:\n","            batch - list of (String, String)\n","\n","        reutrn:\n","            xs - a tensor of all examples in 'batch' after padding\n","            ys - a LongTensor of all labels in batch\n","        \"\"\"\n","        startTime = time.time()\n","        # find longest sequence\n","        Enlengths = [len(x[0].split(\" \")) for x in batch]\n","        #print(\"english lengths:\", Enlengths)\n","        Delengths = [len(x[1].split(\" \")) for x in batch]\n","        #print(\"german lengths:\", Delengths)\n","        max_len1 = max(Enlengths)\n","        max_len2 = max(Delengths)\n","        max_len = max([max_len1, max_len2])\n","        self.enTokenizer.enable_padding(pad_id = PADDING_IDX, pad_token=\"[PAD]\", length=max_len)\n","        self.enTokenizer.enable_truncation(max_length=max_len)\n","        self.deTokenizer.enable_padding(pad_id = PADDING_IDX, pad_token=\"[PAD]\", length=max_len)\n","        self.deTokenizer.enable_truncation(max_length=max_len)\n","        english = [pair[0] for pair in batch]\n","        german = [pair[1] for pair in batch]\n","        enTokens = [line.ids for line in self.enTokenizer.encode_batch(english)]\n","        deTokens = [line.ids for line in self.deTokenizer.encode_batch(german)]\n","        for i in range(len(deTokens)):\n","            deTokens[i].insert(0,0)\n","#         print(english[0])\n","#         print(german[0])\n","#         print(enTokens[0])\n","#         print(deTokens[0])\n","        englishEncoded = torch.IntTensor(enTokens)\n","        germanEncoded = torch.IntTensor(deTokens)\n","        #print(\"tokenization took\", time.time()-startTime)\n","        #print(\"englishEncoded\", englishEncoded)\n","        return englishEncoded, germanEncoded\n","\n","    def __call__(self, batch):\n","        return self.pad_collate(batch)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"p-raRF4xKall","executionInfo":{"status":"ok","timestamp":1668730070448,"user_tz":300,"elapsed":7,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class EmbeddingLayer(nn.Module):\n","    def __init__(self, vocabSize, embeddingSize, padding_idx):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocabSize, embeddingSize, padding_idx = padding_idx)\n","        self.embeddingSize = embeddingSize\n","        \n","    def forward(self, sentenceBatch):\n","        return self.embedding(sentenceBatch) * math.sqrt(self.embeddingSize)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Chq2BdfDKboq","executionInfo":{"status":"ok","timestamp":1668730070691,"user_tz":300,"elapsed":249,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout = 0.1, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n","        )\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n","        return self.dropout(x)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"DKLUvpHyKcqi","executionInfo":{"status":"ok","timestamp":1668730070691,"user_tz":300,"elapsed":6,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def attention(queries, keys, values, dropout, mask=None):\n","    keysTransposed = torch.transpose(keys, -2, -1)\n","    dotProduct = torch.matmul(queries, keysTransposed)\n","    scaledDotProduct = dotProduct / math.sqrt(keys.shape[-1])\n","    if mask is not None:\n","        weights = scaledDotProduct.masked_fill(mask == 0, -1e9)\n","    else:\n","        weights = scaledDotProduct\n","    \n","    weights = torch.softmax(weights, -1)\n","    weights = dropout(weights)\n","    finalProduct = torch.matmul(weights, values)\n","    return finalProduct"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"1CAx7GQEKdmM","executionInfo":{"status":"ok","timestamp":1668730070691,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, d_model, numHeads, dropout=0.1): # h is the number of heads\n","        super().__init__()\n","        self.d_model = d_model\n","        self.qWeight = nn.Linear(d_model, d_model)\n","        self.kWeight = nn.Linear(d_model, d_model)\n","        self.vWeight = nn.Linear(d_model, d_model)\n","        self.finalWeight = nn.Linear(d_model, d_model)\n","        self.numHeads = numHeads\n","        self.d_head = d_model // numHeads # we treat the input matrix as numHead d_head length heads\n","        self.dropout = nn.Dropout(p = dropout)\n","        # ex: 8 heads of length 64 for 512 embedding\n","        \n","    def forward(self, queries, keys, values, mask):\n","        #print(\"mask shape before squeeze:\", mask.shape)\n","        if mask is not None:\n","            # Same mask applied to all h heads.\n","            mask = mask.unsqueeze(1)\n","        #print(\"mask shape after squeeze:\", mask.shape)\n","        batchSize = queries.shape[0]\n","        # Send the queries, keys, and values through their corresponding linear layer\n","        # The dimensions should be unchanged\n","        queries = self.qWeight(queries).to(device)\n","        keys = self.kWeight(keys).to(device)\n","        values = self.vWeight(values).to(device)\n","        \n","        # Then treat the outputs of each linear layer as if they are numHead parts\n","        # ex: treat a batch of 50 sequence length x 512 embedding size matrices as \n","        # a batch of 50 sequence length x (8 heads x 64 head length) size matrices\n","        \n","        # the -1 is the sequence length, which is inferred\n","        queries = queries.reshape(batchSize, -1, self.numHeads, self.d_head)\n","        keys = keys.reshape(batchSize, -1, self.numHeads, self.d_head)\n","        values = values.reshape(batchSize, -1, self.numHeads, self.d_head)\n","        \n","        #print(\"query lin\", queries.shape)\n","        \n","        # Then swap the sequence length and number of heads dimensions\n","        queries = queries.transpose(1, 2)\n","        keys = keys.transpose(1, 2)\n","        values = values.transpose(1, 2)\n","        \n","        # Apply attention to this set of queries, keys, and values\n","        x = attention(queries, keys, values, self.dropout, mask)\n","        \n","        # Because we divided the queries, keys, and values into some number of heads, each head has a different value now\n","        # We need to combine all of these heads back into one matrix again before moving on\n","        x = x.transpose(1, 2) # put sequence length back into dimension 1 and num heads into dimension 2\n","        x = x.reshape(batchSize, -1, (self.numHeads * self.d_head)) # we're now back to our d_model embedding shape\n","        #print(\"shape after attention:\", x.shape)\n","        del queries\n","        del keys\n","        del values\n","        \n","        # Finally, put x through one last linear layer, just because\n","        x = self.finalWeight(x)\n","        return x\n","        "]},{"cell_type":"code","execution_count":25,"metadata":{"id":"oNB1YHSaKejb","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class FeedForwardNN(nn.Module):\n","    # This is just a two layer neural net.\n","    # The input and outputs are d_model, with one d_feedForward hidden layer\n","    # It uses relu for the hidden layer and linear for the output\n","    def __init__(self, d_model, d_feedForward, dropout=0.1):\n","        super().__init__()\n","        self.linear1 = nn.Linear(d_model, d_feedForward)\n","        self.linear2 = nn.Linear(d_feedForward, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = x.relu()\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x\n","        "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"P9r7Me2rKfSw","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    \"Construct a layernorm module (See citation for details).\"\n","    # Taken from http://nlp.seas.harvard.edu/annotated-transformer/\n","    # because I didn't feel like learning about layer normalization\n","\n","    def __init__(self, features, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.a_2 = nn.Parameter(torch.ones(features))\n","        self.b_2 = nn.Parameter(torch.zeros(features))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"0SIAp3-LKfQ9","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class Sublayer(nn.Module):\n","    # A sublayer is a wrapper around either a feed forward layer or multiheaded attention layer\n","    # It takes the output of either one of those and then adds the original input to it\n","    # It then does layer normalization to this sum\n","    def __init__(self, d_model, function, isAttentionLayer, dropout = 0.1):\n","        super().__init__()\n","        self.function = function # function is either feed foward or multiheaded attention\n","        self.layerNorm = LayerNorm(d_model)\n","        self.isAttentionLayer = isAttentionLayer\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x, mask=None, encoding=None):\n","        # The attention layer expects three inputs (queries, keys, values), not 1\n","        if self.isAttentionLayer:\n","            if encoding is None:\n","                sum_ = x + self.dropout(self.function(x, x, x, mask))\n","            else:\n","                sum_ = x + self.dropout(self.function(x, encoding, encoding, mask))\n","        else:\n","            sum_ = x + self.dropout(self.function(x))\n","            \n","        return self.layerNorm(sum_)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"VNJoM1O3Kh7c","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    # an encoder layer is two sublayers.\n","    # It goes through a sublayer containing the multiheaded attention and then a sublayer containing the feed forward layer\n","    def __init__(self, d_model, selfAttention, feedForward, dropout = 0.1):\n","        super().__init__()\n","        self.selfAttention = selfAttention\n","        self.feedForward = feedForward\n","        self.sublayer1 = Sublayer(d_model, self.selfAttention, True, dropout)\n","        self.sublayer2 = Sublayer(d_model, self.feedForward, False, dropout)\n","        \n","    def forward(self, x, mask):\n","        # put x through both sublayers\n","        x = self.sublayer1(x, mask)\n","        x = self.sublayer2(x, mask)\n","        return x"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"WFpP5s2qKi2H","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":4,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    # The encoder is a sequence of encoder layers\n","    def __init__(self, numLayers, d_model):\n","        self.d_model = d_model\n","        super().__init__()\n","        self.layers = []\n","        for i in range(numLayers):\n","            selfAttentionLayer = MultiHeadedAttention(d_model, 8)\n","            feedForwardLayer = FeedForwardNN(d_model, 2048)\n","            encoderLayer = EncoderLayer(d_model, selfAttentionLayer, feedForwardLayer)\n","            self.layers.append(encoderLayer)\n","        self.layers = nn.ModuleList(self.layers)\n","    \n","    def forward(self, x, mask):\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return x"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"7rcqAistKjrf","executionInfo":{"status":"ok","timestamp":1668730070692,"user_tz":300,"elapsed":4,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, selfAttention, encoderAttention, feedForward, dropout=0.1):\n","        super().__init__()\n","        self.selfAttention = selfAttention\n","        self.feedForward = feedForward\n","        self.encoderAttention = encoderAttention\n","        self.sublayer1 = Sublayer(d_model, self.selfAttention, True, dropout)\n","        self.sublayer2 = Sublayer(d_model, self.encoderAttention, True, dropout)\n","        self.sublayer3 = Sublayer(d_model, self.feedForward, False, dropout)\n","        \n","    def forward(self, x, encoding, src_mask, tgt_mask):\n","        x = self.sublayer1(x, tgt_mask)\n","        x = self.sublayer2(x, src_mask, encoding)\n","        x = self.sublayer3(x)\n","        return x"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"8W9lG-qLKkZq","executionInfo":{"status":"ok","timestamp":1668730070693,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    # The decoder is a sequence of decoder layers\n","    def __init__(self, numLayers, d_model):\n","        self.d_model = d_model\n","        super().__init__()\n","        self.layers = []\n","        for i in range(numLayers):\n","            selfAttentionLayer = MultiHeadedAttention(d_model, 8)\n","            encoderAttentionLayer = MultiHeadedAttention(d_model, 8)\n","            feedForwardLayer = FeedForwardNN(d_model, 2048)\n","            decoderLayer = DecoderLayer(d_model, selfAttentionLayer, encoderAttentionLayer, feedForwardLayer)\n","            self.layers.append(decoderLayer)\n","        self.layers = nn.ModuleList(self.layers)\n","        \n","    def forward(self, x, encoding, src_mask, tgt_mask):\n","        for layer in self.layers:\n","            x = layer(x, encoding, src_mask, tgt_mask)\n","            return x"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"M9Q3001HKlJ-","executionInfo":{"status":"ok","timestamp":1668730070693,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, d_model, vocab):\n","        super().__init__()\n","        self.proj = nn.Linear(d_model, vocab)\n","\n","    def forward(self, x):\n","        return log_softmax(self.proj(x), dim=-1)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"MZqkv2WhKl4V","executionInfo":{"status":"ok","timestamp":1668730070693,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class WholeNetwork(nn.Module):\n","    def __init__(self, d_model, d_vocab_src, d_vocab_tgt, padding_idx):\n","        super().__init__()\n","        self.embeddingSrc = EmbeddingLayer(d_vocab_src, d_model, padding_idx)\n","        self.embeddingTgt = EmbeddingLayer(d_vocab_tgt, d_model, padding_idx)\n","        self.posEncoding = PositionalEncoding(d_model, 0.1)\n","        self.encoder = Encoder(6, d_model)\n","        self.decoder = Decoder(6, d_model)\n","        self.generator = Generator(d_model, d_vocab_tgt)\n","\n","    def encode(self, src, src_mask):\n","        src = self.embeddingSrc(src)\n","        src = self.posEncoding(src)\n","        encodings = self.encoder(src, src_mask)\n","        return encodings\n","    \n","    def decode(self, encodings, tgt, src_mask, tgt_mask):\n","        tgt = self.embeddingTgt(tgt)\n","        tgt = self.posEncoding(tgt)\n","        output = self.decoder(tgt, encodings, src_mask, tgt_mask)\n","        return self.generator(output)\n","        \n","    def forward(self, src, tgt, src_mask, tgt_mask):\n","        encodings = self.encode(src, src_mask)\n","        return self.decode(encodings, tgt, src_mask, tgt_mask)\n","        \n","        "]},{"cell_type":"code","execution_count":34,"metadata":{"id":"nbhSsfshKmoi","executionInfo":{"status":"ok","timestamp":1668730070834,"user_tz":300,"elapsed":146,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def get_tgt_mask(size) -> torch.tensor:\n","    # Generates a squeare matrix where the each row allows one word more to be seen\n","    mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n","    mask = mask.float()\n","    mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n","    mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n","    return mask\n","    # EX for size=5:\n","    # [[0., -inf, -inf, -inf, -inf],\n","    #  [0.,   0., -inf, -inf, -inf],\n","    #  [0.,   0.,   0., -inf, -inf],\n","    #  [0.,   0.,   0.,   0., -inf],\n","    #  [0.,   0.,   0.,   0.,   0.]]"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"wgOJpr2jKnai","executionInfo":{"status":"ok","timestamp":1668730070835,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def decodeSentences(intTensor, tokenizer):\n","    intList = intTensor.tolist()\n","    #print(intList)\n","    sentences = tokenizer.decode_batch(intList)\n","    return sentences"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"gxXvUHlEKoFy","executionInfo":{"status":"ok","timestamp":1668730070835,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def subsequent_mask(size):\n","    \"Mask out subsequent positions.\"\n","    attn_shape = (1, size, size)\n","    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n","        torch.uint8\n","    )\n","    return subsequent_mask == 0"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"yNqIQb9TKo8M","executionInfo":{"status":"ok","timestamp":1668730070836,"user_tz":300,"elapsed":6,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def makeStdMask(tgt):\n","    tgt_mask = (tgt != PADDING_IDX).unsqueeze(-2)\n","    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n","    return tgt_mask"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"TnFFaqG846Uy","executionInfo":{"status":"ok","timestamp":1668730070836,"user_tz":300,"elapsed":6,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["def getLearningRate(d_model, stepNum, warmupSteps):\n","  stepNum += 19430 #67 epochs\n","  d_model = d_model ** -0.5\n","  min1 = stepNum ** -0.5 # was -0.5\n","  min2 = stepNum * (warmupSteps ** -1.5)\n","  return d_model * min(min1, min2)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"vKDzqN7X9ysV","executionInfo":{"status":"ok","timestamp":1668730070836,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["class LabelSmoothing(nn.Module):\n","    \"Implement label smoothing.\"\n","\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size\n","        self.true_dist = None\n","\n","    def forward(self, x, target):\n","        assert x.size(1) == self.size\n","        true_dist = x.data.clone()\n","        true_dist.fill_(self.smoothing / (self.size - 2))\n","        true_dist.scatter_(1, target.data.unsqueeze(1).long(), self.confidence)\n","        true_dist[:, self.padding_idx] = 0\n","        mask = torch.nonzero(target.data == self.padding_idx)\n","        if mask.dim() > 0:\n","            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","        self.true_dist = true_dist\n","        return self.criterion(x, true_dist.clone().detach())"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"TIaG856xOm-r","executionInfo":{"status":"ok","timestamp":1668730070836,"user_tz":300,"elapsed":5,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["#enTrain, deTrain, enTest, deTest, enVal, deVal, enAll, deAll = createTrainTestVal(10000)\n","#createDatasets(\"100k.txt\", 100000)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"xlacySijTqJ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668730073601,"user_tz":300,"elapsed":2770,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}},"outputId":"6b0cd3a6-4e6e-4029-f4b4-c8dc8ff8be94"},"outputs":[{"output_type":"stream","name":"stdout","text":["creating en tokenizer...\n","creating de tokenizer...\n"]}],"source":["suffix = \"100k.txt\"\n","#enTokenizer = pickle.load(open(\"en10ktokenizer.pkl\", \"rb\"))\n","#deTokenizer = pickle.load(open(\"de10ktokenizer.pkl\", \"rb\"))\n","enName = folder+\"enTokenizer.pkl\"\n","deName = folder+\"deTokenizer.pkl\"\n","enTokenizer, deTokenizer = setupTokenizers(enRawName, deRawName, True, 60000, 37000, enName, deName)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"4SJEqqKjKprj","executionInfo":{"status":"ok","timestamp":1668730073601,"user_tz":300,"elapsed":2,"user":{"displayName":"Jack Wittmayer","userId":"15582331673550347893"}}},"outputs":[],"source":["\n","def trainModel(epochs = 999, vocab_size_src = 60000, vocab_size_tgt = 37000, d_model=512, warmupSteps=4000, batchSize=64):\n","    suffix = \"100k.txt\"\n","    dataset = SentenceDataset(enRawName, deRawName, True)\n","\n","    train_dataloader = DataLoader(dataset, batch_size=batchSize, collate_fn =\n","                                  PadCollate(enTokenizer, deTokenizer))\n","    valDataset = SentenceDataset(en30kVal, de30kVal, True)\n","    val_dataloader = DataLoader(valDataset, batch_size=batchSize, collate_fn =\n","                                  PadCollate(enTokenizer, deTokenizer))\n","    val_dataloader_iter = iter(val_dataloader)\n","    dataloader_iter = iter(train_dataloader)\n","    losses = []\n","    valLosses = []\n","    startTime = time.time()\n","    i = 0\n","    model = WholeNetwork(d_model, vocab_size_src, vocab_size_tgt, PADDING_IDX)\n","    #model.load_state_dict(torch.load(folder + \"model_2vocab_11_12\"))\n","    model = model.to(device)\n","    # This was important from their code.\n","    # Initialize parameters with Glorot / fan_avg.\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    opt = optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n","    scheduler = optim.lr_scheduler.LambdaLR(opt, lambda step: getLearningRate(d_model, step+1, warmupSteps))\n","    labelSmoothing = LabelSmoothing(vocab_size_tgt, PADDING_IDX, 0.1)\n","    lowestAvgLoss = 100\n","    numFails = 0\n","    stepNum = 0\n","    print(\"Beginning training...\")\n","    for j in range(epochs):\n","        avgLossAtEpoch = 100\n","        lossSumForEpoch = 0\n","        dataloader_iter = iter(train_dataloader)\n","        val_dataloader_iter = iter(val_dataloader)\n","        i = 0\n","        startTime = time.time()\n","        for src, tgt in dataloader_iter:\n","            \n","            #print(\"Everything else time:\", time.time()-startTime)\n","            src, tgt = src.to(device), tgt.to(device)\n","            #tgt_x = tgt[:, :-1]\n","            #tgt_y = tgt[:, 1:]\n","            #print(tgt.shape)\n","            #src_mask = (src != PADDING_IDX).unsqueeze(-2)\n","            #tgt_mask = \n","            #print(tgt_mask[0])\n","            #print(tgt_mask.shape)\n","            #print(src.shape)\n","            #tgt_mask = get_tgt_mask(src.shape[1]).to(device)\n","            output = model(src, tgt[:, :-1], (src != PADDING_IDX).unsqueeze(-2), makeStdMask(tgt[:, :-1]))\n","            #output = torch.transpose(output, 1, 2)\n","            #print(output.shape)\n","            \n","            #loss = lossFunction(output.reshape((output.shape[0], output.shape[2], output.shape[1])), tgt_y.long())\n","            nonPadTokens = (tgt[:, 1:] != PADDING_IDX).data.sum()\n","            #print(output.shape)\n","            loss = labelSmoothing(output.contiguous().view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))/nonPadTokens\n","\n","            #lossMask = tgt_y != PADDING_IDX\n","            #print(\"loss before mask\", loss)\n","            #loss = loss.masked_fill(lossMask == 0, 0)\n","            #print(\"loss after mask\", loss)\n","            #loss = loss.sum()/lossMask.sum()\n","            #print(\"loss after sum\", loss)\n","            #print(lossMask)\n","            #loss *= lossMask\n","            #print(\"Loss calculation time:\", time.time()-startTime)\n","            #print(\"Loss:\", loss.item())\n","            losses.append(loss.item())\n","            lossSumForEpoch += loss.item()\n","            #startTime = time.time()\n","            #print(\"Model weights:\")\n","#             for param in model.parameters():\n","#                 print(param.data)\n","#                 break\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            scheduler.step()\n","            #print(\"opt step time:\", time.time()-startTime)\n","            startTime = time.time()\n","            argmaxOutput = torch.argmax(output, 2)\n","            stepNum += 1\n","            del loss\n","            #print(\"ARGMAX\")\n","            #print(argmaxOutput)\n","            i+=1\n","    #         if i > 20:\n","    #             break\n","        k = 0\n","        valLossSumForEpoch = 0\n","        for src, tgt2 in val_dataloader_iter:\n","            src, tgt2 = src.to(device), tgt2.to(device)\n","            output = model(src, tgt2[:, :-1], (src != PADDING_IDX).unsqueeze(-2), makeStdMask(tgt2[:, :-1]))\n","            nonPadTokens = (tgt2[:, 1:] != PADDING_IDX).data.sum()\n","            loss = labelSmoothing(output.contiguous().view(-1, output.size(-1)), tgt2[:, 1:].contiguous().view(-1))/nonPadTokens\n","            valLosses.append(loss.item())\n","            valLossSumForEpoch += loss.item()\n","            del loss\n","            k += 1\n","\n","        if i == 0:\n","          continue\n","\n","        avgLossAtEpoch = lossSumForEpoch / i\n","        avgValLossAtEpoch = valLossSumForEpoch / k\n","        if avgLossAtEpoch >= lowestAvgLoss:\n","            numFails += 1\n","        else:\n","            numFails = 0\n","            lowestAvgLoss = avgLossAtEpoch\n","        \n","        print(\"finished epoch\", j)\n","        #print(\"epoch time:\", time.time()-startTime)\n","        print(\"Average loss\", avgLossAtEpoch)\n","        print(\"Average val loss\", avgValLossAtEpoch)\n","        print(\"num fails:\", numFails)\n","        print(\"Predicted output: \")\n","        print(decodeSentences(argmaxOutput, deTokenizer)[0])\n","        print(\"Correct output: \")\n","        print(decodeSentences(tgt, deTokenizer)[0])\n","        print()\n","        print()\n","\n","        if numFails >= 5:\n","            break\n","        \n","        torch.save(model.state_dict(), folder + \"model_2vocab_11_12_2\")\n","        if stepNum >= 100000: # the model needs to stop training eventually...\n","          break\n","    plt.plot(losses)\n","    plt.show()\n","    return model\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2jyu454Kqja","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b1d0467-2643-4afb-f6a5-d481dc07c9e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating pairs...\n","29000\n","Creating pairs...\n","1014\n","Beginning training...\n","finished epoch 0\n","Average loss 4.012759544250724\n","Average val loss 4.018590480089188\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in die ein , auf hält ihnen einer von und , mit Hosen , einem Hosen , , einer Kamera , Jacke . und , einem weißen Hosen und und , , . und\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 1\n","Average loss 3.1981615841651276\n","Average val loss 3.857873797416687\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen , die sich und auf auf denen einer in und und ein Hosen und einem Haaren und , einem Kamera in Menschenmenge , Hemden . einem weißen Haaren weißen und und , , und\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 2\n","Average loss 2.9686647275470954\n","Average val loss 3.774867072701454\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die auf und und ein denen einer einer und und ein und , einem Hemden tragen , ein andere , weiße , und , einem weißen Hemden weißen und , und , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 3\n","Average loss 2.8005492897285764\n","Average val loss 3.708503931760788\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen , die in und und ein denen einer ein Hemden und ein Shorts , weißen Hemden tragen . weiße andere weiße weiße , Hemden , einem weißen Blumen Oberteil und und und und .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 4\n","Average loss 2.6573932296904172\n","Average val loss 3.676547959446907\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in die in und und einige denen einer tragen tragen und ein tragen mit weißen Hemden tragen , weiße andere weiße weiße weiße Hemden , einem weißen Hut schwarzen . . und . .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 5\n","Average loss 2.533396509250355\n","Average val loss 3.6835393458604813\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die sich und und einige denen einige eine Hemden und ein Shorts und weißen Westen tragen , weiße weiße weiße weiße weiße und mit einem weißen und Oberteil . . . . .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 6\n","Average loss 2.420375278867814\n","Average val loss 3.7268252074718475\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in die auf tragen und von einem einige tragen Hemden und eine Westen mit einer Hemden tragen , die andere große weiße weiße Hüte mit einem weißen , Oberteil . . . . .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 7\n","Average loss 2.315679843467763\n","Average val loss 3.776698961853981\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die im sitzen und von denen einige einen Hemden mit die Hemden und weißen Westen tragen , eine andere in weiße weiße Hüte mit einem roten , Oberteil und . . , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 8\n","Average loss 2.2191040812610003\n","Average val loss 3.820610299706459\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt die alle sitzen und von ihnen einige mit Hemden und eine Westen , weißen Hemden tragen und auf andere große flauschige weiße Hüte mit einem roten flauschigen Oberteil . . . auf .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 9\n","Average loss 2.130991891354716\n","Average val loss 3.860196530818939\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt die alle sitzen und von ihnen einige weiße Hemden und eine Westen mit gelben Schärpen tragen . die andere in flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . . , . .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 10\n","Average loss 2.0499865488859\n","Average val loss 3.8963484168052673\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die alle sitzen und von denen einige weiße Hemden und ein Westen mit gelben Schärpen tragen und die andere große weiße weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , . , .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 11\n","Average loss 1.971333836406338\n","Average val loss 3.922868713736534\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die alle sitzen und einige denen einige weiße Hemden und blaue Westen mit gelben Hemden tragen und die andere große flauschige weiße Hüte . einem pinkfarbenen flauschigen Oberteil . . , , .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 12\n","Average loss 1.9005860691553695\n","Average val loss 3.963409408926964\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die alle sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen . die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , .\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 13\n","Average loss 1.8321364809500489\n","Average val loss 3.979143440723419\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt die im sitzen und von Bäumen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , . ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 14\n","Average loss 1.7715353317197724\n","Average val loss 4.034944698214531\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die alle sitzen , von denen einige weiße Hunde , blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . im , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 15\n","Average loss 1.7207607213358522\n","Average val loss 4.074125304818153\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die im sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die Hände große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 16\n","Average loss 1.6722274458093265\n","Average val loss 4.121782273054123\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt die im sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Hemden tragen und eine andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 17\n","Average loss 1.6294685931720398\n","Average val loss 4.145160466432571\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt darunter in sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 18\n","Average loss 1.5901901476446227\n","Average val loss 4.1884018033742905\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht darunter alle sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 19\n","Average loss 1.5540121405135168\n","Average val loss 4.230281710624695\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht darunter alle sitzen und von denen einige weiße Hemden mit blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 20\n","Average loss 1.5225796830811689\n","Average val loss 4.25735068321228\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen steht die alle sitzen und von ihnen eine weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . auf , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 21\n","Average loss 1.494401722358712\n","Average val loss 4.251876428723335\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in darunter alle sitzen und einige denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen . die große große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . auf , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 22\n","Average loss 1.4673586789731938\n","Average val loss 4.261788964271545\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . im , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 23\n","Average loss 1.441194604803287\n","Average val loss 4.260608583688736\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen in darunter nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n","finished epoch 24\n","Average loss 1.4190278841010275\n","Average val loss 4.293110013008118\n","num fails: 0\n","Predicted output: \n","Ein Frau von Menschen sitzt darunter zusammen sitzen und von denen einige weiße Hemden und blaue Westen . gelben Schärpen tragen und eine andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil . , , , ,\n","Correct output: \n","Eine Gruppe von Menschen , die nebeneinander sitzen und von denen einige weiße Hemden und blaue Westen mit gelben Schärpen tragen und die andere große flauschige weiße Hüte mit einem pinkfarbenen flauschigen Oberteil .\n","\n","\n"]}],"source":["model = trainModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGcZk3N_Rbqc"},"outputs":[],"source":["# save the model\n","#pickle.dump(model, open(folder + \"size10kModel.pkl\", \"wb\"))\n","# enTokenizer = pickle.load(open(enTokenizerName, \"rb\"))\n","# deTokenizer = pickle.load(open(deTokenizerName, \"rb\"))\n","# pickle.dump(enTokenizer, open(folder + \"en10ktokenizer.pkl\", \"wb\"))\n","# pickle.dump(deTokenizer, open(folder + \"de10ktokenizer.pkl\", \"wb\"))\n","#torch.save(model.state_dict(), folder + \"size10Modell\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9iMrbV-pU3_"},"outputs":[],"source":["#model = WholeNetwork(512, 15000, 1).to(device)\n","#model.load_state_dict(torch.load(folder + \"size10Modell\"))\n","\n","#model = pickle.load(open(folder + \"size10kModel.pkl\", \"rb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqxT8ONhqDSW"},"outputs":[],"source":["import sys\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","def evalModel(srcVocab=60000, tgtVocab=37000):\n","  with torch.no_grad():\n","    model = WholeNetwork(512, srcVocab, tgtVocab, PADDING_IDX)\n","    model.load_state_dict(torch.load(folder + \"30kmodel3_2\", map_location=device))\n","    model = model.to(device)\n","    model.eval()\n","    #suffix = \"10k.txt\"\n","    bleuScores = []\n","    dataset = SentenceDataset(en30kVal, de30kVal, True)\n","\n","    train_dataloader = DataLoader(dataset, batch_size=100, collate_fn =\n","                                  PadCollate(enTokenizer, deTokenizer))\n","    dataloader_iter = iter(train_dataloader)\n","    i = 0\n","    #labelSmoothing = LabelSmoothing(vocab_size, PADDING_IDX, 0.1)\n","    numFails = 0\n","    print(\"Beginning training...\")\n","    avgLossAtEpoch = 100\n","    dataloader_iter = iter(train_dataloader)\n","    i = 0\n","    for src, tgt in dataloader_iter:\n","        \n","        #print(\"Everything else time:\", time.time()-startTime)\n","        src, tgt = src.to(device), tgt.to(device)\n","        tgt_x = tgt[:, :-1]\n","        tgt_y = tgt[:, 1:]\n","        #print(tgt.shape)\n","        src_mask = (src != PADDING_IDX).unsqueeze(-2)\n","        tgt_mask = makeStdMask(tgt_x)\n","        #print(tgt_mask[0])\n","        #print(tgt_mask.shape)\n","        #print(src.shape)\n","        #tgt_mask = get_tgt_mask(src.shape[1]).to(device)\n","        hyps = predictFromTokens(model, src, srcVocab, tgtVocab, 100)\n","        refs = decodeSentences(tgt_y, deTokenizer)\n","        refs = [[ref.split(\" \")] for ref in refs]\n","        hyps = [hyp.split(\" \") for hyp in hyps]\n","        \n","        print(refs)\n","        print(hyps)\n","        # print(len(argmaxOutput), len(tgt_y))\n","        bleu = corpus_bleu(refs, hyps)\n","        print(bleu)\n","        bleuScores.append(bleu)\n","        i+=1\n","  print(bleuScores)\n","\n","        #print(\"ARGMAX\")\n","        #print(argmaxOutput)\n","        \n","#         if i > 20:\n","#             break\n","        # predictions = decodeSentences(argmaxOutput, deTokenizer)[:5]\n","        # actual = decodeSentences(tgt, deTokenizer)[:5]\n","        # print(\"Predicted output: \")\n","        # print(predictions)\n","        # print(\"Correct output: \")\n","        # print(actual)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COpXWM_VslEX"},"outputs":[],"source":["#del model\n","\n","evalModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BkJ1C4ihIEB"},"outputs":[],"source":["def predictFromTokens(model, input, srcVocab, tgtVocab, maxLength):\n","  with torch.no_grad():\n","    predictions = []\n","    for line in input:\n","      line = line.reshape(1, line.shape[0])\n","      src_mask = (line != PADDING_IDX).unsqueeze(-2)\n","      encodings = model.encode(line, src_mask)\n","      output = \"[SOS]\"\n","      output = torch.IntTensor(deTokenizer.encode(output).ids)\n","      output = output.reshape(1, output.shape[0]).to(device)\n","      i = 0\n","      #print(input)\n","      # print(output)\n","      while i < maxLength: # while its not [EOS]\n","        tgt_mask = makeStdMask(output)\n","        # print(line.shape)\n","        # print(output.shape)\n","        prediction = model.decode(encodings, output, src_mask, tgt_mask)\n","        argmaxOutput = torch.argmax(prediction, -1)\n","        #print(argmaxOutput.shape)\n","        #print(argmaxOutput)\n","        if argmaxOutput == 1:\n","          predictions.append(decodeSentences(output, deTokenizer)[0])\n","          break\n","        \n","        #print(output.shape)\n","        \n","        output = torch.cat((output, argmaxOutput.reshape((1,1))), -1)\n","        #print(decodeSentences(output, deTokenizer))\n","        #print(output.shape)\n","        i+=1\n","  return predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTIojMT2NcJp"},"outputs":[],"source":["def predict(model, input, vocab_size, maxLength):\n","  with torch.no_grad():\n","\n","    input += \"[EOS]\"\n","    input = torch.IntTensor(enTokenizer.encode(input).ids)\n","    input = input.reshape(1, input.shape[0]).to(device)\n","    output = \"[SOS]\"\n","    output = torch.IntTensor(deTokenizer.encode(output).ids)\n","    output = output.reshape(1, output.shape[0]).to(device)\n","    i = 0\n","    #print(input)\n","   # print(output)\n","    while i < maxLength: # while its not [EOS]\n","      src_mask = (input != PADDING_IDX).unsqueeze(-2)\n","      tgt_mask = makeStdMask(output)\n","      prediction = model(input, output, src_mask, tgt_mask)[0, -1]\n","      argmaxOutput = torch.argmax(prediction, -1)\n","      #print(argmaxOutput.shape)\n","      #print(argmaxOutput)\n","      if argmaxOutput == 1:\n","        print(decodeSentences(output, deTokenizer))\n","        break\n","      i+=1\n","      #print(output.shape)\n","      \n","      output = torch.cat((output, argmaxOutput.reshape((1,1))), -1)\n","      print(decodeSentences(output, deTokenizer))\n","      #print(output.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXTnO0KGep0y"},"outputs":[],"source":["model = WholeNetwork(512, 60000, 37000, PADDING_IDX)\n","model.load_state_dict(torch.load(folder + \"30kmodel3_2\", map_location=device))\n","model = model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctVcFr1TTc2Y"},"outputs":[],"source":["predict(model, \"adsfasdfas.\", 15000, 30)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPmpH5KYCBLmZqHzzUyavbn"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}