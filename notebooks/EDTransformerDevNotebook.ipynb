{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtjKRJFcYDs53qraulWwHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackWittmayer/Transformer-Implementation/blob/main/EDTransformerDevNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was used when first implementing and training the model. I have since moved the code into individual files, making this notebook out of date.\n",
        "\n",
        "I am keeping it around because it's useful to see the history of it.\n",
        "\n",
        "If you want to run a notebook in colab with the new files, use EDTransformer.ipynb."
      ],
      "metadata": {
        "id": "UsBeif7mN0Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37L0J9nog5yz",
        "outputId": "28598621-bc1f-4c40-f0ff-0e61e7ad2e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNf0Rr3ogy-4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "import pickle\n",
        "from unicodedata import normalize\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(25)\n",
        "random.seed(25)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2Hs0kEZYlwc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a95f7e-cb7a-4d2d-a392-764d262463a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        embeddings = self.table(sequence)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "Pk7xtwam89Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unembedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.weight(x)"
      ],
      "metadata": {
        "id": "EpoJIpc_CaX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_size, max_sequence_length, device):\n",
        "        super().__init__()\n",
        "        self.table = nn.Embedding(max_sequence_length, embedding_size)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        positions = torch.zeros(sequence.shape, dtype=torch.int32).to(self.device)\n",
        "        positions[:, ::] = torch.arange(0, sequence.shape[-1])\n",
        "        positional_embeddings = self.table(positions)\n",
        "        return positional_embeddings"
      ],
      "metadata": {
        "id": "5xpYM9Zf_KLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskStrategy(Enum):\n",
        "    UNMASKED = 1\n",
        "    MASKED = 2\n",
        "\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads,\n",
        "        d_attn,\n",
        "        d_x,\n",
        "        d_z,\n",
        "        d_out,\n",
        "        d_mid,\n",
        "        maskStrategy,\n",
        "        p_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_attn = d_attn\n",
        "        self.d_x = d_x\n",
        "        self.d_z = d_z\n",
        "        self.d_out = d_out\n",
        "        self.d_mid = d_mid\n",
        "        self.maskStrategy = maskStrategy\n",
        "        self.weight_query = nn.Linear(d_x, d_attn)\n",
        "        self.weight_key = nn.Linear(d_z, d_attn)\n",
        "        self.weight_value = nn.Linear(d_z, d_mid)\n",
        "        self.weight_out = nn.Linear(d_mid, d_out)\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "    def forward(self, z, x, padding_mask):\n",
        "        length_z = z.shape[-2]\n",
        "        length_x = x.shape[-2]\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        queries = (\n",
        "            self.weight_query(x)\n",
        "            .view(batch_size, length_x, self.num_heads, -1)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "        keys = (\n",
        "            self.weight_key(z)\n",
        "            .view(batch_size, length_z, self.num_heads, -1)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "        values = (\n",
        "            self.weight_value(z)\n",
        "            .view(batch_size, length_z, self.num_heads, -1)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "\n",
        "        assert queries.shape == (\n",
        "            batch_size,\n",
        "            self.num_heads,\n",
        "            length_x,\n",
        "            self.d_attn / self.num_heads,\n",
        "        )\n",
        "        assert keys.shape == (\n",
        "            batch_size,\n",
        "            self.num_heads,\n",
        "            length_z,\n",
        "            self.d_attn / self.num_heads,\n",
        "        )\n",
        "        assert values.shape == (\n",
        "            batch_size,\n",
        "            self.num_heads,\n",
        "            length_z,\n",
        "            self.d_mid / self.num_heads,\n",
        "        )\n",
        "\n",
        "        if self.maskStrategy == MaskStrategy[\"UNMASKED\"]:\n",
        "            mask = padding_mask.unsqueeze(-2)\n",
        "        elif self.maskStrategy == MaskStrategy[\"MASKED\"]:\n",
        "            padding_mask = padding_mask.unsqueeze(-2)\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device(\"cuda\")\n",
        "            elif torch.backends.mps.is_available():\n",
        "                device = torch.device(\"mps\")\n",
        "            else:\n",
        "                device = torch.device(\"cpu\")\n",
        "            mask = torch.tril(torch.ones(length_x, length_z) == 1).to(device)\n",
        "            # logging.debug(f\"{padding_mask.shape=}\")\n",
        "            # logging.debug(f\"{mask=}\")\n",
        "            mask = mask & padding_mask\n",
        "            # logging.debug(f\"{mask=}\")\n",
        "        mask = mask.unsqueeze(1)\n",
        "        # logging.debug(f\"{mask=}\")\n",
        "        # logging.debug(f\"{mask.shape=}\")\n",
        "        v_out = self.attention(queries, keys, values, mask, self.dropout)\n",
        "        # logging.debug(f\"{v_out.shape=}\")\n",
        "        assert v_out.shape == (\n",
        "            batch_size,\n",
        "            self.num_heads,\n",
        "            length_x,\n",
        "            self.d_mid / self.num_heads,\n",
        "        )\n",
        "        # logging.debug(f\"{v_out=}\")\n",
        "        # logging.debug(f\"{v_out.shape=}\")\n",
        "        v_out = v_out.transpose(1, 2).reshape(batch_size, length_x, -1)\n",
        "        # logging.debug(f\"{v_out.shape=}\")\n",
        "        # logging.debug(f\"{v_out=}\")\n",
        "        output = self.weight_out(v_out)\n",
        "        # logging.debug(f\"{output.shape=}\")\n",
        "        assert output.shape == (batch_size, length_x, self.d_out)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(queries, keys, values, mask, dropout):\n",
        "        # logging.debug(f\"{queries=}\")\n",
        "        # logging.debug(f\"{keys=}\")\n",
        "        # logging.debug(f\"{values=}\")\n",
        "        keys_transposed = torch.transpose(keys, -2, -1)\n",
        "        # logging.debug(f\"{keys_transposed=}\")\n",
        "        scores = torch.matmul(queries, keys_transposed)\n",
        "        # assert scores.shape == (keys.shape[0], keys.shape[-1], queries.shape[-1])\n",
        "        # logging.debug(f\"{scores=}\")\n",
        "        # logging.debug(f\"{scores.shape=}\")\n",
        "        # logging.debug(f\"{mask.shape=}\")\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        # logging.debug(f\"{scores=}\")\n",
        "        d_attn = keys.shape[-1]\n",
        "        scaled_scores = scores / math.sqrt(d_attn)\n",
        "        # logging.debug(f\"{scaled_scores=}\")\n",
        "        softmax_scores = torch.softmax(scaled_scores, -1)\n",
        "        softmax_scores = dropout(softmax_scores)\n",
        "        # logging.debug(f\"{softmax_scores=}\")\n",
        "        # logging.debug(f\"{softmax_scores.shape=}\")\n",
        "        # logging.debug(f\"{values=}\")\n",
        "        v_out = torch.matmul(softmax_scores, values)\n",
        "        return v_out\n",
        "\n",
        "    def disable_subsequent_mask(self):\n",
        "        self.maskStrategy = MaskStrategy[\"UNMASKED\"]\n",
        "\n",
        "    def enable_subsequent_mask(self):\n",
        "        self.maskStrategy = MaskStrategy[\"MASKED\"]\n"
      ],
      "metadata": {
        "id": "DL3t3E_ThGF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, feature_length):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.ones(feature_length))\n",
        "        self.offset = nn.Parameter(torch.zeros(feature_length))\n",
        "\n",
        "    def forward(self, activations):\n",
        "        mean = torch.mean(activations, -1, keepdim=True)\n",
        "        variance = torch.var(activations, -1, keepdim=True, unbiased=False)\n",
        "        normalized_activations = (activations - mean) / torch.sqrt(variance + 1e-6)\n",
        "        return (normalized_activations * self.scale) + self.offset"
      ],
      "metadata": {
        "id": "-Si4-i6PTlFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, hiddenLayerWidth, d_e, p_dropout):\n",
        "        super().__init__()\n",
        "        self.mlp1 = nn.Parameter(torch.rand(d_e, hiddenLayerWidth))\n",
        "        self.mlp2 = nn.Parameter(torch.rand(hiddenLayerWidth, d_e))\n",
        "        self.mlp1_bias = nn.Parameter(torch.zeros(hiddenLayerWidth))\n",
        "        self.mlp2_bias = nn.Parameter(torch.zeros(d_e))\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "    def forward(self, activations):\n",
        "        activations = torch.matmul(activations, self.mlp1) + self.mlp1_bias\n",
        "        activations = activations.relu()\n",
        "        activations = torch.matmul(activations, self.mlp2) + self.mlp2_bias\n",
        "        activations = self.dropout(activations)\n",
        "        return activations"
      ],
      "metadata": {
        "id": "X7rAEAkFoNI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, p_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.multi_head_attention = MultiHeadedAttention(\n",
        "            num_heads,\n",
        "            d_attn,\n",
        "            d_x,\n",
        "            d_z,\n",
        "            d_out,\n",
        "            d_mid,\n",
        "            MaskStrategy[\"UNMASKED\"],\n",
        "            p_dropout\n",
        "        )\n",
        "        self.layer_norm1 = LayerNorm(d_z)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_z, p_dropout)\n",
        "        self.layer_norm2 = LayerNorm(d_z)\n",
        "\n",
        "    def forward(self, z, padding_mask):\n",
        "        z = self.layer_norm1(z)\n",
        "        z = z + self.multi_head_attention(z, z, padding_mask)\n",
        "        z = self.layer_norm2(z)\n",
        "        z = z + self.feed_forward(z)\n",
        "        return z\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        num_heads,\n",
        "        d_attn,\n",
        "        d_x,\n",
        "        d_z,\n",
        "        d_out,\n",
        "        d_mid,\n",
        "        d_mlp,\n",
        "        p_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            encoder_layer = EncoderLayer(\n",
        "                num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, p_dropout\n",
        "            )\n",
        "            self.layers.append(encoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "        self.final_norm = LayerNorm(d_z)\n",
        "\n",
        "    def forward(self, z, padding_mask):\n",
        "        for layer in self.layers:\n",
        "            z = layer(z, padding_mask)\n",
        "        return self.final_norm(z)\n"
      ],
      "metadata": {
        "id": "ikM15oD-qghT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self, num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, p_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.multi_head_self_attention = MultiHeadedAttention(\n",
        "            num_heads,\n",
        "            d_attn,\n",
        "            d_x,\n",
        "            d_z,\n",
        "            d_out,\n",
        "            d_mid,\n",
        "            MaskStrategy[\"MASKED\"],\n",
        "            p_dropout\n",
        "        )\n",
        "        self.layer_norm1 = LayerNorm(d_x)\n",
        "        self.multi_head_global_attention = MultiHeadedAttention(\n",
        "            num_heads,\n",
        "            d_attn,\n",
        "            d_x,\n",
        "            d_z,\n",
        "            d_out,\n",
        "            d_mid,\n",
        "            MaskStrategy[\"UNMASKED\"],\n",
        "            p_dropout\n",
        "        )\n",
        "        self.layer_norm2 = LayerNorm(d_x)\n",
        "        self.feed_forward = FeedForward(d_mlp, d_x, p_dropout)\n",
        "        self.layer_norm3 = LayerNorm(d_x)\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        x = self.layer_norm1(x)\n",
        "        x = x + self.multi_head_self_attention(x, x, tgt_mask)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = x + self.multi_head_global_attention(z, x, src_mask)\n",
        "        x = self.layer_norm3(x)\n",
        "        x = x + self.feed_forward(x)\n",
        "        return x\n",
        "\n",
        "    def disable_subsequent_mask(self):\n",
        "        self.multi_head_self_attention.disable_subsequent_mask()\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        num_heads,\n",
        "        d_attn,\n",
        "        d_x,\n",
        "        d_z,\n",
        "        d_out,\n",
        "        d_mid,\n",
        "        d_mlp,\n",
        "        p_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            decoder_layer = DecoderLayer(\n",
        "                num_heads, d_attn, d_x, d_z, d_out, d_mid, d_mlp, p_dropout\n",
        "            )\n",
        "            self.layers.append(decoder_layer)\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "        self.final_norm = LayerNorm(d_x)\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(z, x, src_mask, tgt_mask)\n",
        "        return self.final_norm(x)\n",
        "\n",
        "    def disable_subsequent_mask(self):\n",
        "        for layer in self.layers:\n",
        "            layer.multi_head_self_attention.disable_subsequent_mask()\n"
      ],
      "metadata": {
        "id": "GSqElGm56xaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        num_heads,\n",
        "        d_attn,\n",
        "        d_x,\n",
        "        d_z,\n",
        "        d_out,\n",
        "        d_mid,\n",
        "        d_mlp,\n",
        "        d_e,\n",
        "        vocab_size,\n",
        "        max_sequence_length,\n",
        "        p_dropout,\n",
        "        device\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.src_embedding = Embedding(vocab_size, d_e)\n",
        "        self.tgt_embedding = Embedding(vocab_size, d_e)\n",
        "        self.unembedding = Unembedding(vocab_size, d_e)\n",
        "        self.embedding_dropout = nn.Dropout(p_dropout)\n",
        "        self.positionalEmbedding = PositionalEmbedding(d_e, max_sequence_length, device)\n",
        "        self.encoder = Encoder(\n",
        "            num_encoder_layers,\n",
        "            num_heads,\n",
        "            d_attn,\n",
        "            d_x,\n",
        "            d_z,\n",
        "            d_out,\n",
        "            d_mid,\n",
        "            d_mlp,\n",
        "            p_dropout\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            num_decoder_layers,\n",
        "            num_heads,\n",
        "            d_attn,\n",
        "            d_x,\n",
        "            d_z,\n",
        "            d_out,\n",
        "            d_mid,\n",
        "            d_mlp,\n",
        "            p_dropout\n",
        "        )\n",
        "\n",
        "    def forward(self, z, x, src_mask, tgt_mask):\n",
        "        z = self.src_embedding(z) + self.positionalEmbedding(z)\n",
        "        z = self.embedding_dropout(z)\n",
        "        z = self.encoder(z, src_mask)\n",
        "        x = self.tgt_embedding(x) + self.positionalEmbedding(x)\n",
        "        x = self.embedding_dropout(x)\n",
        "        x = self.decoder(z, x, src_mask, tgt_mask)\n",
        "        x = self.unembedding(x)\n",
        "        return x\n",
        "\n",
        "    def disable_subsequent_mask(self):\n",
        "        self.decoder.disable_subsequent_mask()\n"
      ],
      "metadata": {
        "id": "ixXJDrPF8RU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc6Y11QfhEAv",
        "outputId": "b1e4d86d-a461-412c-95a5-a731a6342bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SequencePairDataset(Dataset):\n",
        "    BOS_TOKEN = \"[SOS]\"\n",
        "    EOS_TOKEN = \"[EOS]\"\n",
        "    PAD_TOKEN = \"[PAD]\"\n",
        "    UNK_TOKEN = \"[UNK]\"\n",
        "    PAD_ID = 2\n",
        "\n",
        "    def __init__(self, src_text, tgt_text, start_index, end_index):\n",
        "        src_sequences = self.to_sequences(src_text, start_index, end_index)\n",
        "        # tgt_sequences = self.to_sequences(tgt_text, start_index, end_index)\n",
        "        tgt_sequences = self.to_sequences(tgt_text, start_index, end_index)\n",
        "        # src_sequences = [self.add_special_tokens(sequence) for sequence in src_sequences]\n",
        "        # tgt_sequences = [self.add_special_tokens(sequence) for sequence in tgt_sequences]\n",
        "        self.pairs = self.pair_sequences(src_sequences, tgt_sequences)\n",
        "\n",
        "    def pair_sequences(self, src_sequences, tgt_sequences):\n",
        "        paired_sequences = list(zip(src_sequences, tgt_sequences))\n",
        "        sorted_pairs = sorted(paired_sequences, key=lambda x: len(x[0]))\n",
        "        return sorted_pairs\n",
        "\n",
        "    # split a loaded document into sequences\n",
        "    def to_sequences(self, doc, sequence_start_index, sequence_end_index):\n",
        "        sequences = doc.strip().split(\"\\n\")\n",
        "        return sequences[sequence_start_index:sequence_end_index]\n",
        "\n",
        "    def add_special_tokens(self, sequence):\n",
        "        sequence = self.BOS_TOKEN + \" \" + sequence + \" \" + self.EOS_TOKEN\n",
        "        return sequence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_seq, tgt_seq = self.pairs[index]\n",
        "        return src_seq, tgt_seq"
      ],
      "metadata": {
        "id": "vVeybRtnKtJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainAndValidationSequenceDatasets:\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_filename,\n",
        "        tgt_filename,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        train_start_index,\n",
        "        train_end_index,\n",
        "        val_start_index,\n",
        "        val_end_index,\n",
        "    ):\n",
        "        src_text = self.load_doc(src_filename)\n",
        "        tgt_text = self.load_doc(tgt_filename)\n",
        "        self.train_dataset = SequencePairDataset(\n",
        "            src_text, tgt_text, train_start_index, train_end_index\n",
        "        )\n",
        "        self.val_dataset = SequencePairDataset(\n",
        "            src_text, tgt_text, val_start_index, val_end_index\n",
        "        )\n",
        "\n",
        "        # load doc into memory\n",
        "\n",
        "    def load_doc(self, filename):\n",
        "        # open the file as read only\n",
        "        file = open(filename, mode=\"rt\")\n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        # close the file\n",
        "        file.close()\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "IJciEqbpJajo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PadCollate:\n",
        "    TOKENIZER_SUFFIX = \"_tokenizer\"\n",
        "\n",
        "    def __init__(self, src_filename, tgt_filename, src_vocab_size, tgt_vocab_size):\n",
        "        self.src_tokenizer, self.tgt_tokenizer = self.setup_tokenizers(\n",
        "            src_filename,\n",
        "            tgt_filename,\n",
        "            src_vocab_size,\n",
        "            tgt_vocab_size,\n",
        "            src_filename + self.TOKENIZER_SUFFIX,\n",
        "            tgt_filename + self.TOKENIZER_SUFFIX,\n",
        "        )\n",
        "\n",
        "    def setup_tokenizers(\n",
        "        self,\n",
        "        src_filename,\n",
        "        tgt_filename,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        src_tokenizer_name,\n",
        "        tgt_tokenizer_name,\n",
        "    ):\n",
        "        print(\"creating tokenizer for \" + src_filename)\n",
        "        src_tokenizer = Tokenizer(BPE(unk_token=SequencePairDataset.UNK_TOKEN))\n",
        "        src_tokenizer.pre_tokenizer = Whitespace()\n",
        "        # src_tokenizer.post_processor = TemplateProcessing(\n",
        "        #     single=\"[BOS] $A [EOS]\",\n",
        "        #     special_tokens=[(\"[BOS]\", 0), (\"[EOS]\", 1)],\n",
        "        # )\n",
        "        trainer = BpeTrainer(\n",
        "            vocab_size=src_vocab_size,\n",
        "            special_tokens=[\n",
        "                SequencePairDataset.BOS_TOKEN,\n",
        "                SequencePairDataset.EOS_TOKEN,\n",
        "                SequencePairDataset.PAD_TOKEN,\n",
        "                SequencePairDataset.UNK_TOKEN,\n",
        "            ],\n",
        "        )\n",
        "        src_tokenizer.train([src_filename], trainer=trainer)\n",
        "        pickle.dump(src_tokenizer, open(src_tokenizer_name, \"wb\"))\n",
        "\n",
        "        print(\"creating tokenizer for \" + tgt_filename)\n",
        "        tgt_tokenizer = Tokenizer(BPE(unk_token=SequencePairDataset.UNK_TOKEN))\n",
        "        tgt_tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(\n",
        "            vocab_size=tgt_vocab_size,\n",
        "            special_tokens=[\n",
        "                SequencePairDataset.BOS_TOKEN,\n",
        "                SequencePairDataset.EOS_TOKEN,\n",
        "                SequencePairDataset.PAD_TOKEN,\n",
        "                SequencePairDataset.UNK_TOKEN,\n",
        "            ],\n",
        "        )\n",
        "        tgt_tokenizer.train([tgt_filename], trainer=trainer)\n",
        "        tgt_tokenizer.post_processor = TemplateProcessing(\n",
        "            single=\"[BOS] $A [EOS]\",\n",
        "            special_tokens=[(\"[BOS]\", 0), (\"[EOS]\", 1)],\n",
        "        )\n",
        "        pickle.dump(tgt_tokenizer, open(tgt_tokenizer_name, \"wb\"))\n",
        "        return src_tokenizer, tgt_tokenizer\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # max_len_src = max([len(pair[0].split()) for pair in batch])\n",
        "        # max_len_tgt = max([len(pair[1].split()) for pair in batch])\n",
        "\n",
        "        # tgt_sequence_lengths\n",
        "\n",
        "        self.src_tokenizer.no_padding()\n",
        "        self.tgt_tokenizer.no_padding()\n",
        "\n",
        "        self.src_tokenizer.no_truncation()\n",
        "        self.tgt_tokenizer.no_truncation()\n",
        "\n",
        "        src_tokenized = self.src_tokenizer.encode_batch([pair[0] for pair in batch])\n",
        "        tgt_tokenized = self.tgt_tokenizer.encode_batch([pair[1] for pair in batch])\n",
        "\n",
        "        max_len_src = max([len(sequence) for sequence in src_tokenized])\n",
        "        max_len_tgt = max([len(sequence) for sequence in tgt_tokenized])\n",
        "\n",
        "        # print(\"max len src:\", max_len_src)\n",
        "        # print(\"max len tgt:\", max_len_tgt)\n",
        "\n",
        "        self.src_tokenizer.enable_padding(\n",
        "            pad_id=SequencePairDataset.PAD_ID, pad_token=SequencePairDataset.PAD_TOKEN\n",
        "        )\n",
        "        self.src_tokenizer.enable_truncation(max_length=max_len_src)\n",
        "        self.tgt_tokenizer.enable_padding(\n",
        "            pad_id=SequencePairDataset.PAD_ID, pad_token=SequencePairDataset.PAD_TOKEN\n",
        "        )\n",
        "        self.tgt_tokenizer.enable_truncation(max_length=max_len_tgt)\n",
        "\n",
        "        # print(\"src batch:\", [pair[0] for pair in batch])\n",
        "        # print(\"tgt batch:\", [pair[1] for pair in batch])\n",
        "\n",
        "        src_tokenized = self.src_tokenizer.encode_batch([pair[0] for pair in batch])\n",
        "        tgt_tokenized = self.tgt_tokenizer.encode_batch([pair[1] for pair in batch])\n",
        "        # src_tokenized = [sequence.ids for sequence in src_tokenized]\n",
        "        # tgt_tokenized = [sequence.ids for sequence in tgt_tokenized]\n",
        "        # src_tensors = torch.IntTensor(src_tokenized)\n",
        "        # tgt_tensor = torch.IntTensor(tgt_tokenized)\n",
        "\n",
        "        return src_tokenized, tgt_tokenized\n"
      ],
      "metadata": {
        "id": "P1wzP-DDLZ1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(x, tokenizer):\n",
        "    x = torch.softmax(x, -1)\n",
        "    # print(\"x softmax:\", x)\n",
        "    x = torch.argmax(x, dim=-1)\n",
        "    x = x.tolist()\n",
        "    print(\"argmax x:\", x)\n",
        "    return tokenizer.decode(x)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    encoder_decoder_transformer,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    src_tokenizer,\n",
        "    tgt_tokenizer,\n",
        "    device,\n",
        "    state_dict_filename\n",
        "):\n",
        "    torch.manual_seed(25)\n",
        "\n",
        "    epochs = 1000\n",
        "    print(encoder_decoder_transformer.parameters())\n",
        "    opt = optim.AdamW(\n",
        "        encoder_decoder_transformer.parameters(), lr=0.0001, weight_decay=0.0001\n",
        "    )\n",
        "    loss_function = nn.CrossEntropyLoss(label_smoothing=0.1, ignore_index=2)\n",
        "    # labelSmoothing = LabelSmoothing(2000, PADDING_IDX, 0.1)\n",
        "    training_step = 0\n",
        "    validation_step = 0\n",
        "    best_val_loss = 100\n",
        "    num_fails = 0\n",
        "    # Large models need this to actually train\n",
        "    for p in encoder_decoder_transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    for i in range(epochs):\n",
        "        epoch_time_start = time.time()\n",
        "        dataloader_iter = iter(train_dataloader)\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        for src_batch, tgt_batch in dataloader_iter:\n",
        "            # print(\"x:\", sequence_x)\n",
        "            # print(\"z:\", sequence_z)\n",
        "            # sequence_x, sequence_z = sequenceDataset.__getitem__(i)\n",
        "            src_tokens = torch.IntTensor([sequence.ids for sequence in src_batch]).to(\n",
        "                device\n",
        "            )\n",
        "            encoder_input = src_tokens\n",
        "            train_tgt_tokens = torch.IntTensor(\n",
        "                [sequence.ids for sequence in tgt_batch]\n",
        "            ).to(device)\n",
        "            decoder_input = train_tgt_tokens[:, :-1]\n",
        "            decoder_desired_output_train = train_tgt_tokens[:, 1:]\n",
        "            src_masks = torch.IntTensor(\n",
        "                [sequence.attention_mask for sequence in src_batch]\n",
        "            ).to(device)\n",
        "            tgt_masks = torch.IntTensor(\n",
        "                [sequence.attention_mask for sequence in tgt_batch]\n",
        "            )[:, :-1].to(device)\n",
        "            # print(\"src masks\", src_masks)\n",
        "            # print(\"tgt masks\", tgt_masks)\n",
        "            train_output = encoder_decoder_transformer(\n",
        "                encoder_input, decoder_input, src_masks, tgt_masks\n",
        "            )\n",
        "            # print(\"output\", train_output)\n",
        "            output_transpose = train_output.transpose(\n",
        "                -1, -2\n",
        "            )  # output needs to be N, C, other dimension for torch cross entropy\n",
        "            loss = loss_function(output_transpose, decoder_desired_output_train.long())\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            train_losses.append(loss.item())\n",
        "            if training_step % 20 == 0:\n",
        "                print(\"Completed training step\", training_step)\n",
        "            training_step += 1\n",
        "\n",
        "        for src_batch, tgt_batch in val_dataloader:\n",
        "            src_tokens = torch.IntTensor([sequence.ids for sequence in src_batch]).to(\n",
        "                device\n",
        "            )\n",
        "            encoder_input = src_tokens\n",
        "            val_tgt_tokens = torch.IntTensor(\n",
        "                [sequence.ids for sequence in tgt_batch]\n",
        "            ).to(device)\n",
        "            decoder_input = val_tgt_tokens[:, :-1]\n",
        "            decoder_desired_output_val = val_tgt_tokens[:, 1:]\n",
        "            src_masks = torch.IntTensor(\n",
        "                [sequence.attention_mask for sequence in src_batch]\n",
        "            ).to(device)\n",
        "            tgt_masks = torch.IntTensor(\n",
        "                [sequence.attention_mask for sequence in tgt_batch]\n",
        "            )[:, :-1].to(device)\n",
        "            val_output = encoder_decoder_transformer(\n",
        "                encoder_input, decoder_input, src_masks, tgt_masks\n",
        "            )\n",
        "            output_transpose = val_output.transpose(\n",
        "                -1, -2\n",
        "            )  # output needs to be N, C, other dimension for torch cross entropy\n",
        "            loss = loss_function(output_transpose, decoder_desired_output_val.long())\n",
        "            val_losses.append(loss.item())\n",
        "            if validation_step % 20 == 0:\n",
        "                print(\"Completed validation step\", validation_step)\n",
        "            validation_step += 1\n",
        "\n",
        "        print(\"epoch\", i, \"took\", time.time() - epoch_time_start)\n",
        "        print(\"avg training loss:\", sum(train_losses) / len(train_losses))\n",
        "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "        print(\"avg validation loss:\", avg_val_loss)\n",
        "        expected_train_output = tgt_tokenizer.decode(\n",
        "            decoder_desired_output_train[0].tolist()\n",
        "        )\n",
        "        print(\"expected train output\", expected_train_output)\n",
        "        decoded_output = decode(train_output[0], tgt_tokenizer)\n",
        "        print(\"decoded train output:\", decoded_output)\n",
        "        expected_val_output = tgt_tokenizer.decode(\n",
        "            decoder_desired_output_val[0].tolist()\n",
        "        )\n",
        "        print(\"expected validation output\", expected_val_output)\n",
        "        decoded_output = decode(val_output[0], tgt_tokenizer)\n",
        "        print(\"decoded validation output:\", decoded_output)\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(encoder_decoder_transformer.state_dict(), state_dict_filename)\n",
        "            print(\"Saved model state dict to\", state_dict_filename)\n",
        "            num_fails = 0\n",
        "        else:\n",
        "            print(\"Average validation loss did not decrease from \", best_val_loss)\n",
        "            num_fails += 1\n",
        "            print(\"Failed to decrease the average validation loss\", num_fails, \"times.\")\n",
        "            if num_fails >= 2:\n",
        "                print(\"Stopping training\")\n",
        "                break\n",
        "        print()\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "NCHMIluxq6Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    folder = \"drive/MyDrive/colab data/\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    num_encoder_layers = 4\n",
        "    num_decoder_layers = 4\n",
        "    num_heads = 8\n",
        "    d_attn = 256\n",
        "    d_x = 256\n",
        "    d_z = 256\n",
        "    d_out = 256\n",
        "    d_mid = 256\n",
        "    d_mlp = 512\n",
        "    d_e = 256\n",
        "    max_sequence_length = 100\n",
        "    p_dropout = 0.1\n",
        "    enRawName = folder + \"/multi30kEnTrain.txt\"\n",
        "    deRawName = folder + \"/multi30kDeTrain.txt\"\n",
        "    saveDirectory = \"./\"\n",
        "    nameSuffix = \"\"\n",
        "    state_dict_filename = (\n",
        "        saveDirectory\n",
        "        + \"encoder_decoder_transformer_state_dict_\"\n",
        "        + datetime.today().strftime(\"%Y-%m-%d %H\")\n",
        "        + nameSuffix\n",
        "    )\n",
        "    tensor = torch.tensor([1, 2, 3])\n",
        "    tensor.float()\n",
        "    vocab_size = 10000\n",
        "    train_and_validation_sequence_datasets = TrainAndValidationSequenceDatasets(\n",
        "        enRawName, deRawName, vocab_size, vocab_size, 0, 28250, 28250, 29000\n",
        "    )\n",
        "    custom_encoder_decoder_transformer = EncoderDecoderTransformer(\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        num_heads,\n",
        "        d_attn,\n",
        "        d_x,\n",
        "        d_z,\n",
        "        d_out,\n",
        "        d_mid,\n",
        "        d_mlp,\n",
        "        d_e,\n",
        "        vocab_size,\n",
        "        max_sequence_length,\n",
        "        p_dropout,\n",
        "        device\n",
        "    ).to(device)\n",
        "    custom_encoder_decoder_transformer.src_embedding.table = custom_encoder_decoder_transformer.src_embedding.table.to(device)\n",
        "    custom_encoder_decoder_transformer.tgt_embedding.table = custom_encoder_decoder_transformer.tgt_embedding.table.to(device)\n",
        "    custom_encoder_decoder_transformer.positionalEmbedding.table = custom_encoder_decoder_transformer.positionalEmbedding.table.to(device)\n",
        "    train_dataset = train_and_validation_sequence_datasets.train_dataset\n",
        "    val_dataset = train_and_validation_sequence_datasets.val_dataset\n",
        "    pad_collate = PadCollate(enRawName, deRawName, vocab_size, vocab_size)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=256, collate_fn=pad_collate)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=256, collate_fn=pad_collate)\n",
        "    train_model(\n",
        "        custom_encoder_decoder_transformer,\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        pad_collate.src_tokenizer,\n",
        "        pad_collate.tgt_tokenizer,\n",
        "        device,\n",
        "        state_dict_filename\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "VLT6fo1IjhG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64554ea6-d1d2-4323-9390-ae73ab41fe9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating tokenizer for drive/MyDrive/colab data//multi30kEnTrain.txt\n",
            "creating tokenizer for drive/MyDrive/colab data//multi30kDeTrain.txt\n",
            "<generator object Module.parameters at 0x78093ba04430>\n",
            "Completed training step 0\n",
            "Completed training step 20\n",
            "Completed training step 40\n",
            "Completed training step 60\n",
            "Completed training step 80\n",
            "Completed training step 100\n",
            "Completed validation step 0\n",
            "epoch 0 took 25.332783699035645\n",
            "avg training loss: 7.700793476792069\n",
            "avg validation loss: 6.781032244364421\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 14, 14, 14, 14, 14, 14, 1, 14, 14, 1, 14, 1, 14, 14, 1, 1, 14, 1, 1, 1, 1, 1, 14, 1, 14, 14, 1, 1, 1, 1, 14, 1, 1]\n",
            "decoded train output: Ein Mann , , , , , , , , , , , , , , . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [109, 124, 100, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 12, 14, 12, 14, 14, 14, 14, 12, 14]\n",
            "decoded validation output: Ein Mann in , , , , , , , , , , , , , . . . . . . . . . . , . , . . . . , .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 120\n",
            "Completed training step 140\n",
            "Completed training step 160\n",
            "Completed training step 180\n",
            "Completed training step 200\n",
            "Completed training step 220\n",
            "epoch 1 took 20.924058437347412\n",
            "avg training loss: 6.268257321538152\n",
            "avg validation loss: 6.16811736424764\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 100, 100, 100, 100, 12, 12, 12, 12, 12, 111, 12, 12, 12, 111, 14, 12, 12, 14, 111, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 111, 14, 14]\n",
            "decoded train output: Ein Mann in in in in , , , , , einem , , , einem . , , . einem . . . . . . . . . . . . . . . . . . . . . . . . einem . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [109, 124, 100, 100, 100, 12, 12, 100, 12, 12, 12, 12, 111, 12, 12, 12, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Ein Mann in in in , , in , , , , einem , , , . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 240\n",
            "Completed training step 260\n",
            "Completed training step 280\n",
            "Completed training step 300\n",
            "Completed training step 320\n",
            "epoch 2 took 20.744799613952637\n",
            "avg training loss: 5.7794562846690685\n",
            "avg validation loss: 5.8667073249816895\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 100, 124, 100, 124, 100, 100, 100, 12, 100, 111, 124, 100, 114, 111, 14, 14, 12, 14, 111, 1, 14, 14, 1, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 14, 14, 14]\n",
            "decoded train output: Ein Mann in Mann in Mann in in in , in einem Mann in und einem . . , . einem . . . . . . . . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [109, 138, 100, 100, 14, 12, 12, 14, 12, 12, 12, 12, 111, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Ein Frau in in . , , . , , , , einem . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 340\n",
            "Completed training step 360\n",
            "Completed training step 380\n",
            "Completed training step 400\n",
            "Completed training step 420\n",
            "Completed training step 440\n",
            "epoch 3 took 21.177398204803467\n",
            "avg training loss: 5.482313285002837\n",
            "avg validation loss: 5.652891953786214\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 100, 124, 100, 124, 12, 100, 100, 14, 12, 111, 276, 276, 100, 111, 14, 281, 14, 14, 121, 14, 14, 14, 124, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded train output: Ein Mann in Mann in Mann , in in . , einem blauen blauen in einem . weißen . . der . . . Mann . . . . . . . . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 100, 14, 100, 100, 14, 12, 100, 12, 12, 111, 12, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer in in . in in . , in , , einem , . . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 460\n",
            "Completed training step 480\n",
            "Completed training step 500\n",
            "Completed training step 520\n",
            "Completed training step 540\n",
            "epoch 4 took 20.619108200073242\n",
            "avg training loss: 5.260367419268634\n",
            "avg validation loss: 5.445483843485515\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 124, 124, 119, 124, 124, 119, 12, 281, 114, 111, 138, 265, 12, 111, 281, 281, 12, 245, 103, 14, 14, 14, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded train output: Ein Mann Mann Mann mit Mann Mann mit , weißen und einem Frau Hemd , einem weißen weißen , Straße ein . . . Frau . . . . . . . . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 100, 1, 245, 100, 457, 117, 100, 152, 100, 111, 14, 245, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 14, 14]\n",
            "decoded validation output: Zwei Männer in in Straße in Freien auf in die in einem . Straße . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 560\n",
            "Completed training step 580\n",
            "Completed training step 600\n",
            "Completed training step 620\n",
            "Completed training step 640\n",
            "Completed training step 660\n",
            "epoch 5 took 20.816800594329834\n",
            "avg training loss: 5.083119628665684\n",
            "avg validation loss: 5.284485499064128\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 124, 124, 124, 124, 265, 12, 12, 281, 12, 111, 138, 281, 12, 111, 245, 245, 12, 138, 103, 1, 14, 14, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded train output: Ein Mann Mann Mann Mann Mann Hemd , , weißen , einem Frau weißen , einem Straße Straße , Frau ein . . Frau . . . . . . . . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 100, 457, 245, 100, 493, 100, 100, 184, 100, 111, 14, 245, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer in in Freien Straße in Gebäude in in von in einem . Straße . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 680\n",
            "Completed training step 700\n",
            "Completed training step 720\n",
            "Completed training step 740\n",
            "Completed training step 760\n",
            "Completed validation step 20\n",
            "epoch 6 took 20.496312618255615\n",
            "avg training loss: 4.926102681202932\n",
            "avg validation loss: 5.141965230305989\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 100, 124, 138, 124, 265, 114, 12, 281, 12, 111, 124, 265, 12, 111, 124, 281, 13, 13, 12, 448, 12, 14, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 138, 14, 14, 14, 14, 12, 12, 14, 114, 14, 14, 14, 124, 12]\n",
            "decoded train output: Ein Mann in Mann Frau Mann Hemd und , weißen , einem Mann Hemd , einem Mann weißen - - , Hintergrund , . Frau . . . . . . . . . Frau . . . . , , . und . . . Mann ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 117, 457, 245, 100, 493, 100, 100, 184, 100, 111, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1]\n",
            "decoded validation output: Zwei Männer in auf Freien Straße in Gebäude in in von in einem . . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 780\n",
            "Completed training step 800\n",
            "Completed training step 820\n",
            "Completed training step 840\n",
            "Completed training step 860\n",
            "Completed training step 880\n",
            "epoch 7 took 20.887210369110107\n",
            "avg training loss: 4.784048613127287\n",
            "avg validation loss: 5.067708492279053\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 13, 124, 13, 124, 13, 100, 12, 448, 12, 111, 138, 265, 12, 111, 281, 265, 13, 12, 250, 448, 14, 12, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 13, 14, 12, 12, 14, 14, 12, 14, 14, 12, 12]\n",
            "decoded train output: Ein Mann - Mann - Mann - in , Hintergrund , einem Frau Hemd , einem weißen Hemd - , während Hintergrund . , Frau . . . . . . . . . . . . - . , , . . , . . , ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 100, 457, 13, 100, 493, 100, 100, 295, 12, 111, 12, 13, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer in in Freien - in Gebäude in in sitzen , einem , - . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 900\n",
            "Completed training step 920\n",
            "Completed training step 940\n",
            "Completed training step 960\n",
            "Completed training step 980\n",
            "epoch 8 took 20.456078052520752\n",
            "avg training loss: 4.658285918536487\n",
            "avg validation loss: 4.963480790456136\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 13, 124, 13, 124, 265, 100, 100, 448, 12, 111, 138, 281, 12, 111, 245, 265, 12, 124, 250, 448, 12, 12, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded train output: Ein Mann - Mann - Mann Hemd in in Hintergrund , einem Frau weißen , einem Straße Hemd , Mann während Hintergrund , , Frau . . . . . . . . . . . . . . . . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 100, 100, 457, 13, 100, 493, 100, 100, 100, 100, 111, 114, 13, 100, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer in in Freien - in Gebäude in in in in einem und - in . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1000\n",
            "Completed training step 1020\n",
            "Completed training step 1040\n",
            "Completed training step 1060\n",
            "Completed training step 1080\n",
            "Completed training step 1100\n",
            "epoch 9 took 20.874297857284546\n",
            "avg training loss: 4.534460553177842\n",
            "avg validation loss: 4.845283190409343\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 235, 13, 200, 13, 124, 13, 100, 100, 457, 12, 111, 138, 314, 12, 111, 401, 314, 12, 13, 250, 448, 12, 12, 138, 13, 12, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 14, 14, 14, 14, 14, 14, 12]\n",
            "decoded train output: Ein Junge - Hund - Mann - in in Freien , einem Frau Hand , einem großen Hand , - während Hintergrund , , Frau - , . . . . . . . . . . . . . , . . . . . . ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 100, 100, 474, 100, 100, 295, 176, 111, 14, 13, 100, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien in in Tisch in in sitzen vor einem . - in . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1120\n",
            "Completed training step 1140\n",
            "Completed training step 1160\n",
            "Completed training step 1180\n",
            "Completed training step 1200\n",
            "Completed training step 1220\n",
            "epoch 10 took 20.52351212501526\n",
            "avg training loss: 4.41162540891149\n",
            "avg validation loss: 4.751443227132161\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 124, 13, 200, 13, 200, 200, 100, 100, 448, 12, 111, 138, 281, 12, 111, 245, 314, 12, 12, 250, 448, 12, 14, 138, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 12, 14, 14, 14, 14, 14, 14, 12]\n",
            "decoded train output: Ein Mann - Hund - Hund Hund in in Hintergrund , einem Frau weißen , einem Straße Hand , , während Hintergrund , . Frau . . . . . . . . . . . . . . , , . . . . . . ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 100, 100, 457, 100, 100, 100, 100, 111, 14, 13, 100, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien in in Freien in in in in einem . - in . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1240\n",
            "Completed training step 1260\n",
            "Completed training step 1280\n",
            "Completed training step 1300\n",
            "Completed training step 1320\n",
            "epoch 11 took 20.914311170578003\n",
            "avg training loss: 4.292174680812939\n",
            "avg validation loss: 4.628602186838786\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 200, 13, 200, 454, 12, 12, 457, 12, 111, 401, 281, 12, 111, 401, 749, 12, 268, 121, 448, 12, 12, 252, 13, 444, 14, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 184, 14, 14, 254, 268, 14, 444, 12]\n",
            "decoded train output: Ein schwarz - Hund - Hund Jacke , , Freien , einem großen weißen , einem großen Trikot , Personen der Hintergrund , , Gruppe - sind . sehen . . . . . . . . . . , von . . ist Personen . sind ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 100, 100, 535, 100, 100, 295, 100, 111, 268, 75, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien in in Park in in sitzen in einem Personen s . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1340\n",
            "Completed training step 1360\n",
            "Completed training step 1380\n",
            "Completed training step 1400\n",
            "Completed training step 1420\n",
            "Completed training step 1440\n",
            "epoch 12 took 20.447027683258057\n",
            "avg training loss: 4.175337763519974\n",
            "avg validation loss: 4.525044759114583\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 13, 214, 200, 12, 12, 448, 12, 111, 401, 633, 12, 111, 281, 245, 13, 13, 250, 448, 12, 12, 601, 12, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 75, 12, 14, 14, 14, 14, 14, 14, 1]\n",
            "decoded train output: Ein schwarz - weißer - schwarz Hund , , Hintergrund , einem großen Gehweg , einem weißen Straße - - während Hintergrund , , große , . . . . . . . . . . . . . s , . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 100, 100, 474, 100, 100, 295, 100, 111, 14, 75, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien in in Tisch in in sitzen in einem . s . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1460\n",
            "Completed training step 1480\n",
            "Completed training step 1500\n",
            "Completed training step 1520\n",
            "Completed training step 1540\n",
            "Completed validation step 40\n",
            "epoch 13 took 20.848063707351685\n",
            "avg training loss: 4.064636391562384\n",
            "avg validation loss: 4.440720399220784\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 503, 13, 532, 13, 532, 13, 12, 117, 448, 12, 111, 281, 276, 12, 111, 294, 294, 12, 209, 250, 448, 12, 152, 209, 12, 14, 14, 450, 14, 1, 14, 14, 14, 14, 14, 153, 14, 14, 14, 12, 12, 12, 14, 14, 14, 14, 153, 12]\n",
            "decoded train output: Ein schwarzer - weißer - weißer - , auf Hintergrund , einem weißen blauen , einem roten roten , Person während Hintergrund , die Person , . . sehen . . . . . . zu . . . , , , . . . . zu ,\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 13, 100, 457, 100, 100, 359, 100, 111, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien - in Freien in in gehen in einem . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1560\n",
            "Completed training step 1580\n",
            "Completed training step 1600\n",
            "Completed training step 1620\n",
            "Completed training step 1640\n",
            "Completed training step 1660\n",
            "epoch 14 took 20.645208835601807\n",
            "avg training loss: 3.9603948700535403\n",
            "avg validation loss: 4.383593559265137\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 503, 13, 532, 13, 532, 532, 12, 100, 448, 12, 111, 401, 281, 12, 111, 281, 389, 13, 209, 250, 448, 12, 12, 601, 12, 100, 100, 111, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 153, 14, 14, 14, 14, 14, 153, 1]\n",
            "decoded train output: Ein schwarzer - weißer - weißer weißer , in Hintergrund , einem großen weißen , einem weißen Oberteil - Person während Hintergrund , , große , in in einem . . . . . . . . . . , zu . . . . . zu\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 117, 100, 1072, 100, 12, 579, 100, 111, 14, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien auf in Markt in , schauen in einem . ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1680\n",
            "Completed training step 1700\n",
            "Completed training step 1720\n",
            "Completed training step 1740\n",
            "Completed training step 1760\n",
            "epoch 15 took 20.821096897125244\n",
            "avg training loss: 3.8624286780486234\n",
            "avg validation loss: 4.322396914164226\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 13, 532, 200, 117, 117, 457, 12, 111, 401, 245, 100, 111, 276, 245, 12, 276, 152, 448, 254, 103, 601, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded train output: Ein schwarz - weißer - weißer Hund auf auf Freien , einem großen Straße in einem blauen Straße , blauen die Hintergrund ist ein große . . . . . . . . . . . . . . , . . . . . . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 133, 100, 535, 100, 100, 579, 100, 121, 12, 377, 100, 1, 14, 14, 14, 14, 14, 14, 14, 153, 14, 14, 14, 14, 14, 153, 14, 14, 14, 153, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien ten in Park in in schauen in der , ischen in . . . . . . . zu . . . . . zu . . . zu . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1780\n",
            "Completed training step 1800\n",
            "Completed training step 1820\n",
            "Completed training step 1840\n",
            "Completed training step 1860\n",
            "Completed training step 1880\n",
            "epoch 16 took 20.82362937927246\n",
            "avg training loss: 3.77440256685824\n",
            "avg validation loss: 4.181919415791829\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 200, 786, 100, 106, 457, 12, 111, 401, 813, 12, 111, 276, 99, 13, 276, 250, 448, 254, 103, 461, 75, 14, 14, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 14, 14, 14, 75, 14, 14, 14, 75]\n",
            "decoded train output: Ein schwarz - rot - Hund Auto in an Freien , einem großen Tag , einem blauen „ - blauen während Hintergrund ist ein anderen s . . sehen . . . . . . . . . . , . . . s . . . s\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 13, 117, 535, 100, 100, 579, 100, 111, 456, 13, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien - auf Park in in schauen in einem Kleidung - . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 1900\n",
            "Completed training step 1920\n",
            "Completed training step 1940\n",
            "Completed training step 1960\n",
            "Completed training step 1980\n",
            "epoch 17 took 20.707393646240234\n",
            "avg training loss: 3.6812040569545985\n",
            "avg validation loss: 4.114760319391887\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 503, 13, 214, 13, 532, 786, 12, 100, 448, 12, 111, 401, 245, 12, 111, 401, 1743, 75, 12, 152, 448, 12, 12, 209, 12, 184, 153, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 153, 14, 14, 450, 14, 14, 14, 469]\n",
            "decoded train output: Ein schwarzer - schwarz - weißer Auto , in Hintergrund , einem großen Straße , einem großen Aufschrift s , die Hintergrund , , Person , von zu sehen . . . . . . . . . . , zu . . sehen . . . vorbei\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 813, 100, 535, 114, 114, 295, 100, 111, 14, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien Tag in Park und und sitzen in einem . ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2000\n",
            "Completed training step 2020\n",
            "Completed training step 2040\n",
            "Completed training step 2060\n",
            "Completed training step 2080\n",
            "Completed training step 2100\n",
            "epoch 18 took 20.79644274711609\n",
            "avg training loss: 3.59421629948659\n",
            "avg validation loss: 4.0639543533325195\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 13, 532, 200, 12, 100, 448, 119, 111, 401, 245, 119, 111, 281, 1743, 13, 12, 152, 448, 444, 100, 601, 153, 444, 100, 450, 14, 1, 14, 14, 14, 14, 153, 14, 14, 14, 153, 12, 14, 14, 14, 14, 14, 14, 153, 14]\n",
            "decoded train output: Ein schwarz - weißer - weißer Hund , in Hintergrund mit einem großen Straße mit einem weißen Aufschrift - , die Hintergrund sind in große zu sind in sehen . . . . . zu . . . zu , . . . . . . zu .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 106, 117, 1072, 114, 100, 295, 100, 111, 14, 813, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien an auf Markt und in sitzen in einem . Tag . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2120\n",
            "Completed training step 2140\n",
            "Completed training step 2160\n",
            "Completed training step 2180\n",
            "Completed training step 2200\n",
            "epoch 19 took 20.60984492301941\n",
            "avg training loss: 3.5133790626182213\n",
            "avg validation loss: 4.028091351191203\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 214, 13, 532, 786, 12, 100, 457, 12, 111, 401, 245, 12, 111, 401, 99, 12, 184, 119, 448, 254, 103, 601, 153, 254, 153, 450, 14, 1, 14, 14, 14, 14, 14, 14, 254, 14, 14, 786, 153, 14, 14, 14, 14, 14, 153, 1]\n",
            "decoded train output: Ein schwarz - schwarz - weißer Auto , in Freien , einem großen Straße , einem großen „ , von mit Hintergrund ist ein große zu ist zu sehen . . . . . . . ist . . Auto zu . . . . . zu\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 75, 114, 1072, 114, 114, 579, 117, 111, 14, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien s und Markt und und schauen auf einem . ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2220\n",
            "Completed training step 2240\n",
            "Completed training step 2260\n",
            "Completed training step 2280\n",
            "Completed training step 2300\n",
            "Completed training step 2320\n",
            "Completed validation step 60\n",
            "epoch 20 took 20.97809910774231\n",
            "avg training loss: 3.441739254169636\n",
            "avg validation loss: 4.001301050186157\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 13, 532, 786, 117, 117, 457, 125, 111, 276, 245, 119, 111, 276, 1743, 12, 276, 121, 448, 254, 107, 276, 61, 268, 153, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 153, 153, 14, 14, 14, 450, 14, 14, 153, 254]\n",
            "decoded train output: Ein schwarz - weißer - weißer Auto auf auf Freien einer einem blauen Straße mit einem blauen Aufschrift , blauen der Hintergrund ist eine blauen e Personen zu sehen . . . . . . . . . zu zu . . . sehen . . zu ist\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 117, 117, 813, 114, 114, 579, 117, 585, 14, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien auf auf Tag und und schauen auf ihren . ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2340\n",
            "Completed training step 2360\n",
            "Completed training step 2380\n",
            "Completed training step 2400\n",
            "Completed training step 2420\n",
            "Completed training step 2440\n",
            "epoch 21 took 20.505271196365356\n",
            "avg training loss: 3.3750545527483964\n",
            "avg validation loss: 3.982799847920736\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 532, 786, 117, 117, 457, 12, 125, 401, 245, 119, 111, 276, 1743, 100, 184, 152, 448, 254, 107, 601, 153, 184, 100, 450, 153, 1, 14, 14, 14, 14, 14, 444, 14, 14, 153, 137, 444, 14, 14, 153, 153, 14, 153, 97]\n",
            "decoded train output: Ein schwarz - rot - weißer Auto auf auf Freien , einer großen Straße mit einem blauen Aufschrift in von die Hintergrund ist eine große zu von in sehen zu . . . . . sind . . zu te sind . . zu zu . zu “\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 117, 1072, 114, 114, 754, 117, 121, 177, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag auf Markt und und unterhalten auf der sich ten . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2460\n",
            "Completed training step 2480\n",
            "Completed training step 2500\n",
            "Completed training step 2520\n",
            "Completed training step 2540\n",
            "epoch 22 took 20.907456636428833\n",
            "avg training loss: 3.3109448772292955\n",
            "avg validation loss: 3.919201135635376\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 532, 786, 117, 117, 448, 12, 125, 276, 314, 119, 111, 276, 1743, 12, 12, 250, 448, 254, 103, 1377, 14, 444, 153, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 239, 14, 14, 14, 14, 14, 14, 153, 14]\n",
            "decoded train output: Ein schwarz - rot - weißer Auto auf auf Hintergrund , einer blauen Hand mit einem blauen Aufschrift , , während Hintergrund ist ein blaue . sind zu sehen . . . . . . . . . . es . . . . . . zu .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 114, 457, 75, 114, 1024, 117, 111, 14, 352, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag und Freien s und warten auf einem . eln . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2560\n",
            "Completed training step 2580\n",
            "Completed training step 2600\n",
            "Completed training step 2620\n",
            "Completed training step 2640\n",
            "Completed training step 2660\n",
            "epoch 23 took 20.519311666488647\n",
            "avg training loss: 3.2532506590490944\n",
            "avg validation loss: 3.8258570035298667\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 13, 532, 786, 148, 117, 457, 12, 125, 276, 245, 100, 111, 276, 1354, 75, 209, 152, 448, 254, 107, 1377, 75, 100, 148, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 137, 14, 14, 14, 444, 444, 14, 14, 75]\n",
            "decoded train output: Ein schwarz - weißer - weißer Auto im auf Freien , einer blauen Straße in einem blauen Tür s Person die Hintergrund ist eine blaue s in im sehen . . . . . . . . . . te . . . sind sind . . s\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 117, 1072, 13, 114, 295, 117, 111, 14, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag auf Markt - und sitzen auf einem . ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2680\n",
            "Completed training step 2700\n",
            "Completed training step 2720\n",
            "Completed training step 2740\n",
            "Completed training step 2760\n",
            "epoch 24 took 20.88446545600891\n",
            "avg training loss: 3.1940261931032747\n",
            "avg validation loss: 3.7773285706837973\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 532, 907, 532, 786, 148, 117, 457, 119, 125, 798, 245, 119, 111, 276, 1354, 184, 100, 100, 448, 254, 107, 1377, 61, 100, 148, 450, 14, 1, 14, 14, 14, 444, 14, 14, 14, 14, 14, 61, 153, 254, 14, 444, 14, 14, 14, 1]\n",
            "decoded train output: Ein schwarz - weißer gekleideter weißer Auto im auf Freien mit einer grauen Straße mit einem blauen Tür von in in Hintergrund ist eine blaue e in im sehen . . . . sind . . . . . e zu ist . sind . . .\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 100, 457, 117, 117, 1072, 13, 100, 1024, 117, 111, 14, 377, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen in Freien auf auf Markt - in warten auf einem . ischen . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 2780\n",
            "Completed training step 2800\n",
            "Completed training step 2820\n",
            "Completed training step 2840\n",
            "Completed training step 2860\n",
            "Completed training step 2880\n",
            "epoch 25 took 20.574538946151733\n",
            "avg training loss: 3.1333389389622317\n",
            "avg validation loss: 3.798243840535482\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 532, 786, 148, 117, 457, 12, 125, 281, 245, 12, 111, 276, 1743, 13, 13, 117, 448, 254, 107, 601, 61, 100, 153, 450, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 245, 153, 14, 14, 14, 153, 14, 153, 75]\n",
            "decoded train output: Ein schwarz - rot - weißer Auto im auf Freien , einer weißen Straße , einem blauen Aufschrift - - auf Hintergrund ist eine große e in zu sehen . . . . . . . . . . Straße zu . . . zu . zu s\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 117, 3070, 75, 100, 1198, 117, 111, 14, 75, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag auf Flughafen s in kaufen auf einem . s . . . . . . . . . . . . . . . . . . . . .\n",
            "Average validation loss did not decrease from  3.7773285706837973\n",
            "Failed to decrease the average validation loss 1 times.\n",
            "\n",
            "\n",
            "Completed training step 2900\n",
            "Completed training step 2920\n",
            "Completed training step 2940\n",
            "Completed training step 2960\n",
            "Completed training step 2980\n",
            "Completed validation step 80\n",
            "epoch 26 took 20.87740445137024\n",
            "avg training loss: 3.079537194054406\n",
            "avg validation loss: 3.746364116668701\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 322, 13, 532, 200, 148, 148, 457, 117, 125, 798, 1354, 119, 111, 276, 1354, 12, 12, 100, 448, 254, 107, 276, 100, 100, 100, 450, 14, 1, 254, 254, 14, 14, 14, 444, 254, 14, 153, 138, 153, 254, 444, 153, 444, 450, 100, 100]\n",
            "decoded train output: Ein schwarz - weiß - weißer Hund im im Freien auf einer grauen Tür mit einem blauen Tür , , in Hintergrund ist eine blauen in in in sehen . ist ist . . . sind ist . zu Frau zu ist sind zu sind sehen in in\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 117, 3070, 75, 114, 579, 117, 111, 14, 352, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag auf Flughafen s und schauen auf einem . eln . . . . . . . . . . . . . . . . . . . . .\n",
            "Saved model state dict to ./encoder_decoder_transformer_state_dict_2024-08-12 14\n",
            "\n",
            "\n",
            "Completed training step 3000\n",
            "Completed training step 3020\n",
            "Completed training step 3040\n",
            "Completed training step 3060\n",
            "Completed training step 3080\n",
            "Completed training step 3100\n",
            "epoch 27 took 20.532511234283447\n",
            "avg training loss: 3.0291456725146317\n",
            "avg validation loss: 3.7815672556559243\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 532, 1022, 12, 117, 457, 117, 125, 798, 1354, 12, 111, 798, 1354, 100, 12, 100, 448, 254, 107, 1377, 100, 100, 100, 450, 14, 1, 14, 254, 14, 14, 153, 14, 14, 14, 14, 12, 100, 444, 14, 153, 14, 450, 153, 75]\n",
            "decoded train output: Ein schwarz - rot - weißer Rennen , auf Freien auf einer grauen Tür , einem grauen Tür in , in Hintergrund ist eine blaue in in in sehen . . ist . . zu . . . . , in sind . zu . sehen zu s\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 457, 813, 117, 3070, 13, 13, 1024, 117, 111, 133, 133, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Freien Tag auf Flughafen - - warten auf einem ten ten . . . . . . . . . . . . . . . . . . . . .\n",
            "Average validation loss did not decrease from  3.746364116668701\n",
            "Failed to decrease the average validation loss 1 times.\n",
            "\n",
            "\n",
            "Completed training step 3120\n",
            "Completed training step 3140\n",
            "Completed training step 3160\n",
            "Completed training step 3180\n",
            "Completed training step 3200\n",
            "epoch 28 took 20.872478246688843\n",
            "avg training loss: 2.985027886725761\n",
            "avg validation loss: 3.7551663716634116\n",
            "expected train output Ein schwarz - rot - weißes Rennwagen saust im Vordergrund auf einer grauen Strecke mit einer blauen Ban de , im Hintergrund ist eine verschwommen e Menschenmenge zu sehen .\n",
            "argmax x: [109, 214, 13, 611, 13, 532, 13, 117, 117, 457, 117, 125, 798, 245, 12, 111, 276, 1354, 12, 12, 152, 448, 254, 107, 1377, 61, 209, 153, 450, 14, 1, 14, 14, 153, 153, 153, 14, 14, 14, 153, 12, 153, 14, 14, 153, 153, 450, 153, 75]\n",
            "decoded train output: Ein schwarz - rot - weißer - auf auf Freien auf einer grauen Straße , einem blauen Tür , , die Hintergrund ist eine blaue e Person zu sehen . . . zu zu zu . . . zu , zu . . zu zu sehen zu s\n",
            "expected validation output Zwei Männer sitzen im Warte bereich eines Flughafen s und schreiben in Notiz b ücher .\n",
            "argmax x: [160, 217, 295, 117, 3070, 117, 117, 3070, 75, 100, 1024, 117, 585, 14, 352, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
            "decoded validation output: Zwei Männer sitzen auf Flughafen auf auf Flughafen s in warten auf ihren . eln . . . . . . . . . . . . . . . . . . . . .\n",
            "Average validation loss did not decrease from  3.746364116668701\n",
            "Failed to decrease the average validation loss 2 times.\n",
            "Stopping training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_tokens(model, input, src_tokenizer, tgt_tokenizer):\n",
        "    model.disable_subsequent_mask()\n",
        "    src_tokenizer.no_padding()\n",
        "    tgt_tokenizer.no_padding()\n",
        "\n",
        "    src_tokenizer.no_truncation()\n",
        "    tgt_tokenizer.no_truncation()\n",
        "    src_sequence = input\n",
        "    print(src_sequence)\n",
        "    src_sequence = src_tokenizer.encode(src_sequence)\n",
        "    print(src_sequence)\n",
        "    print(src_tokenizer.decode(src_sequence.ids))\n",
        "    src_sequence = torch.IntTensor(src_sequence.ids).unsqueeze(0).to(device)\n",
        "    print(\"src tokens\", src_sequence)\n",
        "    tgt_sequence = torch.IntTensor([0]).unsqueeze(0).to(device)\n",
        "    src_mask = torch.ones(src_sequence.shape, dtype=torch.int32).to(device)\n",
        "    print(\"decoder input\", tgt_sequence)\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        length_gen = 100\n",
        "        for i in range(length_gen):\n",
        "            tgt_mask = torch.ones(tgt_sequence.shape, dtype=torch.int32).to(device)\n",
        "            prediction = model(src_sequence, tgt_sequence, src_mask, tgt_mask)\n",
        "            #print(\"prediction:\", prediction)\n",
        "            prediction = torch.softmax(prediction, -1)\n",
        "            #print(\"softmax prediction:\", prediction.shape)\n",
        "            prediction = torch.argmax(prediction, dim=-1)\n",
        "            print(\"argmax prediction:\", prediction)\n",
        "            print(\"actual prediction:\", tgt_tokenizer.decode(prediction[0].tolist()))\n",
        "            last_token = prediction[0][-1]\n",
        "            tgt_sequence = torch.cat((tgt_sequence, last_token.unsqueeze(0).unsqueeze(0)), dim=-1)\n",
        "            if last_token == 1:\n",
        "                break\n",
        "    return tgt_sequence\n",
        "\n",
        "tgt_sequence = predict_from_tokens(encoder_decoder_transformer, \"A man on the sea\", pad_collate.src_tokenizer, pad_collate.tgt_tokenizer)\n",
        "print(tgt_sequence)\n",
        "print(pad_collate.tgt_tokenizer.decode(tgt_sequence[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FVEp1SmrhVuf",
        "outputId": "a3c4df53-8db3-44be-881b-4aceb45a7563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'encoder_decoder_transformer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-695c621f7b92>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtgt_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_from_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_decoder_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"A man on the sea\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_collate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_collate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_collate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder_decoder_transformer' is not defined"
          ]
        }
      ]
    }
  ]
}